{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-30T16:29:57.806464Z",
     "iopub.status.busy": "2020-09-30T16:29:57.805622Z",
     "iopub.status.idle": "2020-09-30T16:29:57.808157Z",
     "shell.execute_reply": "2020-09-30T16:29:57.808660Z"
    },
    "papermill": {
     "duration": 0.057127,
     "end_time": "2020-09-30T16:29:57.808824",
     "exception": false,
     "start_time": "2020-09-30T16:29:57.751697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:29:57.905075Z",
     "iopub.status.busy": "2020-09-30T16:29:57.904398Z",
     "iopub.status.idle": "2020-09-30T16:29:57.947390Z",
     "shell.execute_reply": "2020-09-30T16:29:57.946830Z"
    },
    "papermill": {
     "duration": 0.093583,
     "end_time": "2020-09-30T16:29:57.947498",
     "exception": false,
     "start_time": "2020-09-30T16:29:57.853915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "traindf_noisy=pd.read_csv('../input/freesound-audio-tagging-2019/train_noisy.csv',dtype=str)\n",
    "\n",
    "traindf_curated=pd.read_csv('../input/freesound-audio-tagging-2019/train_curated.csv',dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading 4-K Fold Noisy Train, CV and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:29:58.049403Z",
     "iopub.status.busy": "2020-09-30T16:29:58.048761Z",
     "iopub.status.idle": "2020-09-30T16:29:58.057886Z",
     "shell.execute_reply": "2020-09-30T16:29:58.058368Z"
    },
    "papermill": {
     "duration": 0.066354,
     "end_time": "2020-09-30T16:29:58.058507",
     "exception": false,
     "start_time": "2020-09-30T16:29:57.992153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00097e21.wav</td>\n",
       "      <td>Bathtub_(filling_or_washing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000b6cfb.wav</td>\n",
       "      <td>Motorcycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00116cd2.wav</td>\n",
       "      <td>Marimba_and_xylophone,Glockenspiel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00127d14.wav</td>\n",
       "      <td>Water_tap_and_faucet,Sink_(filling_or_washing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0019adae.wav</td>\n",
       "      <td>Raindrop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname                                          labels\n",
       "0  00097e21.wav                    Bathtub_(filling_or_washing)\n",
       "1  000b6cfb.wav                                      Motorcycle\n",
       "2  00116cd2.wav              Marimba_and_xylophone,Glockenspiel\n",
       "3  00127d14.wav  Water_tap_and_faucet,Sink_(filling_or_washing)\n",
       "4  0019adae.wav                                        Raindrop"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf_noisy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:29:58.161509Z",
     "iopub.status.busy": "2020-09-30T16:29:58.160765Z",
     "iopub.status.idle": "2020-09-30T16:29:58.192281Z",
     "shell.execute_reply": "2020-09-30T16:29:58.191818Z"
    },
    "papermill": {
     "duration": 0.088341,
     "end_time": "2020-09-30T16:29:58.192408",
     "exception": false,
     "start_time": "2020-09-30T16:29:58.104067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161d2bb8.jpg</td>\n",
       "      <td>Bus,Microwave_oven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abf3a850.jpg</td>\n",
       "      <td>Bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fd802069.jpg</td>\n",
       "      <td>Cheering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0f69e008_aug.jpg</td>\n",
       "      <td>Purr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5c51827a.jpg</td>\n",
       "      <td>Applause</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              fname              labels\n",
       "0      161d2bb8.jpg  Bus,Microwave_oven\n",
       "1      abf3a850.jpg                 Bus\n",
       "2      fd802069.jpg            Cheering\n",
       "3  0f69e008_aug.jpg                Purr\n",
       "4      5c51827a.jpg            Applause"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../input/sc2-total-aug-noisy-data/K_fold_data/K_fold_data/Noisy/Noisy_train_4.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:29:58.288242Z",
     "iopub.status.busy": "2020-09-30T16:29:58.287457Z",
     "iopub.status.idle": "2020-09-30T16:29:58.291359Z",
     "shell.execute_reply": "2020-09-30T16:29:58.290852Z"
    },
    "papermill": {
     "duration": 0.054138,
     "end_time": "2020-09-30T16:29:58.291456",
     "exception": false,
     "start_time": "2020-09-30T16:29:58.237318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19449, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:29:58.391008Z",
     "iopub.status.busy": "2020-09-30T16:29:58.390105Z",
     "iopub.status.idle": "2020-09-30T16:29:58.402457Z",
     "shell.execute_reply": "2020-09-30T16:29:58.403020Z"
    },
    "papermill": {
     "duration": 0.065031,
     "end_time": "2020-09-30T16:29:58.403156",
     "exception": false,
     "start_time": "2020-09-30T16:29:58.338125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4862, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df = pd.read_csv(\"../input/sc2-total-aug-noisy-data/K_fold_data/K_fold_data/Noisy/Noisy_cv_4.csv\")\n",
    "cv_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:29:58.499044Z",
     "iopub.status.busy": "2020-09-30T16:29:58.498459Z",
     "iopub.status.idle": "2020-09-30T16:29:58.511759Z",
     "shell.execute_reply": "2020-09-30T16:29:58.512275Z"
    },
    "papermill": {
     "duration": 0.063439,
     "end_time": "2020-09-30T16:29:58.512414",
     "exception": false,
     "start_time": "2020-09-30T16:29:58.448975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6078, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "test_df = pd.read_csv(\"../input/sc2-total-aug-noisy-data/K_fold_data/K_fold_data/Noisy/Noisy_test.csv\") \n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn MultiLabelBinarizer to One-hot encode the multilablles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:29:58.613559Z",
     "iopub.status.busy": "2020-09-30T16:29:58.612792Z",
     "iopub.status.idle": "2020-09-30T16:29:59.600109Z",
     "shell.execute_reply": "2020-09-30T16:29:59.599057Z"
    },
    "papermill": {
     "duration": 1.04093,
     "end_time": "2020-09-30T16:29:59.600248",
     "exception": false,
     "start_time": "2020-09-30T16:29:58.559318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb_train = MultiLabelBinarizer()\n",
    "\n",
    "\n",
    "labels_train = mlb_train.fit_transform([ i.split(\",\") for i in list(train_df[\"labels\"])])\n",
    "\n",
    "\n",
    "labels_test = mlb_train.transform([ i.split(\",\") for i in list(test_df[\"labels\"])])\n",
    "\n",
    "\n",
    "#mlb_cv = MultiLabelBinarizer()\n",
    "labels_cv = mlb_train.transform([ i.split(\",\") for i in list(cv_df[\"labels\"])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:29:59.705818Z",
     "iopub.status.busy": "2020-09-30T16:29:59.704905Z",
     "iopub.status.idle": "2020-09-30T16:29:59.708943Z",
     "shell.execute_reply": "2020-09-30T16:29:59.709453Z"
    },
    "papermill": {
     "duration": 0.058964,
     "end_time": "2020-09-30T16:29:59.709585",
     "exception": false,
     "start_time": "2020-09-30T16:29:59.650621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6078, 80)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:29:59.825071Z",
     "iopub.status.busy": "2020-09-30T16:29:59.824168Z",
     "iopub.status.idle": "2020-09-30T16:29:59.827718Z",
     "shell.execute_reply": "2020-09-30T16:29:59.828316Z"
    },
    "papermill": {
     "duration": 0.070781,
     "end_time": "2020-09-30T16:29:59.828455",
     "exception": false,
     "start_time": "2020-09-30T16:29:59.757674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainmultidf=pd.DataFrame(data=labels_train,columns=list(mlb_train.classes_))\n",
    "trainmultidf[\"fname\"]=list(train_df[\"fname\"])\n",
    "\n",
    "testmultidf=pd.DataFrame(data=labels_test,columns=list(mlb_train.classes_))\n",
    "testmultidf[\"fname\"]=list(test_df[\"fname\"])\n",
    "\n",
    "\n",
    "cvmultidf=pd.DataFrame(data=labels_cv,columns=list(mlb_train.classes_))\n",
    "cvmultidf[\"fname\"]=list(cv_df[\"fname\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Preprocessed Spectrogram Images via ImageDataGenerator and adding augumnetation to train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:29:59.931432Z",
     "iopub.status.busy": "2020-09-30T16:29:59.930682Z",
     "iopub.status.idle": "2020-09-30T16:30:10.254702Z",
     "shell.execute_reply": "2020-09-30T16:30:10.254062Z"
    },
    "papermill": {
     "duration": 10.378857,
     "end_time": "2020-09-30T16:30:10.254827",
     "exception": false,
     "start_time": "2020-09-30T16:29:59.875970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19449 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "#We change the ids for the images in the csv files to reflect their new status as jpgs\n",
    "#https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "datagen=ImageDataGenerator(rescale=1./255.,zoom_range=[0.5,1.0],brightness_range=[0.8,1.4])\n",
    "\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=trainmultidf,\n",
    "    directory=\"../input/sc2-total-aug-noisy-data/Total Images bucket Noisy/Total Images bucket Noisy\",\n",
    "    x_col=\"fname\",\n",
    "    y_col=list(mlb_train.classes_),\n",
    "    subset=\"training\",\n",
    "    batch_size=64,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=\"raw\",\n",
    "    #color_mode=\"grayscale\",\n",
    "    target_size=(128,128))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:30:10.357995Z",
     "iopub.status.busy": "2020-09-30T16:30:10.356960Z",
     "iopub.status.idle": "2020-09-30T16:30:10.361153Z",
     "shell.execute_reply": "2020-09-30T16:30:10.360586Z"
    },
    "papermill": {
     "duration": 0.056509,
     "end_time": "2020-09-30T16:30:10.361246",
     "exception": false,
     "start_time": "2020-09-30T16:30:10.304737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19449"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:30:10.462243Z",
     "iopub.status.busy": "2020-09-30T16:30:10.461314Z",
     "iopub.status.idle": "2020-09-30T16:30:10.465542Z",
     "shell.execute_reply": "2020-09-30T16:30:10.465026Z"
    },
    "papermill": {
     "duration": 0.056297,
     "end_time": "2020-09-30T16:30:10.465658",
     "exception": false,
     "start_time": "2020-09-30T16:30:10.409361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4862, 81)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvmultidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:30:10.580207Z",
     "iopub.status.busy": "2020-09-30T16:30:10.579346Z",
     "iopub.status.idle": "2020-09-30T16:30:10.583319Z",
     "shell.execute_reply": "2020-09-30T16:30:10.583968Z"
    },
    "papermill": {
     "duration": 0.070975,
     "end_time": "2020-09-30T16:30:10.584094",
     "exception": false,
     "start_time": "2020-09-30T16:30:10.513119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accelerating_and_revving_and_vroom</th>\n",
       "      <th>Accordion</th>\n",
       "      <th>Acoustic_guitar</th>\n",
       "      <th>Applause</th>\n",
       "      <th>Bark</th>\n",
       "      <th>Bass_drum</th>\n",
       "      <th>Bass_guitar</th>\n",
       "      <th>Bathtub_(filling_or_washing)</th>\n",
       "      <th>Bicycle_bell</th>\n",
       "      <th>Burping_and_eructation</th>\n",
       "      <th>...</th>\n",
       "      <th>Traffic_noise_and_roadway_noise</th>\n",
       "      <th>Trickle_and_dribble</th>\n",
       "      <th>Walk_and_footsteps</th>\n",
       "      <th>Water_tap_and_faucet</th>\n",
       "      <th>Waves_and_surf</th>\n",
       "      <th>Whispering</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Yell</th>\n",
       "      <th>Zipper_(clothing)</th>\n",
       "      <th>fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>663172d7.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>eaa46c62.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7b5bcb5a_aug.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>deda9c42.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9b85cccc_aug.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accelerating_and_revving_and_vroom  Accordion  Acoustic_guitar  Applause  \\\n",
       "0                                   0          0                0         0   \n",
       "1                                   0          0                0         1   \n",
       "2                                   0          0                0         0   \n",
       "3                                   0          0                0         0   \n",
       "4                                   0          0                0         0   \n",
       "\n",
       "   Bark  Bass_drum  Bass_guitar  Bathtub_(filling_or_washing)  Bicycle_bell  \\\n",
       "0     0          0            0                             0             0   \n",
       "1     0          0            0                             0             0   \n",
       "2     0          0            0                             0             0   \n",
       "3     0          0            1                             0             0   \n",
       "4     0          0            0                             0             0   \n",
       "\n",
       "   Burping_and_eructation  ...  Traffic_noise_and_roadway_noise  \\\n",
       "0                       0  ...                                0   \n",
       "1                       0  ...                                0   \n",
       "2                       0  ...                                0   \n",
       "3                       0  ...                                0   \n",
       "4                       0  ...                                0   \n",
       "\n",
       "   Trickle_and_dribble  Walk_and_footsteps  Water_tap_and_faucet  \\\n",
       "0                    0                   0                     0   \n",
       "1                    0                   0                     0   \n",
       "2                    0                   0                     0   \n",
       "3                    0                   0                     0   \n",
       "4                    0                   0                     0   \n",
       "\n",
       "   Waves_and_surf  Whispering  Writing  Yell  Zipper_(clothing)  \\\n",
       "0               0           0        0     0                  0   \n",
       "1               0           0        0     0                  0   \n",
       "2               0           0        0     0                  0   \n",
       "3               0           0        0     0                  0   \n",
       "4               0           0        0     0                  0   \n",
       "\n",
       "              fname  \n",
       "0      663172d7.jpg  \n",
       "1      eaa46c62.jpg  \n",
       "2  7b5bcb5a_aug.jpg  \n",
       "3      deda9c42.jpg  \n",
       "4  9b85cccc_aug.jpg  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvmultidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:30:10.693047Z",
     "iopub.status.busy": "2020-09-30T16:30:10.691846Z",
     "iopub.status.idle": "2020-09-30T16:30:11.742814Z",
     "shell.execute_reply": "2020-09-30T16:30:11.743723Z"
    },
    "papermill": {
     "duration": 1.110436,
     "end_time": "2020-09-30T16:30:11.743873",
     "exception": false,
     "start_time": "2020-09-30T16:30:10.633437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4862 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "valid_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "valid_generator=valid_datagen.flow_from_dataframe(\n",
    "    dataframe=cvmultidf,\n",
    "    directory=\"../input/sc2-total-aug-noisy-data/Total Images bucket Noisy/Total Images bucket Noisy\",\n",
    "    x_col=\"fname\",\n",
    "    y_col=list(mlb_train.classes_),\n",
    "   # subset=\"validation\",\n",
    "    batch_size=64,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=\"raw\",\n",
    "    #color_mode=\"grayscale\",\n",
    "    target_size=(128,128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:30:11.853151Z",
     "iopub.status.busy": "2020-09-30T16:30:11.851973Z",
     "iopub.status.idle": "2020-09-30T16:30:13.293725Z",
     "shell.execute_reply": "2020-09-30T16:30:13.294965Z"
    },
    "papermill": {
     "duration": 1.500547,
     "end_time": "2020-09-30T16:30:13.295156",
     "exception": false,
     "start_time": "2020-09-30T16:30:11.794609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6078 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "    dataframe=testmultidf,\n",
    "    directory=\"../input/sc2-total-aug-noisy-data/Total Images bucket Noisy/Total Images bucket Noisy\",\n",
    "    x_col=\"fname\",\n",
    "    y_col=None,\n",
    "    batch_size=64,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "   # color_mode=\"grayscale\",\n",
    "    target_size=(128,128))\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Model and Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:30:13.477969Z",
     "iopub.status.busy": "2020-09-30T16:30:13.477027Z",
     "iopub.status.idle": "2020-09-30T16:30:13.551104Z",
     "shell.execute_reply": "2020-09-30T16:30:13.552147Z"
    },
    "papermill": {
     "duration": 0.167183,
     "end_time": "2020-09-30T16:30:13.552311",
     "exception": false,
     "start_time": "2020-09-30T16:30:13.385128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping \n",
    "from tensorflow.keras.layers import Dense, Flatten, LSTM, Conv2D, MaxPooling2D, Dropout, Activation, Input,BatchNormalization, AveragePooling2D,GlobalMaxPool2D,PReLU\n",
    "\n",
    "from tensorflow.keras.models import model_from_json  \n",
    "from tensorflow.keras.applications import DenseNet169\n",
    "\n",
    "from tensorflow.keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n",
    "                             EarlyStopping, ReduceLROnPlateau,CSVLogger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:30:13.727043Z",
     "iopub.status.busy": "2020-09-30T16:30:13.726131Z",
     "iopub.status.idle": "2020-09-30T16:30:22.806261Z",
     "shell.execute_reply": "2020-09-30T16:30:22.805188Z"
    },
    "papermill": {
     "duration": 9.172897,
     "end_time": "2020-09-30T16:30:22.806448",
     "exception": false,
     "start_time": "2020-09-30T16:30:13.633551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet169_weights_tf_dim_ordering_tf_kernels.h5\n",
      "58548224/58541896 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#last_layer = model.get_layer('avg_pool').output\n",
    "\n",
    "image_input = Input(shape=(128,128, 3))\n",
    "model = DenseNet169(input_tensor=image_input, include_top=True)\n",
    "last_layer = model.get_layer('avg_pool').output\n",
    "x= Flatten(name='flatten')(last_layer)\n",
    "#model=\n",
    "\n",
    "\n",
    "#output = Dense(80, activation='sigmoid', name='output_layer')(model.layers[-2].output)\n",
    "x= Dense(80)(x)\n",
    "output = Activation('sigmoid')(x)\n",
    "#out = Dense(num_classes, activation='softmax', name='output_layer')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:30:22.923080Z",
     "iopub.status.busy": "2020-09-30T16:30:22.918562Z",
     "iopub.status.idle": "2020-09-30T16:30:22.926750Z",
     "shell.execute_reply": "2020-09-30T16:30:22.926183Z"
    },
    "papermill": {
     "duration": 0.063332,
     "end_time": "2020-09-30T16:30:22.926875",
     "exception": false,
     "start_time": "2020-09-30T16:30:22.863543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7f4bdc5af710>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f4bdc54e490>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x7f4bdc54ecd0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f4bdc551250>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:30:23.036798Z",
     "iopub.status.busy": "2020-09-30T16:30:23.035660Z",
     "iopub.status.idle": "2020-09-30T16:30:23.040462Z",
     "shell.execute_reply": "2020-09-30T16:30:23.039951Z"
    },
    "papermill": {
     "duration": 0.061929,
     "end_time": "2020-09-30T16:30:23.040557",
     "exception": false,
     "start_time": "2020-09-30T16:30:22.978628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7f4bdc5af710>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7f4bdc54e490>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x7f4bdc54ecd0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7f4bdc551250>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:30:23.153791Z",
     "iopub.status.busy": "2020-09-30T16:30:23.152904Z",
     "iopub.status.idle": "2020-09-30T16:30:23.490695Z",
     "shell.execute_reply": "2020-09-30T16:30:23.489872Z"
    },
    "papermill": {
     "duration": 0.39696,
     "end_time": "2020-09-30T16:30:23.490889",
     "exception": false,
     "start_time": "2020-09-30T16:30:23.093929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 134, 134, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 64, 64, 64)   9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 64, 64, 64)   256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 64, 64, 64)   0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 66, 66, 64)   0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 32, 32, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 32, 32, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 32, 32, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 32, 32, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 32, 32, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 32, 32, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 32, 32, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 32, 32, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 32, 32, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 32, 32, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 32, 32, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 32, 32, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 32, 32, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 32, 32, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 32, 32, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 32, 32, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 32, 32, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 32, 32, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 32, 32, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 32, 32, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 32, 32, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 32, 32, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 32, 32, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 32, 32, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 32, 32, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 32, 32, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 32, 32, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 32, 32, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 32, 32, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 32, 32, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 32, 32, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 32, 32, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 32, 32, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 16, 16, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 16, 16, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 16, 16, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 16, 16, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 16, 16, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 16, 16, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 16, 16, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 16, 16, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 16, 16, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 16, 16, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 16, 16, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 16, 16, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 16, 16, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 16, 16, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 16, 16, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 16, 16, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 16, 16, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 16, 16, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 16, 16, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 16, 16, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 16, 16, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 16, 16, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 16, 16, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 16, 16, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 16, 16, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 16, 16, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 16, 16, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 16, 16, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 16, 16, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 16, 16, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 16, 16, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 16, 16, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 16, 16, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 16, 16, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 16, 16, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 16, 16, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 16, 16, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 16, 16, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 16, 16, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 16, 16, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 16, 16, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 16, 16, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 16, 16, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 16, 16, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 16, 16, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 16, 16, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 16, 16, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 16, 16, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 16, 16, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 16, 16, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 16, 16, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 16, 16, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 16, 16, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 16, 16, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 16, 16, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 16, 16, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 16, 16, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 16, 16, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 16, 16, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 16, 16, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 16, 16, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 8, 8, 256)    0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 8, 8, 256)    0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 8, 8, 128)    32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 8, 8, 128)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 8, 8, 288)    0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 8, 8, 288)    1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 8, 8, 288)    0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 8, 8, 128)    36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 8, 8, 128)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 8, 8, 320)    0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 8, 8, 320)    1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 8, 8, 320)    0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 8, 8, 128)    40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 8, 8, 128)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 8, 8, 352)    0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 8, 8, 352)    1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 8, 8, 352)    0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 8, 8, 128)    45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 8, 8, 128)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 8, 8, 384)    0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 8, 8, 384)    1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 8, 8, 384)    0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 8, 8, 128)    49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 8, 8, 128)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 8, 8, 416)    0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 8, 8, 416)    1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 8, 8, 416)    0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 8, 8, 128)    53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 8, 8, 128)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 8, 8, 448)    0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 8, 8, 448)    1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 8, 8, 448)    0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 8, 8, 128)    57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 8, 8, 128)    0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 8, 8, 480)    0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 8, 8, 480)    1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 8, 8, 480)    0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 8, 8, 128)    61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 8, 8, 128)    0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 8, 8, 512)    0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 8, 8, 512)    2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 8, 8, 512)    0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 8, 8, 128)    65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 8, 8, 128)    0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 8, 8, 544)    0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 8, 8, 544)    2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 8, 8, 544)    0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 8, 8, 128)    69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 8, 8, 576)    0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 8, 8, 576)    2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 8, 8, 576)    0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 8, 8, 128)    73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 8, 8, 608)    0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 8, 8, 608)    2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 8, 8, 608)    0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 8, 8, 128)    77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 8, 8, 640)    0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 8, 8, 640)    2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 8, 8, 640)    0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 8, 8, 128)    81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 8, 8, 672)    0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 8, 8, 672)    2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 8, 8, 672)    0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 8, 8, 128)    86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 8, 8, 704)    0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 8, 8, 704)    2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 8, 8, 704)    0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 8, 8, 128)    90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 8, 8, 736)    0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 8, 8, 736)    2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 8, 8, 736)    0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 8, 8, 128)    94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 8, 8, 768)    0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 8, 8, 768)    3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 8, 8, 768)    0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 8, 8, 128)    98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 8, 8, 800)    0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 8, 8, 800)    3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 8, 8, 800)    0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 8, 8, 128)    102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 8, 8, 832)    0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 8, 8, 832)    3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 8, 8, 832)    0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 8, 8, 128)    106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 8, 8, 864)    0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 8, 8, 864)    3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 8, 8, 864)    0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 8, 8, 128)    110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 8, 8, 896)    0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 8, 8, 896)    3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 8, 8, 896)    0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 8, 8, 128)    114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 8, 8, 928)    0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 8, 8, 928)    3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 8, 8, 928)    0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 8, 8, 128)    118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 8, 8, 960)    0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 8, 8, 960)    3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 8, 8, 960)    0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 8, 8, 128)    122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 8, 8, 992)    0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 8, 8, 992)    3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 8, 8, 992)    0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 8, 8, 128)    126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 8, 8, 1024)   0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_bn (BatchNormal (None, 8, 8, 1024)   4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_relu (Activatio (None, 8, 8, 1024)   0           conv4_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_conv (Conv2D)   (None, 8, 8, 128)    131072      conv4_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_concat (Concatena (None, 8, 8, 1056)   0           conv4_block24_concat[0][0]       \n",
      "                                                                 conv4_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_bn (BatchNormal (None, 8, 8, 1056)   4224        conv4_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_relu (Activatio (None, 8, 8, 1056)   0           conv4_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_conv (Conv2D)   (None, 8, 8, 128)    135168      conv4_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_concat (Concatena (None, 8, 8, 1088)   0           conv4_block25_concat[0][0]       \n",
      "                                                                 conv4_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_bn (BatchNormal (None, 8, 8, 1088)   4352        conv4_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_relu (Activatio (None, 8, 8, 1088)   0           conv4_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_conv (Conv2D)   (None, 8, 8, 128)    139264      conv4_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_concat (Concatena (None, 8, 8, 1120)   0           conv4_block26_concat[0][0]       \n",
      "                                                                 conv4_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_bn (BatchNormal (None, 8, 8, 1120)   4480        conv4_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_relu (Activatio (None, 8, 8, 1120)   0           conv4_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_conv (Conv2D)   (None, 8, 8, 128)    143360      conv4_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_concat (Concatena (None, 8, 8, 1152)   0           conv4_block27_concat[0][0]       \n",
      "                                                                 conv4_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_bn (BatchNormal (None, 8, 8, 1152)   4608        conv4_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_relu (Activatio (None, 8, 8, 1152)   0           conv4_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_conv (Conv2D)   (None, 8, 8, 128)    147456      conv4_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_concat (Concatena (None, 8, 8, 1184)   0           conv4_block28_concat[0][0]       \n",
      "                                                                 conv4_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_bn (BatchNormal (None, 8, 8, 1184)   4736        conv4_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_relu (Activatio (None, 8, 8, 1184)   0           conv4_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_conv (Conv2D)   (None, 8, 8, 128)    151552      conv4_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_concat (Concatena (None, 8, 8, 1216)   0           conv4_block29_concat[0][0]       \n",
      "                                                                 conv4_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_bn (BatchNormal (None, 8, 8, 1216)   4864        conv4_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_relu (Activatio (None, 8, 8, 1216)   0           conv4_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_conv (Conv2D)   (None, 8, 8, 128)    155648      conv4_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_concat (Concatena (None, 8, 8, 1248)   0           conv4_block30_concat[0][0]       \n",
      "                                                                 conv4_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_bn (BatchNormal (None, 8, 8, 1248)   4992        conv4_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_relu (Activatio (None, 8, 8, 1248)   0           conv4_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_conv (Conv2D)   (None, 8, 8, 128)    159744      conv4_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_concat (Concatena (None, 8, 8, 1280)   0           conv4_block31_concat[0][0]       \n",
      "                                                                 conv4_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 8, 8, 1280)   5120        conv4_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 8, 8, 1280)   0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 8, 8, 640)    819200      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 4, 4, 640)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 4, 640)    2560        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 4, 4, 640)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 128)    81920       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 4, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 4, 4, 672)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 4, 4, 672)    2688        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 4, 4, 672)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 128)    86016       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 4, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 4, 4, 704)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 4, 4, 704)    2816        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 4, 4, 704)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 128)    90112       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 4, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 4, 4, 736)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 4, 4, 736)    2944        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 4, 4, 736)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 4, 4, 128)    94208       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 4, 4, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 4, 4, 768)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 4, 4, 768)    3072        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 4, 4, 768)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 4, 4, 128)    98304       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 4, 4, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 4, 4, 800)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 4, 4, 800)    3200        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 4, 4, 800)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 4, 4, 128)    102400      conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 4, 4, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 4, 4, 832)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 4, 4, 832)    3328        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 4, 4, 832)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 4, 4, 128)    106496      conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 4, 4, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 4, 4, 864)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 4, 4, 864)    3456        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 4, 4, 864)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 4, 4, 128)    110592      conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 4, 4, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 4, 4, 896)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 4, 4, 896)    3584        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 4, 4, 896)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 4, 4, 128)    114688      conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 4, 4, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 4, 4, 928)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 4, 4, 928)    3712        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 4, 4, 928)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 4, 4, 128)    118784      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 4, 4, 960)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 4, 4, 960)    3840        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 4, 4, 960)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 4, 4, 128)    122880      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 4, 4, 992)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 4, 4, 992)    3968        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 4, 4, 992)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 4, 4, 128)    126976      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 4, 4, 1024)   0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 4, 4, 1024)   4096        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 4, 4, 1024)   0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 4, 4, 128)    131072      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 4, 4, 1056)   0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 4, 4, 1056)   4224        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 4, 4, 1056)   0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 4, 4, 128)    135168      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 4, 4, 1088)   0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 4, 4, 1088)   4352        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 4, 4, 1088)   0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 4, 4, 128)    139264      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 4, 4, 1120)   0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 4, 4, 1120)   4480        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 4, 4, 1120)   0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 4, 4, 128)    143360      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 4, 4, 1152)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_bn (BatchNormal (None, 4, 4, 1152)   4608        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_relu (Activatio (None, 4, 4, 1152)   0           conv5_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_conv (Conv2D)   (None, 4, 4, 128)    147456      conv5_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_concat (Concatena (None, 4, 4, 1184)   0           conv5_block16_concat[0][0]       \n",
      "                                                                 conv5_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_bn (BatchNormal (None, 4, 4, 1184)   4736        conv5_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_relu (Activatio (None, 4, 4, 1184)   0           conv5_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_conv (Conv2D)   (None, 4, 4, 128)    151552      conv5_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_concat (Concatena (None, 4, 4, 1216)   0           conv5_block17_concat[0][0]       \n",
      "                                                                 conv5_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_bn (BatchNormal (None, 4, 4, 1216)   4864        conv5_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_relu (Activatio (None, 4, 4, 1216)   0           conv5_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_conv (Conv2D)   (None, 4, 4, 128)    155648      conv5_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_concat (Concatena (None, 4, 4, 1248)   0           conv5_block18_concat[0][0]       \n",
      "                                                                 conv5_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_bn (BatchNormal (None, 4, 4, 1248)   4992        conv5_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_relu (Activatio (None, 4, 4, 1248)   0           conv5_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_conv (Conv2D)   (None, 4, 4, 128)    159744      conv5_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_concat (Concatena (None, 4, 4, 1280)   0           conv5_block19_concat[0][0]       \n",
      "                                                                 conv5_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_bn (BatchNormal (None, 4, 4, 1280)   5120        conv5_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_relu (Activatio (None, 4, 4, 1280)   0           conv5_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_conv (Conv2D)   (None, 4, 4, 128)    163840      conv5_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_concat (Concatena (None, 4, 4, 1312)   0           conv5_block20_concat[0][0]       \n",
      "                                                                 conv5_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_bn (BatchNormal (None, 4, 4, 1312)   5248        conv5_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_relu (Activatio (None, 4, 4, 1312)   0           conv5_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_conv (Conv2D)   (None, 4, 4, 128)    167936      conv5_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_concat (Concatena (None, 4, 4, 1344)   0           conv5_block21_concat[0][0]       \n",
      "                                                                 conv5_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_bn (BatchNormal (None, 4, 4, 1344)   5376        conv5_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_relu (Activatio (None, 4, 4, 1344)   0           conv5_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_conv (Conv2D)   (None, 4, 4, 128)    172032      conv5_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_concat (Concatena (None, 4, 4, 1376)   0           conv5_block22_concat[0][0]       \n",
      "                                                                 conv5_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_bn (BatchNormal (None, 4, 4, 1376)   5504        conv5_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_relu (Activatio (None, 4, 4, 1376)   0           conv5_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_conv (Conv2D)   (None, 4, 4, 128)    176128      conv5_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_concat (Concatena (None, 4, 4, 1408)   0           conv5_block23_concat[0][0]       \n",
      "                                                                 conv5_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_bn (BatchNormal (None, 4, 4, 1408)   5632        conv5_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_relu (Activatio (None, 4, 4, 1408)   0           conv5_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_conv (Conv2D)   (None, 4, 4, 128)    180224      conv5_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_concat (Concatena (None, 4, 4, 1440)   0           conv5_block24_concat[0][0]       \n",
      "                                                                 conv5_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_bn (BatchNormal (None, 4, 4, 1440)   5760        conv5_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_relu (Activatio (None, 4, 4, 1440)   0           conv5_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_conv (Conv2D)   (None, 4, 4, 128)    184320      conv5_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_concat (Concatena (None, 4, 4, 1472)   0           conv5_block25_concat[0][0]       \n",
      "                                                                 conv5_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_bn (BatchNormal (None, 4, 4, 1472)   5888        conv5_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_relu (Activatio (None, 4, 4, 1472)   0           conv5_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_conv (Conv2D)   (None, 4, 4, 128)    188416      conv5_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_concat (Concatena (None, 4, 4, 1504)   0           conv5_block26_concat[0][0]       \n",
      "                                                                 conv5_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_bn (BatchNormal (None, 4, 4, 1504)   6016        conv5_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_relu (Activatio (None, 4, 4, 1504)   0           conv5_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_conv (Conv2D)   (None, 4, 4, 128)    192512      conv5_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_concat (Concatena (None, 4, 4, 1536)   0           conv5_block27_concat[0][0]       \n",
      "                                                                 conv5_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_bn (BatchNormal (None, 4, 4, 1536)   6144        conv5_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_relu (Activatio (None, 4, 4, 1536)   0           conv5_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_conv (Conv2D)   (None, 4, 4, 128)    196608      conv5_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_concat (Concatena (None, 4, 4, 1568)   0           conv5_block28_concat[0][0]       \n",
      "                                                                 conv5_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_bn (BatchNormal (None, 4, 4, 1568)   6272        conv5_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_relu (Activatio (None, 4, 4, 1568)   0           conv5_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_conv (Conv2D)   (None, 4, 4, 128)    200704      conv5_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_concat (Concatena (None, 4, 4, 1600)   0           conv5_block29_concat[0][0]       \n",
      "                                                                 conv5_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_bn (BatchNormal (None, 4, 4, 1600)   6400        conv5_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_relu (Activatio (None, 4, 4, 1600)   0           conv5_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_conv (Conv2D)   (None, 4, 4, 128)    204800      conv5_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_concat (Concatena (None, 4, 4, 1632)   0           conv5_block30_concat[0][0]       \n",
      "                                                                 conv5_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_bn (BatchNormal (None, 4, 4, 1632)   6528        conv5_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_relu (Activatio (None, 4, 4, 1632)   0           conv5_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_conv (Conv2D)   (None, 4, 4, 128)    208896      conv5_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_concat (Concatena (None, 4, 4, 1664)   0           conv5_block31_concat[0][0]       \n",
      "                                                                 conv5_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 4, 4, 1664)   6656        conv5_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 4, 4, 1664)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1664)         0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1664)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 80)           133200      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 80)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 12,776,080\n",
      "Trainable params: 12,617,680\n",
      "Non-trainable params: 158,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_densenet169_model = Model(inputs=image_input,outputs= output)\n",
    "custom_densenet169_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:30:23.643038Z",
     "iopub.status.busy": "2020-09-30T16:30:23.642140Z",
     "iopub.status.idle": "2020-09-30T16:30:23.644907Z",
     "shell.execute_reply": "2020-09-30T16:30:23.644282Z"
    },
    "papermill": {
     "duration": 0.061491,
     "end_time": "2020-09-30T16:30:23.645001",
     "exception": false,
     "start_time": "2020-09-30T16:30:23.583510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from tensorflow.keras.utils import plot_model\n",
    "#plot_model(custom_densenet169_model, 'model_resnet50.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:30:23.778079Z",
     "iopub.status.busy": "2020-09-30T16:30:23.767819Z",
     "iopub.status.idle": "2020-09-30T16:30:23.793957Z",
     "shell.execute_reply": "2020-09-30T16:30:23.793300Z"
    },
    "papermill": {
     "duration": 0.093494,
     "end_time": "2020-09-30T16:30:23.794057",
     "exception": false,
     "start_time": "2020-09-30T16:30:23.700563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr=0.0009)#tf.keras.optimizers.RMSprop(lr=0.3, decay=1e-6) \n",
    "#tf.keras.optimizers.Adam(lr=0.001)#RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "custom_densenet169_model.compile(loss=tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.SUM),#,label_smoothing=0.7#'categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "               metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:30:23.910487Z",
     "iopub.status.busy": "2020-09-30T16:30:23.909784Z",
     "iopub.status.idle": "2020-09-30T16:30:23.913937Z",
     "shell.execute_reply": "2020-09-30T16:30:23.913455Z"
    },
    "papermill": {
     "duration": 0.063934,
     "end_time": "2020-09-30T16:30:23.914025",
     "exception": false,
     "start_time": "2020-09-30T16:30:23.850091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Fitting keras model, no test gen for now\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "#STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:30:24.031860Z",
     "iopub.status.busy": "2020-09-30T16:30:24.031038Z",
     "iopub.status.idle": "2020-09-30T16:30:24.034732Z",
     "shell.execute_reply": "2020-09-30T16:30:24.035197Z"
    },
    "papermill": {
     "duration": 0.065502,
     "end_time": "2020-09-30T16:30:24.035321",
     "exception": false,
     "start_time": "2020-09-30T16:30:23.969819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:30:24.245384Z",
     "iopub.status.busy": "2020-09-30T16:30:24.244454Z",
     "iopub.status.idle": "2020-09-30T16:30:24.249215Z",
     "shell.execute_reply": "2020-09-30T16:30:24.250383Z"
    },
    "papermill": {
     "duration": 0.152359,
     "end_time": "2020-09-30T16:30:24.250570",
     "exception": false,
     "start_time": "2020-09-30T16:30:24.098211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# simple early stopping\n",
    "#earlyStop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100,)\n",
    "#https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "\n",
    "\n",
    "#model_checkpoint = ModelCheckpoint('weights_cnn_lstm.best.hdf5', monitor='val_categorical_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "#filepath=\"weights-improvement-{epoch:02d}-{val_categorical_accuracy:.2f}.hdf5\"\n",
    "\n",
    "\n",
    "csv_logger = CSVLogger(filename='../working/training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.6,\n",
    "                              patience=6, min_lr=0,verbose=1)\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\"NoisyTotal.best_weights-128.hdf5\", monitor='val_categorical_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "# fit model\n",
    "\n",
    "#es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20, min_delta=0.001 )\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', mode='max', verbose=1, patience=30, min_delta=0.001 )\n",
    "\n",
    "callbacks_list = [model_checkpoint, csv_logger, reduceLROnPlat,es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:30:24.442443Z",
     "iopub.status.busy": "2020-09-30T16:30:24.441301Z",
     "iopub.status.idle": "2020-09-30T16:30:24.444055Z",
     "shell.execute_reply": "2020-09-30T16:30:24.443292Z"
    },
    "papermill": {
     "duration": 0.099721,
     "end_time": "2020-09-30T16:30:24.444195",
     "exception": false,
     "start_time": "2020-09-30T16:30:24.344474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#custom_densenet169_model.load_weights(\"../input/sc2weights/total.best_weights.hdf5\")\n",
    "#custom_densenet169_model.load_weights(\"../input/sc2weights/total.best_weights_iter2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T16:30:24.634635Z",
     "iopub.status.busy": "2020-09-30T16:30:24.633702Z",
     "iopub.status.idle": "2020-09-30T23:12:37.205064Z",
     "shell.execute_reply": "2020-09-30T23:12:37.206098Z"
    },
    "papermill": {
     "duration": 24132.675202,
     "end_time": "2020-09-30T23:12:37.206244",
     "exception": false,
     "start_time": "2020-09-30T16:30:24.531042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 4.7804 - categorical_accuracy: 0.1182\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.14062, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 187s 618ms/step - loss: 4.7804 - categorical_accuracy: 0.1182 - val_loss: 4.2785 - val_categorical_accuracy: 0.1406\n",
      "Epoch 2/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 3.8033 - categorical_accuracy: 0.2054\n",
      "Epoch 00002: val_categorical_accuracy did not improve from 0.14062\n",
      "303/303 [==============================] - 152s 501ms/step - loss: 3.8033 - categorical_accuracy: 0.2054 - val_loss: 4.2956 - val_categorical_accuracy: 0.1381\n",
      "Epoch 3/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 3.5680 - categorical_accuracy: 0.2557\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.14062 to 0.18917, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 156s 516ms/step - loss: 3.5680 - categorical_accuracy: 0.2557 - val_loss: 4.0529 - val_categorical_accuracy: 0.1892\n",
      "Epoch 4/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 3.3942 - categorical_accuracy: 0.2904\n",
      "Epoch 00004: val_categorical_accuracy improved from 0.18917 to 0.20208, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 149s 492ms/step - loss: 3.3942 - categorical_accuracy: 0.2904 - val_loss: 3.9733 - val_categorical_accuracy: 0.2021\n",
      "Epoch 5/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 3.2458 - categorical_accuracy: 0.3211\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.20208 to 0.21958, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 153s 505ms/step - loss: 3.2458 - categorical_accuracy: 0.3211 - val_loss: 3.9136 - val_categorical_accuracy: 0.2196\n",
      "Epoch 6/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 3.1037 - categorical_accuracy: 0.3442\n",
      "Epoch 00006: val_categorical_accuracy improved from 0.21958 to 0.22688, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 154s 508ms/step - loss: 3.1037 - categorical_accuracy: 0.3442 - val_loss: 3.8972 - val_categorical_accuracy: 0.2269\n",
      "Epoch 7/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 2.9666 - categorical_accuracy: 0.3714\n",
      "Epoch 00007: val_categorical_accuracy improved from 0.22688 to 0.24729, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 152s 500ms/step - loss: 2.9666 - categorical_accuracy: 0.3714 - val_loss: 3.7981 - val_categorical_accuracy: 0.2473\n",
      "Epoch 8/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 2.8136 - categorical_accuracy: 0.4022\n",
      "Epoch 00008: val_categorical_accuracy did not improve from 0.24729\n",
      "303/303 [==============================] - 150s 496ms/step - loss: 2.8136 - categorical_accuracy: 0.4022 - val_loss: 4.0655 - val_categorical_accuracy: 0.2344\n",
      "Epoch 9/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 2.6471 - categorical_accuracy: 0.4350\n",
      "Epoch 00009: val_categorical_accuracy improved from 0.24729 to 0.24875, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 155s 510ms/step - loss: 2.6471 - categorical_accuracy: 0.4350 - val_loss: 4.0086 - val_categorical_accuracy: 0.2488\n",
      "Epoch 10/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 2.4884 - categorical_accuracy: 0.4653\n",
      "Epoch 00010: val_categorical_accuracy improved from 0.24875 to 0.26500, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 156s 516ms/step - loss: 2.4884 - categorical_accuracy: 0.4653 - val_loss: 3.7674 - val_categorical_accuracy: 0.2650\n",
      "Epoch 11/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 2.3078 - categorical_accuracy: 0.5052\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.26500\n",
      "303/303 [==============================] - 152s 502ms/step - loss: 2.3078 - categorical_accuracy: 0.5052 - val_loss: 4.1634 - val_categorical_accuracy: 0.2373\n",
      "Epoch 12/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 2.1167 - categorical_accuracy: 0.5486\n",
      "Epoch 00012: val_categorical_accuracy improved from 0.26500 to 0.30875, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 158s 522ms/step - loss: 2.1167 - categorical_accuracy: 0.5486 - val_loss: 3.6743 - val_categorical_accuracy: 0.3088\n",
      "Epoch 13/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.9088 - categorical_accuracy: 0.5939\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.30875\n",
      "303/303 [==============================] - 154s 509ms/step - loss: 1.9088 - categorical_accuracy: 0.5939 - val_loss: 4.9174 - val_categorical_accuracy: 0.2129\n",
      "Epoch 14/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.6956 - categorical_accuracy: 0.6331\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.30875\n",
      "303/303 [==============================] - 158s 522ms/step - loss: 1.6956 - categorical_accuracy: 0.6331 - val_loss: 4.1254 - val_categorical_accuracy: 0.3052\n",
      "Epoch 15/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.5319 - categorical_accuracy: 0.6681\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.30875\n",
      "303/303 [==============================] - 167s 551ms/step - loss: 1.5319 - categorical_accuracy: 0.6681 - val_loss: 4.2492 - val_categorical_accuracy: 0.3073\n",
      "Epoch 16/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.3618 - categorical_accuracy: 0.7084\n",
      "Epoch 00016: val_categorical_accuracy did not improve from 0.30875\n",
      "303/303 [==============================] - 167s 551ms/step - loss: 1.3618 - categorical_accuracy: 0.7084 - val_loss: 4.8482 - val_categorical_accuracy: 0.2425\n",
      "Epoch 17/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.1926 - categorical_accuracy: 0.7403\n",
      "Epoch 00017: val_categorical_accuracy improved from 0.30875 to 0.36125, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 173s 569ms/step - loss: 1.1926 - categorical_accuracy: 0.7403 - val_loss: 3.8199 - val_categorical_accuracy: 0.3613\n",
      "Epoch 18/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.0489 - categorical_accuracy: 0.7701\n",
      "Epoch 00018: val_categorical_accuracy did not improve from 0.36125\n",
      "303/303 [==============================] - 167s 551ms/step - loss: 1.0489 - categorical_accuracy: 0.7701 - val_loss: 4.6660 - val_categorical_accuracy: 0.2877\n",
      "Epoch 19/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.9131 - categorical_accuracy: 0.7926\n",
      "Epoch 00019: val_categorical_accuracy did not improve from 0.36125\n",
      "303/303 [==============================] - 166s 547ms/step - loss: 0.9131 - categorical_accuracy: 0.7926 - val_loss: 4.1358 - val_categorical_accuracy: 0.3567\n",
      "Epoch 20/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.8172 - categorical_accuracy: 0.8146\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.36125\n",
      "303/303 [==============================] - 165s 544ms/step - loss: 0.8172 - categorical_accuracy: 0.8146 - val_loss: 5.1052 - val_categorical_accuracy: 0.2923\n",
      "Epoch 21/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.7355 - categorical_accuracy: 0.8270\n",
      "Epoch 00021: val_categorical_accuracy did not improve from 0.36125\n",
      "303/303 [==============================] - 166s 546ms/step - loss: 0.7355 - categorical_accuracy: 0.8270 - val_loss: 4.3492 - val_categorical_accuracy: 0.3467\n",
      "Epoch 22/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.6639 - categorical_accuracy: 0.8427\n",
      "Epoch 00022: val_categorical_accuracy did not improve from 0.36125\n",
      "303/303 [==============================] - 165s 545ms/step - loss: 0.6639 - categorical_accuracy: 0.8427 - val_loss: 4.4231 - val_categorical_accuracy: 0.3444\n",
      "Epoch 23/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.6173 - categorical_accuracy: 0.8453\n",
      "Epoch 00023: val_categorical_accuracy did not improve from 0.36125\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0005399999907240271.\n",
      "303/303 [==============================] - 164s 542ms/step - loss: 0.6173 - categorical_accuracy: 0.8453 - val_loss: 4.8948 - val_categorical_accuracy: 0.3371\n",
      "Epoch 24/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3516 - categorical_accuracy: 0.8866\n",
      "Epoch 00024: val_categorical_accuracy improved from 0.36125 to 0.46458, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 166s 547ms/step - loss: 0.3516 - categorical_accuracy: 0.8866 - val_loss: 3.6986 - val_categorical_accuracy: 0.4646\n",
      "Epoch 25/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.2239 - categorical_accuracy: 0.8993\n",
      "Epoch 00025: val_categorical_accuracy did not improve from 0.46458\n",
      "303/303 [==============================] - 166s 549ms/step - loss: 0.2239 - categorical_accuracy: 0.8993 - val_loss: 4.1613 - val_categorical_accuracy: 0.4154\n",
      "Epoch 26/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.1930 - categorical_accuracy: 0.9024\n",
      "Epoch 00026: val_categorical_accuracy did not improve from 0.46458\n",
      "303/303 [==============================] - 171s 563ms/step - loss: 0.1930 - categorical_accuracy: 0.9024 - val_loss: 3.8920 - val_categorical_accuracy: 0.4615\n",
      "Epoch 27/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.1697 - categorical_accuracy: 0.9037\n",
      "Epoch 00027: val_categorical_accuracy did not improve from 0.46458\n",
      "303/303 [==============================] - 174s 575ms/step - loss: 0.1697 - categorical_accuracy: 0.9037 - val_loss: 3.9875 - val_categorical_accuracy: 0.4644\n",
      "Epoch 28/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.1660 - categorical_accuracy: 0.9033\n",
      "Epoch 00028: val_categorical_accuracy did not improve from 0.46458\n",
      "303/303 [==============================] - 175s 578ms/step - loss: 0.1660 - categorical_accuracy: 0.9033 - val_loss: 4.7654 - val_categorical_accuracy: 0.4044\n",
      "Epoch 29/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.1889 - categorical_accuracy: 0.8994\n",
      "Epoch 00029: val_categorical_accuracy did not improve from 0.46458\n",
      "303/303 [==============================] - 178s 588ms/step - loss: 0.1889 - categorical_accuracy: 0.8994 - val_loss: 4.2860 - val_categorical_accuracy: 0.4498\n",
      "Epoch 30/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.2112 - categorical_accuracy: 0.8990\n",
      "Epoch 00030: val_categorical_accuracy did not improve from 0.46458\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.00032399998744949695.\n",
      "303/303 [==============================] - 176s 581ms/step - loss: 0.2112 - categorical_accuracy: 0.8990 - val_loss: 4.5653 - val_categorical_accuracy: 0.4258\n",
      "Epoch 31/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.1210 - categorical_accuracy: 0.9052\n",
      "Epoch 00031: val_categorical_accuracy improved from 0.46458 to 0.47917, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 175s 579ms/step - loss: 0.1210 - categorical_accuracy: 0.9052 - val_loss: 4.0908 - val_categorical_accuracy: 0.4792\n",
      "Epoch 32/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0797 - categorical_accuracy: 0.9119\n",
      "Epoch 00032: val_categorical_accuracy did not improve from 0.47917\n",
      "303/303 [==============================] - 171s 563ms/step - loss: 0.0797 - categorical_accuracy: 0.9119 - val_loss: 4.5050 - val_categorical_accuracy: 0.4421\n",
      "Epoch 33/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0736 - categorical_accuracy: 0.9110\n",
      "Epoch 00033: val_categorical_accuracy improved from 0.47917 to 0.49187, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 177s 585ms/step - loss: 0.0736 - categorical_accuracy: 0.9110 - val_loss: 4.1974 - val_categorical_accuracy: 0.4919\n",
      "Epoch 34/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0642 - categorical_accuracy: 0.9123\n",
      "Epoch 00034: val_categorical_accuracy did not improve from 0.49187\n",
      "303/303 [==============================] - 172s 567ms/step - loss: 0.0642 - categorical_accuracy: 0.9123 - val_loss: 4.3199 - val_categorical_accuracy: 0.4754\n",
      "Epoch 35/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0596 - categorical_accuracy: 0.9105\n",
      "Epoch 00035: val_categorical_accuracy did not improve from 0.49187\n",
      "303/303 [==============================] - 175s 578ms/step - loss: 0.0596 - categorical_accuracy: 0.9105 - val_loss: 4.3660 - val_categorical_accuracy: 0.4842\n",
      "Epoch 36/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0658 - categorical_accuracy: 0.9085\n",
      "Epoch 00036: val_categorical_accuracy did not improve from 0.49187\n",
      "303/303 [==============================] - 172s 568ms/step - loss: 0.0658 - categorical_accuracy: 0.9085 - val_loss: 4.4810 - val_categorical_accuracy: 0.4829\n",
      "Epoch 37/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0711 - categorical_accuracy: 0.9092\n",
      "Epoch 00037: val_categorical_accuracy did not improve from 0.49187\n",
      "303/303 [==============================] - 176s 580ms/step - loss: 0.0711 - categorical_accuracy: 0.9092 - val_loss: 4.6319 - val_categorical_accuracy: 0.4690\n",
      "Epoch 38/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0805 - categorical_accuracy: 0.9098\n",
      "Epoch 00038: val_categorical_accuracy did not improve from 0.49187\n",
      "303/303 [==============================] - 174s 573ms/step - loss: 0.0805 - categorical_accuracy: 0.9098 - val_loss: 5.2954 - val_categorical_accuracy: 0.3983\n",
      "Epoch 39/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0762 - categorical_accuracy: 0.9121\n",
      "Epoch 00039: val_categorical_accuracy did not improve from 0.49187\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.00019439999596215785.\n",
      "303/303 [==============================] - 177s 583ms/step - loss: 0.0762 - categorical_accuracy: 0.9121 - val_loss: 4.8214 - val_categorical_accuracy: 0.4663\n",
      "Epoch 40/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0489 - categorical_accuracy: 0.9128\n",
      "Epoch 00040: val_categorical_accuracy improved from 0.49187 to 0.49708, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 177s 583ms/step - loss: 0.0489 - categorical_accuracy: 0.9128 - val_loss: 4.4299 - val_categorical_accuracy: 0.4971\n",
      "Epoch 41/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0353 - categorical_accuracy: 0.9142\n",
      "Epoch 00041: val_categorical_accuracy did not improve from 0.49708\n",
      "303/303 [==============================] - 177s 583ms/step - loss: 0.0353 - categorical_accuracy: 0.9142 - val_loss: 4.7320 - val_categorical_accuracy: 0.4690\n",
      "Epoch 42/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0298 - categorical_accuracy: 0.9124\n",
      "Epoch 00042: val_categorical_accuracy did not improve from 0.49708\n",
      "303/303 [==============================] - 172s 569ms/step - loss: 0.0298 - categorical_accuracy: 0.9124 - val_loss: 4.5896 - val_categorical_accuracy: 0.4881\n",
      "Epoch 43/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0287 - categorical_accuracy: 0.9118\n",
      "Epoch 00043: val_categorical_accuracy improved from 0.49708 to 0.51208, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 180s 595ms/step - loss: 0.0287 - categorical_accuracy: 0.9118 - val_loss: 4.5559 - val_categorical_accuracy: 0.5121\n",
      "Epoch 44/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0283 - categorical_accuracy: 0.9118\n",
      "Epoch 00044: val_categorical_accuracy did not improve from 0.51208\n",
      "303/303 [==============================] - 175s 577ms/step - loss: 0.0283 - categorical_accuracy: 0.9118 - val_loss: 4.5854 - val_categorical_accuracy: 0.5088\n",
      "Epoch 45/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0281 - categorical_accuracy: 0.9134\n",
      "Epoch 00045: val_categorical_accuracy did not improve from 0.51208\n",
      "303/303 [==============================] - 179s 590ms/step - loss: 0.0281 - categorical_accuracy: 0.9134 - val_loss: 4.6449 - val_categorical_accuracy: 0.4979\n",
      "Epoch 46/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0241 - categorical_accuracy: 0.9123\n",
      "Epoch 00046: val_categorical_accuracy did not improve from 0.51208\n",
      "303/303 [==============================] - 174s 574ms/step - loss: 0.0241 - categorical_accuracy: 0.9123 - val_loss: 5.1796 - val_categorical_accuracy: 0.4442\n",
      "Epoch 47/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0264 - categorical_accuracy: 0.9106\n",
      "Epoch 00047: val_categorical_accuracy did not improve from 0.51208\n",
      "303/303 [==============================] - 179s 589ms/step - loss: 0.0264 - categorical_accuracy: 0.9106 - val_loss: 4.7660 - val_categorical_accuracy: 0.4929\n",
      "Epoch 48/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0263 - categorical_accuracy: 0.9100\n",
      "Epoch 00048: val_categorical_accuracy did not improve from 0.51208\n",
      "303/303 [==============================] - 174s 574ms/step - loss: 0.0263 - categorical_accuracy: 0.9100 - val_loss: 4.7752 - val_categorical_accuracy: 0.5075\n",
      "Epoch 49/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0270 - categorical_accuracy: 0.9111\n",
      "Epoch 00049: val_categorical_accuracy did not improve from 0.51208\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0001166399975772947.\n",
      "303/303 [==============================] - 180s 593ms/step - loss: 0.0270 - categorical_accuracy: 0.9111 - val_loss: 4.8202 - val_categorical_accuracy: 0.5102\n",
      "Epoch 50/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0212 - categorical_accuracy: 0.9126\n",
      "Epoch 00050: val_categorical_accuracy improved from 0.51208 to 0.51979, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 180s 593ms/step - loss: 0.0212 - categorical_accuracy: 0.9126 - val_loss: 4.5951 - val_categorical_accuracy: 0.5198\n",
      "Epoch 51/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0162 - categorical_accuracy: 0.9113\n",
      "Epoch 00051: val_categorical_accuracy did not improve from 0.51979\n",
      "303/303 [==============================] - 181s 596ms/step - loss: 0.0162 - categorical_accuracy: 0.9113 - val_loss: 4.7215 - val_categorical_accuracy: 0.5194\n",
      "Epoch 52/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0162 - categorical_accuracy: 0.9130\n",
      "Epoch 00052: val_categorical_accuracy did not improve from 0.51979\n",
      "303/303 [==============================] - 178s 587ms/step - loss: 0.0162 - categorical_accuracy: 0.9130 - val_loss: 4.7458 - val_categorical_accuracy: 0.5088\n",
      "Epoch 53/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0143 - categorical_accuracy: 0.9135\n",
      "Epoch 00053: val_categorical_accuracy did not improve from 0.51979\n",
      "303/303 [==============================] - 180s 596ms/step - loss: 0.0143 - categorical_accuracy: 0.9135 - val_loss: 4.7770 - val_categorical_accuracy: 0.5144\n",
      "Epoch 54/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0123 - categorical_accuracy: 0.9126\n",
      "Epoch 00054: val_categorical_accuracy did not improve from 0.51979\n",
      "303/303 [==============================] - 178s 588ms/step - loss: 0.0123 - categorical_accuracy: 0.9126 - val_loss: 4.9844 - val_categorical_accuracy: 0.5090\n",
      "Epoch 55/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0111 - categorical_accuracy: 0.9148\n",
      "Epoch 00055: val_categorical_accuracy did not improve from 0.51979\n",
      "303/303 [==============================] - 182s 601ms/step - loss: 0.0111 - categorical_accuracy: 0.9148 - val_loss: 4.8457 - val_categorical_accuracy: 0.5094\n",
      "Epoch 56/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0110 - categorical_accuracy: 0.9152\n",
      "Epoch 00056: val_categorical_accuracy did not improve from 0.51979\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 6.998399767326191e-05.\n",
      "303/303 [==============================] - 178s 589ms/step - loss: 0.0110 - categorical_accuracy: 0.9152 - val_loss: 5.1005 - val_categorical_accuracy: 0.4856\n",
      "Epoch 57/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0103 - categorical_accuracy: 0.9148\n",
      "Epoch 00057: val_categorical_accuracy improved from 0.51979 to 0.52771, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 187s 617ms/step - loss: 0.0103 - categorical_accuracy: 0.9148 - val_loss: 4.7426 - val_categorical_accuracy: 0.5277\n",
      "Epoch 58/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0089 - categorical_accuracy: 0.9124\n",
      "Epoch 00058: val_categorical_accuracy improved from 0.52771 to 0.53000, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 182s 601ms/step - loss: 0.0089 - categorical_accuracy: 0.9124 - val_loss: 4.6790 - val_categorical_accuracy: 0.5300\n",
      "Epoch 59/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0085 - categorical_accuracy: 0.9119\n",
      "Epoch 00059: val_categorical_accuracy did not improve from 0.53000\n",
      "303/303 [==============================] - 183s 605ms/step - loss: 0.0085 - categorical_accuracy: 0.9119 - val_loss: 4.7409 - val_categorical_accuracy: 0.5233\n",
      "Epoch 60/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0074 - categorical_accuracy: 0.9139\n",
      "Epoch 00060: val_categorical_accuracy did not improve from 0.53000\n",
      "303/303 [==============================] - 178s 588ms/step - loss: 0.0074 - categorical_accuracy: 0.9139 - val_loss: 4.7291 - val_categorical_accuracy: 0.5267\n",
      "Epoch 61/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0082 - categorical_accuracy: 0.9119\n",
      "Epoch 00061: val_categorical_accuracy did not improve from 0.53000\n",
      "303/303 [==============================] - 183s 605ms/step - loss: 0.0082 - categorical_accuracy: 0.9119 - val_loss: 4.8592 - val_categorical_accuracy: 0.5108\n",
      "Epoch 62/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0069 - categorical_accuracy: 0.9147\n",
      "Epoch 00062: val_categorical_accuracy did not improve from 0.53000\n",
      "303/303 [==============================] - 179s 590ms/step - loss: 0.0069 - categorical_accuracy: 0.9147 - val_loss: 4.8571 - val_categorical_accuracy: 0.5231\n",
      "Epoch 63/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0070 - categorical_accuracy: 0.9125\n",
      "Epoch 00063: val_categorical_accuracy did not improve from 0.53000\n",
      "303/303 [==============================] - 186s 613ms/step - loss: 0.0070 - categorical_accuracy: 0.9125 - val_loss: 4.9233 - val_categorical_accuracy: 0.5163\n",
      "Epoch 64/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0062 - categorical_accuracy: 0.9137\n",
      "Epoch 00064: val_categorical_accuracy improved from 0.53000 to 0.53438, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 182s 599ms/step - loss: 0.0062 - categorical_accuracy: 0.9137 - val_loss: 4.8147 - val_categorical_accuracy: 0.5344\n",
      "Epoch 65/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0060 - categorical_accuracy: 0.9107\n",
      "Epoch 00065: val_categorical_accuracy improved from 0.53438 to 0.53625, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 188s 619ms/step - loss: 0.0060 - categorical_accuracy: 0.9107 - val_loss: 4.7883 - val_categorical_accuracy: 0.5362\n",
      "Epoch 66/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0069 - categorical_accuracy: 0.9121\n",
      "Epoch 00066: val_categorical_accuracy did not improve from 0.53625\n",
      "303/303 [==============================] - 173s 570ms/step - loss: 0.0069 - categorical_accuracy: 0.9121 - val_loss: 4.8956 - val_categorical_accuracy: 0.5294\n",
      "Epoch 67/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0059 - categorical_accuracy: 0.9155\n",
      "Epoch 00067: val_categorical_accuracy did not improve from 0.53625\n",
      "303/303 [==============================] - 172s 568ms/step - loss: 0.0059 - categorical_accuracy: 0.9155 - val_loss: 4.8125 - val_categorical_accuracy: 0.5360\n",
      "Epoch 68/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0063 - categorical_accuracy: 0.9119\n",
      "Epoch 00068: val_categorical_accuracy did not improve from 0.53625\n",
      "303/303 [==============================] - 171s 564ms/step - loss: 0.0063 - categorical_accuracy: 0.9119 - val_loss: 4.8236 - val_categorical_accuracy: 0.5323\n",
      "Epoch 69/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0061 - categorical_accuracy: 0.9142\n",
      "Epoch 00069: val_categorical_accuracy did not improve from 0.53625\n",
      "303/303 [==============================] - 178s 587ms/step - loss: 0.0061 - categorical_accuracy: 0.9142 - val_loss: 4.8189 - val_categorical_accuracy: 0.5327\n",
      "Epoch 70/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0068 - categorical_accuracy: 0.9120\n",
      "Epoch 00070: val_categorical_accuracy did not improve from 0.53625\n",
      "303/303 [==============================] - 171s 564ms/step - loss: 0.0068 - categorical_accuracy: 0.9120 - val_loss: 4.9556 - val_categorical_accuracy: 0.5246\n",
      "Epoch 71/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0079 - categorical_accuracy: 0.9142\n",
      "Epoch 00071: val_categorical_accuracy improved from 0.53625 to 0.53833, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 174s 573ms/step - loss: 0.0079 - categorical_accuracy: 0.9142 - val_loss: 4.8636 - val_categorical_accuracy: 0.5383\n",
      "Epoch 72/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0058 - categorical_accuracy: 0.9141\n",
      "Epoch 00072: val_categorical_accuracy did not improve from 0.53833\n",
      "303/303 [==============================] - 179s 590ms/step - loss: 0.0058 - categorical_accuracy: 0.9141 - val_loss: 4.9222 - val_categorical_accuracy: 0.5244\n",
      "Epoch 73/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0053 - categorical_accuracy: 0.9139\n",
      "Epoch 00073: val_categorical_accuracy did not improve from 0.53833\n",
      "303/303 [==============================] - 172s 567ms/step - loss: 0.0053 - categorical_accuracy: 0.9139 - val_loss: 5.0840 - val_categorical_accuracy: 0.5183\n",
      "Epoch 74/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0049 - categorical_accuracy: 0.9129\n",
      "Epoch 00074: val_categorical_accuracy did not improve from 0.53833\n",
      "303/303 [==============================] - 169s 557ms/step - loss: 0.0049 - categorical_accuracy: 0.9129 - val_loss: 4.8781 - val_categorical_accuracy: 0.5331\n",
      "Epoch 75/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0042 - categorical_accuracy: 0.9140\n",
      "Epoch 00075: val_categorical_accuracy did not improve from 0.53833\n",
      "303/303 [==============================] - 169s 557ms/step - loss: 0.0042 - categorical_accuracy: 0.9140 - val_loss: 4.9217 - val_categorical_accuracy: 0.5346\n",
      "Epoch 76/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0054 - categorical_accuracy: 0.9105\n",
      "Epoch 00076: val_categorical_accuracy did not improve from 0.53833\n",
      "303/303 [==============================] - 175s 578ms/step - loss: 0.0054 - categorical_accuracy: 0.9105 - val_loss: 5.0101 - val_categorical_accuracy: 0.5283\n",
      "Epoch 77/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0053 - categorical_accuracy: 0.9101\n",
      "Epoch 00077: val_categorical_accuracy did not improve from 0.53833\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 4.199039685772732e-05.\n",
      "303/303 [==============================] - 169s 557ms/step - loss: 0.0053 - categorical_accuracy: 0.9101 - val_loss: 5.2224 - val_categorical_accuracy: 0.5113\n",
      "Epoch 78/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0054 - categorical_accuracy: 0.9133\n",
      "Epoch 00078: val_categorical_accuracy did not improve from 0.53833\n",
      "303/303 [==============================] - 168s 555ms/step - loss: 0.0054 - categorical_accuracy: 0.9133 - val_loss: 5.0705 - val_categorical_accuracy: 0.5152\n",
      "Epoch 79/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0044 - categorical_accuracy: 0.9109\n",
      "Epoch 00079: val_categorical_accuracy did not improve from 0.53833\n",
      "303/303 [==============================] - 169s 559ms/step - loss: 0.0044 - categorical_accuracy: 0.9109 - val_loss: 4.9269 - val_categorical_accuracy: 0.5317\n",
      "Epoch 80/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0035 - categorical_accuracy: 0.9121\n",
      "Epoch 00080: val_categorical_accuracy did not improve from 0.53833\n",
      "303/303 [==============================] - 178s 588ms/step - loss: 0.0035 - categorical_accuracy: 0.9121 - val_loss: 4.9323 - val_categorical_accuracy: 0.5365\n",
      "Epoch 81/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0031 - categorical_accuracy: 0.9112\n",
      "Epoch 00081: val_categorical_accuracy did not improve from 0.53833\n",
      "303/303 [==============================] - 169s 559ms/step - loss: 0.0031 - categorical_accuracy: 0.9112 - val_loss: 4.9746 - val_categorical_accuracy: 0.5292\n",
      "Epoch 82/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0037 - categorical_accuracy: 0.9110\n",
      "Epoch 00082: val_categorical_accuracy did not improve from 0.53833\n",
      "303/303 [==============================] - 170s 563ms/step - loss: 0.0037 - categorical_accuracy: 0.9110 - val_loss: 5.0567 - val_categorical_accuracy: 0.5294\n",
      "Epoch 83/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0032 - categorical_accuracy: 0.9120\n",
      "Epoch 00083: val_categorical_accuracy did not improve from 0.53833\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 2.519423724152148e-05.\n",
      "303/303 [==============================] - 169s 558ms/step - loss: 0.0032 - categorical_accuracy: 0.9120 - val_loss: 4.9817 - val_categorical_accuracy: 0.5340\n",
      "Epoch 84/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0035 - categorical_accuracy: 0.9112\n",
      "Epoch 00084: val_categorical_accuracy did not improve from 0.53833\n",
      "303/303 [==============================] - 179s 589ms/step - loss: 0.0035 - categorical_accuracy: 0.9112 - val_loss: 4.9239 - val_categorical_accuracy: 0.5331\n",
      "Epoch 85/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0029 - categorical_accuracy: 0.9133\n",
      "Epoch 00085: val_categorical_accuracy did not improve from 0.53833\n",
      "303/303 [==============================] - 171s 563ms/step - loss: 0.0029 - categorical_accuracy: 0.9133 - val_loss: 5.0128 - val_categorical_accuracy: 0.5342\n",
      "Epoch 86/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0025 - categorical_accuracy: 0.9107\n",
      "Epoch 00086: val_categorical_accuracy did not improve from 0.53833\n",
      "303/303 [==============================] - 171s 564ms/step - loss: 0.0025 - categorical_accuracy: 0.9107 - val_loss: 5.0005 - val_categorical_accuracy: 0.5375\n",
      "Epoch 87/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0027 - categorical_accuracy: 0.9124\n",
      "Epoch 00087: val_categorical_accuracy did not improve from 0.53833\n",
      "303/303 [==============================] - 172s 569ms/step - loss: 0.0027 - categorical_accuracy: 0.9124 - val_loss: 5.0756 - val_categorical_accuracy: 0.5312\n",
      "Epoch 88/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0028 - categorical_accuracy: 0.9105\n",
      "Epoch 00088: val_categorical_accuracy improved from 0.53833 to 0.53938, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 183s 604ms/step - loss: 0.0028 - categorical_accuracy: 0.9105 - val_loss: 4.9989 - val_categorical_accuracy: 0.5394\n",
      "Epoch 89/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0023 - categorical_accuracy: 0.9115\n",
      "Epoch 00089: val_categorical_accuracy did not improve from 0.53938\n",
      "303/303 [==============================] - 174s 573ms/step - loss: 0.0023 - categorical_accuracy: 0.9115 - val_loss: 5.0580 - val_categorical_accuracy: 0.5310\n",
      "Epoch 90/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0027 - categorical_accuracy: 0.9130\n",
      "Epoch 00090: val_categorical_accuracy did not improve from 0.53938\n",
      "303/303 [==============================] - 173s 572ms/step - loss: 0.0027 - categorical_accuracy: 0.9130 - val_loss: 5.0230 - val_categorical_accuracy: 0.5383\n",
      "Epoch 91/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0027 - categorical_accuracy: 0.9101\n",
      "Epoch 00091: val_categorical_accuracy did not improve from 0.53938\n",
      "303/303 [==============================] - 173s 572ms/step - loss: 0.0027 - categorical_accuracy: 0.9101 - val_loss: 5.0030 - val_categorical_accuracy: 0.5392\n",
      "Epoch 92/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0026 - categorical_accuracy: 0.9114\n",
      "Epoch 00092: val_categorical_accuracy did not improve from 0.53938\n",
      "303/303 [==============================] - 183s 603ms/step - loss: 0.0026 - categorical_accuracy: 0.9114 - val_loss: 5.0642 - val_categorical_accuracy: 0.5319\n",
      "Epoch 93/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0021 - categorical_accuracy: 0.9114\n",
      "Epoch 00093: val_categorical_accuracy improved from 0.53938 to 0.54333, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 176s 582ms/step - loss: 0.0021 - categorical_accuracy: 0.9114 - val_loss: 4.9996 - val_categorical_accuracy: 0.5433\n",
      "Epoch 94/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0024 - categorical_accuracy: 0.9138\n",
      "Epoch 00094: val_categorical_accuracy improved from 0.54333 to 0.54542, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 176s 580ms/step - loss: 0.0024 - categorical_accuracy: 0.9138 - val_loss: 4.9983 - val_categorical_accuracy: 0.5454\n",
      "Epoch 95/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0021 - categorical_accuracy: 0.9105\n",
      "Epoch 00095: val_categorical_accuracy did not improve from 0.54542\n",
      "303/303 [==============================] - 174s 574ms/step - loss: 0.0021 - categorical_accuracy: 0.9105 - val_loss: 5.0635 - val_categorical_accuracy: 0.5331\n",
      "Epoch 96/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0019 - categorical_accuracy: 0.9124\n",
      "Epoch 00096: val_categorical_accuracy did not improve from 0.54542\n",
      "303/303 [==============================] - 183s 604ms/step - loss: 0.0019 - categorical_accuracy: 0.9124 - val_loss: 5.0648 - val_categorical_accuracy: 0.5375\n",
      "Epoch 97/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0022 - categorical_accuracy: 0.9157\n",
      "Epoch 00097: val_categorical_accuracy did not improve from 0.54542\n",
      "303/303 [==============================] - 175s 578ms/step - loss: 0.0022 - categorical_accuracy: 0.9157 - val_loss: 5.0711 - val_categorical_accuracy: 0.5375\n",
      "Epoch 98/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0021 - categorical_accuracy: 0.9125\n",
      "Epoch 00098: val_categorical_accuracy did not improve from 0.54542\n",
      "303/303 [==============================] - 177s 585ms/step - loss: 0.0021 - categorical_accuracy: 0.9125 - val_loss: 5.0810 - val_categorical_accuracy: 0.5421\n",
      "Epoch 99/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0022 - categorical_accuracy: 0.9137\n",
      "Epoch 00099: val_categorical_accuracy did not improve from 0.54542\n",
      "303/303 [==============================] - 177s 583ms/step - loss: 0.0022 - categorical_accuracy: 0.9137 - val_loss: 5.0592 - val_categorical_accuracy: 0.5408\n",
      "Epoch 100/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0018 - categorical_accuracy: 0.9139\n",
      "Epoch 00100: val_categorical_accuracy did not improve from 0.54542\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 1.511654190835543e-05.\n",
      "303/303 [==============================] - 186s 615ms/step - loss: 0.0018 - categorical_accuracy: 0.9139 - val_loss: 5.0843 - val_categorical_accuracy: 0.5406\n",
      "Epoch 101/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0021 - categorical_accuracy: 0.9141\n",
      "Epoch 00101: val_categorical_accuracy did not improve from 0.54542\n",
      "303/303 [==============================] - 177s 583ms/step - loss: 0.0021 - categorical_accuracy: 0.9141 - val_loss: 5.0792 - val_categorical_accuracy: 0.5417\n",
      "Epoch 102/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0020 - categorical_accuracy: 0.9134\n",
      "Epoch 00102: val_categorical_accuracy did not improve from 0.54542\n",
      "303/303 [==============================] - 176s 580ms/step - loss: 0.0020 - categorical_accuracy: 0.9134 - val_loss: 5.1457 - val_categorical_accuracy: 0.5365\n",
      "Epoch 103/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0019 - categorical_accuracy: 0.9117\n",
      "Epoch 00103: val_categorical_accuracy did not improve from 0.54542\n",
      "303/303 [==============================] - 176s 581ms/step - loss: 0.0019 - categorical_accuracy: 0.9117 - val_loss: 5.0781 - val_categorical_accuracy: 0.5433\n",
      "Epoch 104/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0015 - categorical_accuracy: 0.9128\n",
      "Epoch 00104: val_categorical_accuracy did not improve from 0.54542\n",
      "303/303 [==============================] - 185s 611ms/step - loss: 0.0015 - categorical_accuracy: 0.9128 - val_loss: 5.1083 - val_categorical_accuracy: 0.5396\n",
      "Epoch 105/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0019 - categorical_accuracy: 0.9155\n",
      "Epoch 00105: val_categorical_accuracy did not improve from 0.54542\n",
      "303/303 [==============================] - 177s 583ms/step - loss: 0.0019 - categorical_accuracy: 0.9155 - val_loss: 5.0924 - val_categorical_accuracy: 0.5440\n",
      "Epoch 106/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0019 - categorical_accuracy: 0.9133\n",
      "Epoch 00106: val_categorical_accuracy did not improve from 0.54542\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 9.069925363291987e-06.\n",
      "303/303 [==============================] - 178s 587ms/step - loss: 0.0019 - categorical_accuracy: 0.9133 - val_loss: 5.1325 - val_categorical_accuracy: 0.5412\n",
      "Epoch 107/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0019 - categorical_accuracy: 0.9134\n",
      "Epoch 00107: val_categorical_accuracy did not improve from 0.54542\n",
      "303/303 [==============================] - 177s 586ms/step - loss: 0.0019 - categorical_accuracy: 0.9134 - val_loss: 5.1275 - val_categorical_accuracy: 0.5392\n",
      "Epoch 108/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 0.9139\n",
      "Epoch 00108: val_categorical_accuracy improved from 0.54542 to 0.55104, saving model to NoisyTotal.best_weights-128.hdf5\n",
      "303/303 [==============================] - 188s 620ms/step - loss: 0.0017 - categorical_accuracy: 0.9139 - val_loss: 5.0709 - val_categorical_accuracy: 0.5510\n",
      "Epoch 109/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0015 - categorical_accuracy: 0.9132\n",
      "Epoch 00109: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 176s 582ms/step - loss: 0.0015 - categorical_accuracy: 0.9132 - val_loss: 5.1109 - val_categorical_accuracy: 0.5446\n",
      "Epoch 110/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 0.9133\n",
      "Epoch 00110: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 176s 579ms/step - loss: 0.0017 - categorical_accuracy: 0.9133 - val_loss: 5.0877 - val_categorical_accuracy: 0.5429\n",
      "Epoch 111/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0015 - categorical_accuracy: 0.9105\n",
      "Epoch 00111: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 176s 581ms/step - loss: 0.0015 - categorical_accuracy: 0.9105 - val_loss: 5.0965 - val_categorical_accuracy: 0.5442\n",
      "Epoch 112/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0014 - categorical_accuracy: 0.9145\n",
      "Epoch 00112: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 187s 616ms/step - loss: 0.0014 - categorical_accuracy: 0.9145 - val_loss: 5.0893 - val_categorical_accuracy: 0.5431\n",
      "Epoch 113/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0017 - categorical_accuracy: 0.9139\n",
      "Epoch 00113: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 176s 581ms/step - loss: 0.0017 - categorical_accuracy: 0.9139 - val_loss: 5.1065 - val_categorical_accuracy: 0.5427\n",
      "Epoch 114/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0015 - categorical_accuracy: 0.9127\n",
      "Epoch 00114: val_categorical_accuracy did not improve from 0.55104\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 5.441954999696463e-06.\n",
      "303/303 [==============================] - 175s 577ms/step - loss: 0.0015 - categorical_accuracy: 0.9127 - val_loss: 5.0662 - val_categorical_accuracy: 0.5483\n",
      "Epoch 115/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 0.9131\n",
      "Epoch 00115: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 176s 580ms/step - loss: 0.0016 - categorical_accuracy: 0.9131 - val_loss: 5.1181 - val_categorical_accuracy: 0.5400\n",
      "Epoch 116/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0015 - categorical_accuracy: 0.9129\n",
      "Epoch 00116: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 182s 602ms/step - loss: 0.0015 - categorical_accuracy: 0.9129 - val_loss: 5.1011 - val_categorical_accuracy: 0.5452\n",
      "Epoch 117/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 0.9100\n",
      "Epoch 00117: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 177s 586ms/step - loss: 0.0013 - categorical_accuracy: 0.9100 - val_loss: 5.1202 - val_categorical_accuracy: 0.5425\n",
      "Epoch 118/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0012 - categorical_accuracy: 0.9126\n",
      "Epoch 00118: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 177s 585ms/step - loss: 0.0012 - categorical_accuracy: 0.9126 - val_loss: 5.1067 - val_categorical_accuracy: 0.5469\n",
      "Epoch 119/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0014 - categorical_accuracy: 0.9120\n",
      "Epoch 00119: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 177s 586ms/step - loss: 0.0014 - categorical_accuracy: 0.9120 - val_loss: 5.1465 - val_categorical_accuracy: 0.5446\n",
      "Epoch 120/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 0.9128\n",
      "Epoch 00120: val_categorical_accuracy did not improve from 0.55104\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 3.265173108957242e-06.\n",
      "303/303 [==============================] - 178s 588ms/step - loss: 0.0013 - categorical_accuracy: 0.9128 - val_loss: 5.1178 - val_categorical_accuracy: 0.5481\n",
      "Epoch 121/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0015 - categorical_accuracy: 0.9130\n",
      "Epoch 00121: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 189s 624ms/step - loss: 0.0015 - categorical_accuracy: 0.9130 - val_loss: 5.1163 - val_categorical_accuracy: 0.5477\n",
      "Epoch 122/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 0.9124\n",
      "Epoch 00122: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 179s 592ms/step - loss: 0.0013 - categorical_accuracy: 0.9124 - val_loss: 5.1199 - val_categorical_accuracy: 0.5475\n",
      "Epoch 123/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0012 - categorical_accuracy: 0.9113\n",
      "Epoch 00123: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 178s 589ms/step - loss: 0.0012 - categorical_accuracy: 0.9113 - val_loss: 5.1353 - val_categorical_accuracy: 0.5473\n",
      "Epoch 124/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 0.9130\n",
      "Epoch 00124: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 179s 590ms/step - loss: 0.0013 - categorical_accuracy: 0.9130 - val_loss: 5.1463 - val_categorical_accuracy: 0.5454\n",
      "Epoch 125/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0012 - categorical_accuracy: 0.9108\n",
      "Epoch 00125: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 187s 616ms/step - loss: 0.0012 - categorical_accuracy: 0.9108 - val_loss: 5.1472 - val_categorical_accuracy: 0.5471\n",
      "Epoch 126/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 0.9144\n",
      "Epoch 00126: val_categorical_accuracy did not improve from 0.55104\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 1.959103838089504e-06.\n",
      "303/303 [==============================] - 177s 585ms/step - loss: 0.0013 - categorical_accuracy: 0.9144 - val_loss: 5.1383 - val_categorical_accuracy: 0.5475\n",
      "Epoch 127/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 0.9125\n",
      "Epoch 00127: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 179s 590ms/step - loss: 0.0013 - categorical_accuracy: 0.9125 - val_loss: 5.1364 - val_categorical_accuracy: 0.5452\n",
      "Epoch 128/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 0.9128\n",
      "Epoch 00128: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 178s 587ms/step - loss: 0.0013 - categorical_accuracy: 0.9128 - val_loss: 5.1409 - val_categorical_accuracy: 0.5452\n",
      "Epoch 129/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0012 - categorical_accuracy: 0.9096\n",
      "Epoch 00129: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 178s 589ms/step - loss: 0.0012 - categorical_accuracy: 0.9096 - val_loss: 5.1487 - val_categorical_accuracy: 0.5452\n",
      "Epoch 130/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 0.9122\n",
      "Epoch 00130: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 188s 622ms/step - loss: 0.0013 - categorical_accuracy: 0.9122 - val_loss: 5.1413 - val_categorical_accuracy: 0.5442\n",
      "Epoch 131/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0012 - categorical_accuracy: 0.9116\n",
      "Epoch 00131: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 178s 588ms/step - loss: 0.0012 - categorical_accuracy: 0.9116 - val_loss: 5.1632 - val_categorical_accuracy: 0.5456\n",
      "Epoch 132/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 0.9125\n",
      "Epoch 00132: val_categorical_accuracy did not improve from 0.55104\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 1.1754623301385436e-06.\n",
      "303/303 [==============================] - 178s 588ms/step - loss: 0.0013 - categorical_accuracy: 0.9125 - val_loss: 5.1497 - val_categorical_accuracy: 0.5450\n",
      "Epoch 133/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 0.9117\n",
      "Epoch 00133: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 166s 548ms/step - loss: 0.0013 - categorical_accuracy: 0.9117 - val_loss: 5.1491 - val_categorical_accuracy: 0.5456\n",
      "Epoch 134/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 0.9143\n",
      "Epoch 00134: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 179s 590ms/step - loss: 0.0013 - categorical_accuracy: 0.9143 - val_loss: 5.1445 - val_categorical_accuracy: 0.5448\n",
      "Epoch 135/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0012 - categorical_accuracy: 0.9134\n",
      "Epoch 00135: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 179s 591ms/step - loss: 0.0012 - categorical_accuracy: 0.9134 - val_loss: 5.1542 - val_categorical_accuracy: 0.5442\n",
      "Epoch 136/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0016 - categorical_accuracy: 0.9115\n",
      "Epoch 00136: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 165s 545ms/step - loss: 0.0016 - categorical_accuracy: 0.9115 - val_loss: 5.1479 - val_categorical_accuracy: 0.5444\n",
      "Epoch 137/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0012 - categorical_accuracy: 0.9149\n",
      "Epoch 00137: val_categorical_accuracy did not improve from 0.55104\n",
      "303/303 [==============================] - 178s 588ms/step - loss: 0.0012 - categorical_accuracy: 0.9149 - val_loss: 5.1530 - val_categorical_accuracy: 0.5446\n",
      "Epoch 138/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0013 - categorical_accuracy: 0.9138\n",
      "Epoch 00138: val_categorical_accuracy did not improve from 0.55104\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 7.052773980831261e-07.\n",
      "303/303 [==============================] - 181s 599ms/step - loss: 0.0013 - categorical_accuracy: 0.9138 - val_loss: 5.1536 - val_categorical_accuracy: 0.5450\n",
      "Epoch 00138: early stopping\n"
     ]
    }
   ],
   "source": [
    "history=custom_densenet169_model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=300,\n",
    "                    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:13:13.226305Z",
     "iopub.status.busy": "2020-09-30T23:13:13.224960Z",
     "iopub.status.idle": "2020-09-30T23:13:13.227155Z",
     "shell.execute_reply": "2020-09-30T23:13:13.227898Z"
    },
    "papermill": {
     "duration": 17.452798,
     "end_time": "2020-09-30T23:13:13.228054",
     "exception": false,
     "start_time": "2020-09-30T23:12:55.775256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:13:48.751447Z",
     "iopub.status.busy": "2020-09-30T23:13:48.750405Z",
     "iopub.status.idle": "2020-09-30T23:13:49.019739Z",
     "shell.execute_reply": "2020-09-30T23:13:49.019068Z"
    },
    "papermill": {
     "duration": 18.357765,
     "end_time": "2020-09-30T23:13:49.019880",
     "exception": false,
     "start_time": "2020-09-30T23:13:30.662115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "loss_train = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "#epochs = np.range(1,1)\n",
    "plt.plot(loss_train, 'g', label='Training loss')\n",
    "plt.plot(loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:14:24.200749Z",
     "iopub.status.busy": "2020-09-30T23:14:24.199454Z",
     "iopub.status.idle": "2020-09-30T23:14:24.560321Z",
     "shell.execute_reply": "2020-09-30T23:14:24.561231Z"
    },
    "papermill": {
     "duration": 17.641391,
     "end_time": "2020-09-30T23:14:24.561497",
     "exception": false,
     "start_time": "2020-09-30T23:14:06.920106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = history.history['categorical_accuracy']\n",
    "loss_val = history.history['val_categorical_accuracy']\n",
    "epochs = range(1,41)\n",
    "plt.plot(loss_train, 'g', label='Training accuracy')\n",
    "plt.plot(loss_val, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:15:00.451447Z",
     "iopub.status.busy": "2020-09-30T23:15:00.449633Z",
     "iopub.status.idle": "2020-09-30T23:15:14.606979Z",
     "shell.execute_reply": "2020-09-30T23:15:14.606387Z"
    },
    "papermill": {
     "duration": 32.26591,
     "end_time": "2020-09-30T23:15:14.607102",
     "exception": false,
     "start_time": "2020-09-30T23:14:42.341192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 11s 143ms/step\n"
     ]
    }
   ],
   "source": [
    "res = custom_densenet169_model.predict_generator(valid_generator, verbose=1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:15:50.304603Z",
     "iopub.status.busy": "2020-09-30T23:15:50.303505Z",
     "iopub.status.idle": "2020-09-30T23:16:15.137596Z",
     "shell.execute_reply": "2020-09-30T23:16:15.136885Z"
    },
    "papermill": {
     "duration": 43.050474,
     "end_time": "2020-09-30T23:16:15.137727",
     "exception": false,
     "start_time": "2020-09-30T23:15:32.087253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 22s 226ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "res_test=custom_densenet169_model.predict_generator(test_generator,\n",
    "#steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:16:51.200415Z",
     "iopub.status.busy": "2020-09-30T23:16:51.199226Z",
     "iopub.status.idle": "2020-09-30T23:17:01.677808Z",
     "shell.execute_reply": "2020-09-30T23:17:01.676823Z"
    },
    "papermill": {
     "duration": 28.904862,
     "end_time": "2020-09-30T23:17:01.677934",
     "exception": false,
     "start_time": "2020-09-30T23:16:32.773072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 10s 131ms/step\n"
     ]
    }
   ],
   "source": [
    "valid_generator.reset()\n",
    "res_cv=custom_densenet169_model.predict_generator(valid_generator,\n",
    "#steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:17:37.293420Z",
     "iopub.status.busy": "2020-09-30T23:17:37.292063Z",
     "iopub.status.idle": "2020-09-30T23:20:00.019930Z",
     "shell.execute_reply": "2020-09-30T23:20:00.019137Z"
    },
    "papermill": {
     "duration": 160.393855,
     "end_time": "2020-09-30T23:20:00.020075",
     "exception": false,
     "start_time": "2020-09-30T23:17:19.626220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304/304 [==============================] - 142s 466ms/step\n"
     ]
    }
   ],
   "source": [
    "train_generator.reset()\n",
    "res_train=custom_densenet169_model.predict_generator(train_generator,\n",
    "#steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:20:35.265537Z",
     "iopub.status.busy": "2020-09-30T23:20:35.264388Z",
     "iopub.status.idle": "2020-09-30T23:20:35.271035Z",
     "shell.execute_reply": "2020-09-30T23:20:35.270345Z"
    },
    "papermill": {
     "duration": 17.570226,
     "end_time": "2020-09-30T23:20:35.271150",
     "exception": false,
     "start_time": "2020-09-30T23:20:17.700924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6078, 80)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:21:12.091764Z",
     "iopub.status.busy": "2020-09-30T23:21:12.090764Z",
     "iopub.status.idle": "2020-09-30T23:21:12.424609Z",
     "shell.execute_reply": "2020-09-30T23:21:12.423997Z"
    },
    "papermill": {
     "duration": 17.865855,
     "end_time": "2020-09-30T23:21:12.424747",
     "exception": false,
     "start_time": "2020-09-30T23:20:54.558892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converting taget and identity columns to booleans\n",
    "\n",
    "target_columns=list(trainmultidf.columns)[:-1]\n",
    "\n",
    "def convert_to_bool(df, col_name):\n",
    "    df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n",
    "    \n",
    "def convert_dataframe_to_bool(df):\n",
    "    bool_df = df.copy()\n",
    "    for col in target_columns:\n",
    "        convert_to_bool(bool_df, col)\n",
    "    return bool_df\n",
    "\n",
    "test_bool = convert_dataframe_to_bool(testmultidf) \n",
    "test_lable_bool=test_bool[list(test_bool.columns)[:-1]].to_numpy()\n",
    "\n",
    "train_bool = convert_dataframe_to_bool(trainmultidf) \n",
    "train_lable_bool=train_bool[list(train_bool.columns)[:-1]].to_numpy()\n",
    "\n",
    "cv_bool = convert_dataframe_to_bool(cvmultidf) \n",
    "cv_lable_bool=cv_bool[list(cv_bool.columns)[:-1]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:21:48.858594Z",
     "iopub.status.busy": "2020-09-30T23:21:48.857495Z",
     "iopub.status.idle": "2020-09-30T23:21:48.862798Z",
     "shell.execute_reply": "2020-09-30T23:21:48.862193Z"
    },
    "papermill": {
     "duration": 18.628349,
     "end_time": "2020-09-30T23:21:48.862915",
     "exception": false,
     "start_time": "2020-09-30T23:21:30.234566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4862, 80)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_lable_bool.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 18.002108,
     "end_time": "2020-09-30T23:22:24.325190",
     "exception": false,
     "start_time": "2020-09-30T23:22:06.323082",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:23:00.624149Z",
     "iopub.status.busy": "2020-09-30T23:23:00.622985Z",
     "iopub.status.idle": "2020-09-30T23:23:00.625391Z",
     "shell.execute_reply": "2020-09-30T23:23:00.625944Z"
    },
    "papermill": {
     "duration": 18.987539,
     "end_time": "2020-09-30T23:23:00.626085",
     "exception": false,
     "start_time": "2020-09-30T23:22:41.638546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:23:35.571586Z",
     "iopub.status.busy": "2020-09-30T23:23:35.570420Z",
     "iopub.status.idle": "2020-09-30T23:23:35.573818Z",
     "shell.execute_reply": "2020-09-30T23:23:35.573215Z"
    },
    "papermill": {
     "duration": 17.461186,
     "end_time": "2020-09-30T23:23:35.573936",
     "exception": false,
     "start_time": "2020-09-30T23:23:18.112750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Core calculation of label precisions for one test sample.\n",
    "\n",
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "  \"\"\"Calculate precisions for each true class for a single sample.\n",
    "  \n",
    "  Args:\n",
    "    scores: np.array of (num_classes,) giving the individual classifier scores.\n",
    "    truth: np.array of (num_classes,) bools indicating which classes are true.\n",
    "\n",
    "  Returns:\n",
    "    pos_class_indices: np.array of indices of the true classes for this sample.\n",
    "    pos_class_precisions: np.array of precisions corresponding to each of those\n",
    "      classes.\n",
    "  \"\"\"\n",
    "  num_classes = scores.shape[0]\n",
    "  pos_class_indices = np.flatnonzero(truth > 0)\n",
    "  # Only calculate precisions if there are some true classes.\n",
    "  if not len(pos_class_indices):\n",
    "    return pos_class_indices, np.zeros(0)\n",
    "  # Retrieval list of classes for this sample. \n",
    "  retrieved_classes = np.argsort(scores)[::-1]\n",
    "  # class_rankings[top_scoring_class_index] == 0 etc.\n",
    "  class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "  class_rankings[retrieved_classes] = range(num_classes)\n",
    "  # Which of these is a true label?\n",
    "  retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "  retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "  # Num hits for every truncated retrieval list.\n",
    "  retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "  # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
    "  precision_at_hits = (\n",
    "      retrieved_cumulative_hits[class_rankings[pos_class_indices]] / \n",
    "      (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "  return pos_class_indices, precision_at_hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:24:11.927034Z",
     "iopub.status.busy": "2020-09-30T23:24:11.925971Z",
     "iopub.status.idle": "2020-09-30T23:24:11.937095Z",
     "shell.execute_reply": "2020-09-30T23:24:11.937630Z"
    },
    "papermill": {
     "duration": 17.651225,
     "end_time": "2020-09-30T23:24:11.937786",
     "exception": false,
     "start_time": "2020-09-30T23:23:54.286561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All-in-one calculation of per-class lwlrap.\n",
    "\n",
    "def calculate_per_class_lwlrap(truth, scores):\n",
    "  \"\"\"Calculate label-weighted label-ranking average precision.\n",
    "  \n",
    "  Arguments:\n",
    "    truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
    "      of presence of that class in that sample.\n",
    "    scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
    "      test's real-valued score for each class for each sample.\n",
    "  \n",
    "  Returns:\n",
    "    per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each \n",
    "      class.\n",
    "    weight_per_class: np.array of (num_classes,) giving the prior of each \n",
    "      class within the truth labels.  Then the overall unbalanced lwlrap is \n",
    "      simply np.sum(per_class_lwlrap * weight_per_class)\n",
    "  \"\"\"\n",
    "  assert truth.shape == scores.shape\n",
    "  num_samples, num_classes = scores.shape\n",
    "  # Space to store a distinct precision value for each class on each sample.\n",
    "  # Only the classes that are true for each sample will be filled in.\n",
    "  precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
    "  for sample_num in range(num_samples):\n",
    "    pos_class_indices, precision_at_hits = (\n",
    "      _one_sample_positive_class_precisions(scores[sample_num, :], \n",
    "                                            truth[sample_num, :]))\n",
    "    precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
    "        precision_at_hits)\n",
    "  labels_per_class = np.sum(truth > 0, axis=0)\n",
    "  weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
    "  # Form average of each column, i.e. all the precisions assigned to labels in\n",
    "  # a particular class.\n",
    "  per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) / \n",
    "                      np.maximum(1, labels_per_class))\n",
    "  # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
    "  #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
    "  #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
    "  #                = np.sum(per_class_lwlrap * weight_per_class)\n",
    "  return per_class_lwlrap, weight_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:24:47.847016Z",
     "iopub.status.busy": "2020-09-30T23:24:47.845919Z",
     "iopub.status.idle": "2020-09-30T23:24:47.849388Z",
     "shell.execute_reply": "2020-09-30T23:24:47.848776Z"
    },
    "papermill": {
     "duration": 18.336419,
     "end_time": "2020-09-30T23:24:47.849521",
     "exception": false,
     "start_time": "2020-09-30T23:24:29.513102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the overall lwlrap using sklearn.metrics function.\n",
    "\n",
    "def calculate_overall_lwlrap_sklearn(truth, scores):\n",
    "  \"\"\"Calculate the overall lwlrap using sklearn.metrics.lrap.\"\"\"\n",
    "  # sklearn doesn't correctly apply weighting to samples with no labels, so just skip them.\n",
    "  sample_weight = np.sum(truth > 0, axis=1)\n",
    "  nonzero_weight_sample_indices = np.flatnonzero(sample_weight > 0)\n",
    "  overall_lwlrap = sklearn.metrics.label_ranking_average_precision_score(\n",
    "      truth[nonzero_weight_sample_indices, :] > 0, \n",
    "      scores[nonzero_weight_sample_indices, :], \n",
    "      sample_weight=sample_weight[nonzero_weight_sample_indices])\n",
    "  return overall_lwlrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:25:22.893785Z",
     "iopub.status.busy": "2020-09-30T23:25:22.885810Z",
     "iopub.status.idle": "2020-09-30T23:25:22.897305Z",
     "shell.execute_reply": "2020-09-30T23:25:22.896676Z"
    },
    "papermill": {
     "duration": 17.577002,
     "end_time": "2020-09-30T23:25:22.897438",
     "exception": false,
     "start_time": "2020-09-30T23:25:05.320436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Accumulator object version.\n",
    "\n",
    "class lwlrap_accumulator(object):\n",
    "  \"\"\"Accumulate batches of test samples into per-class and overall lwlrap.\"\"\"  \n",
    "\n",
    "  def __init__(self):\n",
    "    self.num_classes = 0\n",
    "    self.total_num_samples = 0\n",
    "  \n",
    "  def accumulate_samples(self, batch_truth, batch_scores):\n",
    "    \"\"\"Cumulate a new batch of samples into the metric.\n",
    "    \n",
    "    Args:\n",
    "      truth: np.array of (num_samples, num_classes) giving boolean\n",
    "        ground-truth of presence of that class in that sample for this batch.\n",
    "      scores: np.array of (num_samples, num_classes) giving the \n",
    "        classifier-under-test's real-valued score for each class for each\n",
    "        sample.\n",
    "    \"\"\"\n",
    "    assert batch_scores.shape == batch_truth.shape\n",
    "    num_samples, num_classes = batch_truth.shape\n",
    "    if not self.num_classes:\n",
    "      self.num_classes = num_classes\n",
    "      self._per_class_cumulative_precision = np.zeros(self.num_classes)\n",
    "      self._per_class_cumulative_count = np.zeros(self.num_classes, \n",
    "                                                  dtype=np.int)\n",
    "    assert num_classes == self.num_classes\n",
    "    for truth, scores in zip(batch_truth, batch_scores):\n",
    "      pos_class_indices, precision_at_hits = (\n",
    "        _one_sample_positive_class_precisions(scores, truth))\n",
    "      self._per_class_cumulative_precision[pos_class_indices] += (\n",
    "        precision_at_hits)\n",
    "      self._per_class_cumulative_count[pos_class_indices] += 1\n",
    "    self.total_num_samples += num_samples\n",
    "\n",
    "  def per_class_lwlrap(self):\n",
    "    \"\"\"Return a vector of the per-class lwlraps for the accumulated samples.\"\"\"\n",
    "    return (self._per_class_cumulative_precision / \n",
    "            np.maximum(1, self._per_class_cumulative_count))\n",
    "\n",
    "  def per_class_weight(self):\n",
    "    \"\"\"Return a normalized weight vector for the contributions of each class.\"\"\"\n",
    "    return (self._per_class_cumulative_count / \n",
    "            float(np.sum(self._per_class_cumulative_count)))\n",
    "\n",
    "  def overall_lwlrap(self):\n",
    "    \"\"\"Return the scalar overall lwlrap for cumulated samples.\"\"\"\n",
    "    return np.sum(self.per_class_lwlrap() * self.per_class_weight())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:25:59.509494Z",
     "iopub.status.busy": "2020-09-30T23:25:59.508419Z",
     "iopub.status.idle": "2020-09-30T23:26:00.554255Z",
     "shell.execute_reply": "2020-09-30T23:26:00.554954Z"
    },
    "papermill": {
     "duration": 20.008822,
     "end_time": "2020-09-30T23:26:00.555129",
     "exception": false,
     "start_time": "2020-09-30T23:25:40.546307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lwlrap from sklearn.metrics = 0.6809694067668535\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/voglinio/keras-2d-model-5-fold-log-specgram-curated-only\n",
    "truth = test_lable_bool\n",
    "scores = res_test\n",
    "print(\"lwlrap from sklearn.metrics =\", calculate_overall_lwlrap_sklearn(truth, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:26:36.159548Z",
     "iopub.status.busy": "2020-09-30T23:26:36.158431Z",
     "iopub.status.idle": "2020-09-30T23:26:39.178746Z",
     "shell.execute_reply": "2020-09-30T23:26:39.178057Z"
    },
    "papermill": {
     "duration": 20.947873,
     "end_time": "2020-09-30T23:26:39.178871",
     "exception": false,
     "start_time": "2020-09-30T23:26:18.230998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lwlrap from sklearn.metrics = 0.9996580295177233\n"
     ]
    }
   ],
   "source": [
    "truth = train_lable_bool\n",
    "scores = res_train\n",
    "print(\"lwlrap from sklearn.metrics =\", calculate_overall_lwlrap_sklearn(truth, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:27:15.367279Z",
     "iopub.status.busy": "2020-09-30T23:27:15.366196Z",
     "iopub.status.idle": "2020-09-30T23:27:16.126860Z",
     "shell.execute_reply": "2020-09-30T23:27:16.127476Z"
    },
    "papermill": {
     "duration": 18.272356,
     "end_time": "2020-09-30T23:27:16.127625",
     "exception": false,
     "start_time": "2020-09-30T23:26:57.855269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lwlrap from sklearn.metrics = 0.6861282922569297\n"
     ]
    }
   ],
   "source": [
    "truth = cv_lable_bool\n",
    "scores = res_cv\n",
    "print(\"lwlrap from sklearn.metrics =\", calculate_overall_lwlrap_sklearn(truth, scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 18.676758,
     "end_time": "2020-09-30T23:27:52.619607",
     "exception": false,
     "start_time": "2020-09-30T23:27:33.942849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:28:27.806396Z",
     "iopub.status.busy": "2020-09-30T23:28:27.805576Z",
     "iopub.status.idle": "2020-09-30T23:28:28.393946Z",
     "shell.execute_reply": "2020-09-30T23:28:28.394500Z"
    },
    "papermill": {
     "duration": 18.221215,
     "end_time": "2020-09-30T23:28:28.394662",
     "exception": false,
     "start_time": "2020-09-30T23:28:10.173447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3361 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "sub_dataframe = pd.DataFrame({'fname':os.listdir('../input/sc2-total-aug-noisy-data/sub2/sub2')})\n",
    "\n",
    "sub_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "sub_generator=sub_datagen.flow_from_dataframe(\n",
    "    dataframe=sub_dataframe,\n",
    "    directory=\"../input/sc2-total-aug-noisy-data/sub2/sub2\",\n",
    "    x_col=\"fname\",\n",
    "    y_col=None,\n",
    "    batch_size=64,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "    target_size=(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:29:04.753660Z",
     "iopub.status.busy": "2020-09-30T23:29:04.752550Z",
     "iopub.status.idle": "2020-09-30T23:29:04.755298Z",
     "shell.execute_reply": "2020-09-30T23:29:04.755962Z"
    },
    "papermill": {
     "duration": 17.671186,
     "end_time": "2020-09-30T23:29:04.756107",
     "exception": false,
     "start_time": "2020-09-30T23:28:47.084921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "STEP_SIZE_SUB=sub_generator.n//sub_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:29:40.206843Z",
     "iopub.status.busy": "2020-09-30T23:29:40.205105Z",
     "iopub.status.idle": "2020-09-30T23:29:53.095013Z",
     "shell.execute_reply": "2020-09-30T23:29:53.094041Z"
    },
    "papermill": {
     "duration": 30.43909,
     "end_time": "2020-09-30T23:29:53.095150",
     "exception": false,
     "start_time": "2020-09-30T23:29:22.656060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 12s 233ms/step\n"
     ]
    }
   ],
   "source": [
    "sub_generator.reset()\n",
    "res_sub=custom_densenet169_model.predict_generator(sub_generator,\n",
    "#steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:30:28.337718Z",
     "iopub.status.busy": "2020-09-30T23:30:28.336670Z",
     "iopub.status.idle": "2020-09-30T23:30:28.342927Z",
     "shell.execute_reply": "2020-09-30T23:30:28.343489Z"
    },
    "papermill": {
     "duration": 17.633742,
     "end_time": "2020-09-30T23:30:28.343629",
     "exception": false,
     "start_time": "2020-09-30T23:30:10.709887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3361, 80)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:31:05.165605Z",
     "iopub.status.busy": "2020-09-30T23:31:05.164603Z",
     "iopub.status.idle": "2020-09-30T23:31:05.171077Z",
     "shell.execute_reply": "2020-09-30T23:31:05.171616Z"
    },
    "papermill": {
     "duration": 18.593075,
     "end_time": "2020-09-30T23:31:05.171776",
     "exception": false,
     "start_time": "2020-09-30T23:30:46.578701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit_data=pd.DataFrame(res_sub.astype(\"float64\"), columns=list(mlb_train.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:31:40.475665Z",
     "iopub.status.busy": "2020-09-30T23:31:40.474618Z",
     "iopub.status.idle": "2020-09-30T23:31:40.525083Z",
     "shell.execute_reply": "2020-09-30T23:31:40.524073Z"
    },
    "papermill": {
     "duration": 17.480139,
     "end_time": "2020-09-30T23:31:40.525220",
     "exception": false,
     "start_time": "2020-09-30T23:31:23.045081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>Accelerating_and_revving_and_vroom</th>\n",
       "      <th>Accordion</th>\n",
       "      <th>Acoustic_guitar</th>\n",
       "      <th>Applause</th>\n",
       "      <th>Bark</th>\n",
       "      <th>Bass_drum</th>\n",
       "      <th>Bass_guitar</th>\n",
       "      <th>Bathtub_(filling_or_washing)</th>\n",
       "      <th>Bicycle_bell</th>\n",
       "      <th>...</th>\n",
       "      <th>Toilet_flush</th>\n",
       "      <th>Traffic_noise_and_roadway_noise</th>\n",
       "      <th>Trickle_and_dribble</th>\n",
       "      <th>Walk_and_footsteps</th>\n",
       "      <th>Water_tap_and_faucet</th>\n",
       "      <th>Waves_and_surf</th>\n",
       "      <th>Whispering</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Yell</th>\n",
       "      <th>Zipper_(clothing)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f308ee9f.wav</td>\n",
       "      <td>1.802976e-09</td>\n",
       "      <td>2.193314e-11</td>\n",
       "      <td>1.091289e-12</td>\n",
       "      <td>1.525379e-11</td>\n",
       "      <td>7.366197e-13</td>\n",
       "      <td>4.515448e-13</td>\n",
       "      <td>7.110506e-10</td>\n",
       "      <td>1.227545e-13</td>\n",
       "      <td>5.567424e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>4.997243e-12</td>\n",
       "      <td>1.093083e-12</td>\n",
       "      <td>1.139433e-12</td>\n",
       "      <td>3.154429e-04</td>\n",
       "      <td>1.606418e-11</td>\n",
       "      <td>5.067228e-10</td>\n",
       "      <td>1.241425e-09</td>\n",
       "      <td>4.056759e-06</td>\n",
       "      <td>1.138677e-13</td>\n",
       "      <td>1.971627e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57e25987.wav</td>\n",
       "      <td>8.616885e-05</td>\n",
       "      <td>3.837429e-08</td>\n",
       "      <td>1.428463e-09</td>\n",
       "      <td>1.236976e-14</td>\n",
       "      <td>9.540003e-10</td>\n",
       "      <td>2.771097e-07</td>\n",
       "      <td>9.091188e-08</td>\n",
       "      <td>3.418489e-11</td>\n",
       "      <td>2.535638e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.821206e-07</td>\n",
       "      <td>1.517653e-07</td>\n",
       "      <td>1.067828e-10</td>\n",
       "      <td>1.829520e-07</td>\n",
       "      <td>4.878509e-07</td>\n",
       "      <td>8.540898e-09</td>\n",
       "      <td>1.393260e-15</td>\n",
       "      <td>1.268866e-10</td>\n",
       "      <td>3.618386e-11</td>\n",
       "      <td>3.496712e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85965288.wav</td>\n",
       "      <td>4.138248e-08</td>\n",
       "      <td>7.158026e-09</td>\n",
       "      <td>1.374212e-07</td>\n",
       "      <td>2.168913e-09</td>\n",
       "      <td>7.750023e-10</td>\n",
       "      <td>2.282050e-07</td>\n",
       "      <td>1.727277e-09</td>\n",
       "      <td>1.364692e-10</td>\n",
       "      <td>3.102129e-13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.811820e-11</td>\n",
       "      <td>4.161197e-10</td>\n",
       "      <td>8.218265e-08</td>\n",
       "      <td>3.368313e-06</td>\n",
       "      <td>4.843679e-12</td>\n",
       "      <td>2.183332e-10</td>\n",
       "      <td>4.255435e-10</td>\n",
       "      <td>1.336419e-05</td>\n",
       "      <td>2.989644e-10</td>\n",
       "      <td>1.320604e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f0d764ff.wav</td>\n",
       "      <td>7.161722e-07</td>\n",
       "      <td>1.700881e-09</td>\n",
       "      <td>3.094692e-04</td>\n",
       "      <td>1.766508e-10</td>\n",
       "      <td>7.765345e-12</td>\n",
       "      <td>1.637857e-08</td>\n",
       "      <td>6.600867e-12</td>\n",
       "      <td>8.624804e-11</td>\n",
       "      <td>1.394455e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>9.205314e-06</td>\n",
       "      <td>1.308995e-09</td>\n",
       "      <td>7.894054e-09</td>\n",
       "      <td>1.900045e-09</td>\n",
       "      <td>3.975071e-12</td>\n",
       "      <td>1.999290e-07</td>\n",
       "      <td>5.632135e-12</td>\n",
       "      <td>4.393474e-10</td>\n",
       "      <td>4.612280e-12</td>\n",
       "      <td>2.969787e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d337d98e.wav</td>\n",
       "      <td>1.716987e-12</td>\n",
       "      <td>8.749738e-11</td>\n",
       "      <td>7.718911e-10</td>\n",
       "      <td>4.390883e-15</td>\n",
       "      <td>7.139785e-12</td>\n",
       "      <td>1.280778e-14</td>\n",
       "      <td>2.133012e-13</td>\n",
       "      <td>7.704488e-12</td>\n",
       "      <td>1.904747e-09</td>\n",
       "      <td>...</td>\n",
       "      <td>3.249434e-14</td>\n",
       "      <td>2.900032e-12</td>\n",
       "      <td>1.923023e-07</td>\n",
       "      <td>1.891433e-11</td>\n",
       "      <td>5.294268e-10</td>\n",
       "      <td>2.097969e-07</td>\n",
       "      <td>6.285276e-05</td>\n",
       "      <td>9.611204e-12</td>\n",
       "      <td>1.198566e-15</td>\n",
       "      <td>1.230003e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname  Accelerating_and_revving_and_vroom     Accordion  \\\n",
       "0  f308ee9f.wav                        1.802976e-09  2.193314e-11   \n",
       "1  57e25987.wav                        8.616885e-05  3.837429e-08   \n",
       "2  85965288.wav                        4.138248e-08  7.158026e-09   \n",
       "3  f0d764ff.wav                        7.161722e-07  1.700881e-09   \n",
       "4  d337d98e.wav                        1.716987e-12  8.749738e-11   \n",
       "\n",
       "   Acoustic_guitar      Applause          Bark     Bass_drum   Bass_guitar  \\\n",
       "0     1.091289e-12  1.525379e-11  7.366197e-13  4.515448e-13  7.110506e-10   \n",
       "1     1.428463e-09  1.236976e-14  9.540003e-10  2.771097e-07  9.091188e-08   \n",
       "2     1.374212e-07  2.168913e-09  7.750023e-10  2.282050e-07  1.727277e-09   \n",
       "3     3.094692e-04  1.766508e-10  7.765345e-12  1.637857e-08  6.600867e-12   \n",
       "4     7.718911e-10  4.390883e-15  7.139785e-12  1.280778e-14  2.133012e-13   \n",
       "\n",
       "   Bathtub_(filling_or_washing)  Bicycle_bell  ...  Toilet_flush  \\\n",
       "0                  1.227545e-13  5.567424e-11  ...  4.997243e-12   \n",
       "1                  3.418489e-11  2.535638e-10  ...  1.821206e-07   \n",
       "2                  1.364692e-10  3.102129e-13  ...  1.811820e-11   \n",
       "3                  8.624804e-11  1.394455e-09  ...  9.205314e-06   \n",
       "4                  7.704488e-12  1.904747e-09  ...  3.249434e-14   \n",
       "\n",
       "   Traffic_noise_and_roadway_noise  Trickle_and_dribble  Walk_and_footsteps  \\\n",
       "0                     1.093083e-12         1.139433e-12        3.154429e-04   \n",
       "1                     1.517653e-07         1.067828e-10        1.829520e-07   \n",
       "2                     4.161197e-10         8.218265e-08        3.368313e-06   \n",
       "3                     1.308995e-09         7.894054e-09        1.900045e-09   \n",
       "4                     2.900032e-12         1.923023e-07        1.891433e-11   \n",
       "\n",
       "   Water_tap_and_faucet  Waves_and_surf    Whispering       Writing  \\\n",
       "0          1.606418e-11    5.067228e-10  1.241425e-09  4.056759e-06   \n",
       "1          4.878509e-07    8.540898e-09  1.393260e-15  1.268866e-10   \n",
       "2          4.843679e-12    2.183332e-10  4.255435e-10  1.336419e-05   \n",
       "3          3.975071e-12    1.999290e-07  5.632135e-12  4.393474e-10   \n",
       "4          5.294268e-10    2.097969e-07  6.285276e-05  9.611204e-12   \n",
       "\n",
       "           Yell  Zipper_(clothing)  \n",
       "0  1.138677e-13       1.971627e-09  \n",
       "1  3.618386e-11       3.496712e-08  \n",
       "2  2.989644e-10       1.320604e-06  \n",
       "3  4.612280e-12       2.969787e-10  \n",
       "4  1.198566e-15       1.230003e-05  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_data.insert(0, 'fname', os.listdir('../input/sc2-total-aug-noisy-data/sub2/sub2'))\n",
    "submit_data[\"fname\"]=submit_data[\"fname\"].apply(lambda x: x.split(\".\")[0]+\".wav\")\n",
    "submit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-30T23:32:17.583032Z",
     "iopub.status.busy": "2020-09-30T23:32:17.582022Z",
     "iopub.status.idle": "2020-09-30T23:32:18.712540Z",
     "shell.execute_reply": "2020-09-30T23:32:18.711843Z"
    },
    "papermill": {
     "duration": 19.252009,
     "end_time": "2020-09-30T23:32:18.712685",
     "exception": false,
     "start_time": "2020-09-30T23:31:59.460676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit_data.to_csv(\"submissionDenseNoisyCV_4.csv\",index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 18.899769,
     "end_time": "2020-09-30T23:32:54.930792",
     "exception": false,
     "start_time": "2020-09-30T23:32:36.031023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "papermill": {
   "duration": 25401.08549,
   "end_time": "2020-09-30T23:33:14.225590",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-30T16:29:53.140100",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
