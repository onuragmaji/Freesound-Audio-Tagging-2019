{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:26.435376Z",
     "iopub.status.busy": "2020-10-04T17:50:26.434464Z",
     "iopub.status.idle": "2020-10-04T17:50:26.437488Z",
     "shell.execute_reply": "2020-10-04T17:50:26.436969Z"
    },
    "papermill": {
     "duration": 0.051151,
     "end_time": "2020-10-04T17:50:26.437598",
     "exception": false,
     "start_time": "2020-10-04T17:50:26.386447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:26.529565Z",
     "iopub.status.busy": "2020-10-04T17:50:26.528933Z",
     "iopub.status.idle": "2020-10-04T17:50:26.570120Z",
     "shell.execute_reply": "2020-10-04T17:50:26.569458Z"
    },
    "papermill": {
     "duration": 0.089759,
     "end_time": "2020-10-04T17:50:26.570232",
     "exception": false,
     "start_time": "2020-10-04T17:50:26.480473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "traindf_noisy=pd.read_csv('../input/freesound-audio-tagging-2019/train_noisy.csv',dtype=str)\n",
    "\n",
    "traindf_curated=pd.read_csv('../input/freesound-audio-tagging-2019/train_curated.csv',dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:26.667830Z",
     "iopub.status.busy": "2020-10-04T17:50:26.666957Z",
     "iopub.status.idle": "2020-10-04T17:50:26.674406Z",
     "shell.execute_reply": "2020-10-04T17:50:26.675031Z"
    },
    "papermill": {
     "duration": 0.06179,
     "end_time": "2020-10-04T17:50:26.675170",
     "exception": false,
     "start_time": "2020-10-04T17:50:26.613380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00097e21.wav</td>\n",
       "      <td>Bathtub_(filling_or_washing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000b6cfb.wav</td>\n",
       "      <td>Motorcycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00116cd2.wav</td>\n",
       "      <td>Marimba_and_xylophone,Glockenspiel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00127d14.wav</td>\n",
       "      <td>Water_tap_and_faucet,Sink_(filling_or_washing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0019adae.wav</td>\n",
       "      <td>Raindrop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname                                          labels\n",
       "0  00097e21.wav                    Bathtub_(filling_or_washing)\n",
       "1  000b6cfb.wav                                      Motorcycle\n",
       "2  00116cd2.wav              Marimba_and_xylophone,Glockenspiel\n",
       "3  00127d14.wav  Water_tap_and_faucet,Sink_(filling_or_washing)\n",
       "4  0019adae.wav                                        Raindrop"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf_noisy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:26.767747Z",
     "iopub.status.busy": "2020-10-04T17:50:26.767106Z",
     "iopub.status.idle": "2020-10-04T17:50:26.799624Z",
     "shell.execute_reply": "2020-10-04T17:50:26.799113Z"
    },
    "papermill": {
     "duration": 0.081768,
     "end_time": "2020-10-04T17:50:26.799733",
     "exception": false,
     "start_time": "2020-10-04T17:50:26.717965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161d2bb8.jpg</td>\n",
       "      <td>Bus,Microwave_oven</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abf3a850.jpg</td>\n",
       "      <td>Bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fd802069.jpg</td>\n",
       "      <td>Cheering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0f69e008_aug.jpg</td>\n",
       "      <td>Purr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5c51827a.jpg</td>\n",
       "      <td>Applause</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              fname              labels\n",
       "0      161d2bb8.jpg  Bus,Microwave_oven\n",
       "1      abf3a850.jpg                 Bus\n",
       "2      fd802069.jpg            Cheering\n",
       "3  0f69e008_aug.jpg                Purr\n",
       "4      5c51827a.jpg            Applause"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../input/sc2-total-aug-noisy-data/K_fold_data/K_fold_data/Noisy/Noisy_train_4.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:26.891820Z",
     "iopub.status.busy": "2020-10-04T17:50:26.891105Z",
     "iopub.status.idle": "2020-10-04T17:50:26.894039Z",
     "shell.execute_reply": "2020-10-04T17:50:26.894595Z"
    },
    "papermill": {
     "duration": 0.051477,
     "end_time": "2020-10-04T17:50:26.894730",
     "exception": false,
     "start_time": "2020-10-04T17:50:26.843253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19449, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:26.987322Z",
     "iopub.status.busy": "2020-10-04T17:50:26.986655Z",
     "iopub.status.idle": "2020-10-04T17:50:26.999823Z",
     "shell.execute_reply": "2020-10-04T17:50:26.999273Z"
    },
    "papermill": {
     "duration": 0.061575,
     "end_time": "2020-10-04T17:50:26.999946",
     "exception": false,
     "start_time": "2020-10-04T17:50:26.938371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4862, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df = pd.read_csv(\"../input/sc2-total-aug-noisy-data/K_fold_data/K_fold_data/Noisy/Noisy_cv_4.csv\")\n",
    "cv_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:27.092950Z",
     "iopub.status.busy": "2020-10-04T17:50:27.092292Z",
     "iopub.status.idle": "2020-10-04T17:50:27.111655Z",
     "shell.execute_reply": "2020-10-04T17:50:27.111147Z"
    },
    "papermill": {
     "duration": 0.067788,
     "end_time": "2020-10-04T17:50:27.111761",
     "exception": false,
     "start_time": "2020-10-04T17:50:27.043973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6078, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "test_df = pd.read_csv(\"../input/sc2-total-aug-noisy-data/K_fold_data/K_fold_data/Noisy/Noisy_test.csv\") \n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:27.208763Z",
     "iopub.status.busy": "2020-10-04T17:50:27.207905Z",
     "iopub.status.idle": "2020-10-04T17:50:28.106891Z",
     "shell.execute_reply": "2020-10-04T17:50:28.106230Z"
    },
    "papermill": {
     "duration": 0.950041,
     "end_time": "2020-10-04T17:50:28.107007",
     "exception": false,
     "start_time": "2020-10-04T17:50:27.156966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb_train = MultiLabelBinarizer()\n",
    "\n",
    "\n",
    "labels_train = mlb_train.fit_transform([ i.split(\",\") for i in list(train_df[\"labels\"])])\n",
    "\n",
    "\n",
    "labels_test = mlb_train.transform([ i.split(\",\") for i in list(test_df[\"labels\"])])\n",
    "\n",
    "\n",
    "#mlb_cv = MultiLabelBinarizer()\n",
    "labels_cv = mlb_train.transform([ i.split(\",\") for i in list(cv_df[\"labels\"])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:28.201301Z",
     "iopub.status.busy": "2020-10-04T17:50:28.200555Z",
     "iopub.status.idle": "2020-10-04T17:50:28.203455Z",
     "shell.execute_reply": "2020-10-04T17:50:28.204062Z"
    },
    "papermill": {
     "duration": 0.052482,
     "end_time": "2020-10-04T17:50:28.204189",
     "exception": false,
     "start_time": "2020-10-04T17:50:28.151707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6078, 80)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:28.312736Z",
     "iopub.status.busy": "2020-10-04T17:50:28.311127Z",
     "iopub.status.idle": "2020-10-04T17:50:28.313558Z",
     "shell.execute_reply": "2020-10-04T17:50:28.314075Z"
    },
    "papermill": {
     "duration": 0.06519,
     "end_time": "2020-10-04T17:50:28.314206",
     "exception": false,
     "start_time": "2020-10-04T17:50:28.249016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainmultidf=pd.DataFrame(data=labels_train,columns=list(mlb_train.classes_))\n",
    "trainmultidf[\"fname\"]=list(train_df[\"fname\"])\n",
    "\n",
    "testmultidf=pd.DataFrame(data=labels_test,columns=list(mlb_train.classes_))\n",
    "testmultidf[\"fname\"]=list(test_df[\"fname\"])\n",
    "\n",
    "\n",
    "cvmultidf=pd.DataFrame(data=labels_cv,columns=list(mlb_train.classes_))\n",
    "cvmultidf[\"fname\"]=list(cv_df[\"fname\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:28.411917Z",
     "iopub.status.busy": "2020-10-04T17:50:28.411093Z",
     "iopub.status.idle": "2020-10-04T17:50:37.668761Z",
     "shell.execute_reply": "2020-10-04T17:50:37.669649Z"
    },
    "papermill": {
     "duration": 9.31057,
     "end_time": "2020-10-04T17:50:37.669821",
     "exception": false,
     "start_time": "2020-10-04T17:50:28.359251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19449 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "#We change the ids for the images in the csv files to reflect their new status as jpgs\n",
    "#https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "datagen=ImageDataGenerator(rescale=1./255.,zoom_range=[0.5,1.0],brightness_range=[0.8,1.4])\n",
    "\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=trainmultidf,\n",
    "    directory=\"../input/sc2-total-aug-noisy-data/Total Images bucket Noisy/Total Images bucket Noisy\",\n",
    "    x_col=\"fname\",\n",
    "    y_col=list(mlb_train.classes_),\n",
    "    subset=\"training\",\n",
    "    batch_size=64,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=\"raw\",\n",
    "    #color_mode=\"grayscale\",\n",
    "    target_size=(128,128))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:37.765017Z",
     "iopub.status.busy": "2020-10-04T17:50:37.764138Z",
     "iopub.status.idle": "2020-10-04T17:50:37.768255Z",
     "shell.execute_reply": "2020-10-04T17:50:37.767705Z"
    },
    "papermill": {
     "duration": 0.0531,
     "end_time": "2020-10-04T17:50:37.768355",
     "exception": false,
     "start_time": "2020-10-04T17:50:37.715255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19449"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:37.863715Z",
     "iopub.status.busy": "2020-10-04T17:50:37.862862Z",
     "iopub.status.idle": "2020-10-04T17:50:37.866349Z",
     "shell.execute_reply": "2020-10-04T17:50:37.866791Z"
    },
    "papermill": {
     "duration": 0.053455,
     "end_time": "2020-10-04T17:50:37.866929",
     "exception": false,
     "start_time": "2020-10-04T17:50:37.813474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4862, 81)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvmultidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:37.994693Z",
     "iopub.status.busy": "2020-10-04T17:50:37.993721Z",
     "iopub.status.idle": "2020-10-04T17:50:37.998252Z",
     "shell.execute_reply": "2020-10-04T17:50:37.998714Z"
    },
    "papermill": {
     "duration": 0.079405,
     "end_time": "2020-10-04T17:50:37.998885",
     "exception": false,
     "start_time": "2020-10-04T17:50:37.919480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accelerating_and_revving_and_vroom</th>\n",
       "      <th>Accordion</th>\n",
       "      <th>Acoustic_guitar</th>\n",
       "      <th>Applause</th>\n",
       "      <th>Bark</th>\n",
       "      <th>Bass_drum</th>\n",
       "      <th>Bass_guitar</th>\n",
       "      <th>Bathtub_(filling_or_washing)</th>\n",
       "      <th>Bicycle_bell</th>\n",
       "      <th>Burping_and_eructation</th>\n",
       "      <th>...</th>\n",
       "      <th>Traffic_noise_and_roadway_noise</th>\n",
       "      <th>Trickle_and_dribble</th>\n",
       "      <th>Walk_and_footsteps</th>\n",
       "      <th>Water_tap_and_faucet</th>\n",
       "      <th>Waves_and_surf</th>\n",
       "      <th>Whispering</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Yell</th>\n",
       "      <th>Zipper_(clothing)</th>\n",
       "      <th>fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>663172d7.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>eaa46c62.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7b5bcb5a_aug.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>deda9c42.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9b85cccc_aug.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accelerating_and_revving_and_vroom  Accordion  Acoustic_guitar  Applause  \\\n",
       "0                                   0          0                0         0   \n",
       "1                                   0          0                0         1   \n",
       "2                                   0          0                0         0   \n",
       "3                                   0          0                0         0   \n",
       "4                                   0          0                0         0   \n",
       "\n",
       "   Bark  Bass_drum  Bass_guitar  Bathtub_(filling_or_washing)  Bicycle_bell  \\\n",
       "0     0          0            0                             0             0   \n",
       "1     0          0            0                             0             0   \n",
       "2     0          0            0                             0             0   \n",
       "3     0          0            1                             0             0   \n",
       "4     0          0            0                             0             0   \n",
       "\n",
       "   Burping_and_eructation  ...  Traffic_noise_and_roadway_noise  \\\n",
       "0                       0  ...                                0   \n",
       "1                       0  ...                                0   \n",
       "2                       0  ...                                0   \n",
       "3                       0  ...                                0   \n",
       "4                       0  ...                                0   \n",
       "\n",
       "   Trickle_and_dribble  Walk_and_footsteps  Water_tap_and_faucet  \\\n",
       "0                    0                   0                     0   \n",
       "1                    0                   0                     0   \n",
       "2                    0                   0                     0   \n",
       "3                    0                   0                     0   \n",
       "4                    0                   0                     0   \n",
       "\n",
       "   Waves_and_surf  Whispering  Writing  Yell  Zipper_(clothing)  \\\n",
       "0               0           0        0     0                  0   \n",
       "1               0           0        0     0                  0   \n",
       "2               0           0        0     0                  0   \n",
       "3               0           0        0     0                  0   \n",
       "4               0           0        0     0                  0   \n",
       "\n",
       "              fname  \n",
       "0      663172d7.jpg  \n",
       "1      eaa46c62.jpg  \n",
       "2  7b5bcb5a_aug.jpg  \n",
       "3      deda9c42.jpg  \n",
       "4  9b85cccc_aug.jpg  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvmultidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:38.112295Z",
     "iopub.status.busy": "2020-10-04T17:50:38.111189Z",
     "iopub.status.idle": "2020-10-04T17:50:39.137919Z",
     "shell.execute_reply": "2020-10-04T17:50:39.137167Z"
    },
    "papermill": {
     "duration": 1.085091,
     "end_time": "2020-10-04T17:50:39.138066",
     "exception": false,
     "start_time": "2020-10-04T17:50:38.052975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4862 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "valid_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "valid_generator=valid_datagen.flow_from_dataframe(\n",
    "    dataframe=cvmultidf,\n",
    "    directory=\"../input/sc2-total-aug-noisy-data/Total Images bucket Noisy/Total Images bucket Noisy\",\n",
    "    x_col=\"fname\",\n",
    "    y_col=list(mlb_train.classes_),\n",
    "   # subset=\"validation\",\n",
    "    batch_size=64,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=\"raw\",\n",
    "    #color_mode=\"grayscale\",\n",
    "    target_size=(128,128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:39.242052Z",
     "iopub.status.busy": "2020-10-04T17:50:39.241016Z",
     "iopub.status.idle": "2020-10-04T17:50:40.555150Z",
     "shell.execute_reply": "2020-10-04T17:50:40.555777Z"
    },
    "papermill": {
     "duration": 1.368907,
     "end_time": "2020-10-04T17:50:40.555940",
     "exception": false,
     "start_time": "2020-10-04T17:50:39.187033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6078 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "    dataframe=testmultidf,\n",
    "    directory=\"../input/sc2-total-aug-noisy-data/Total Images bucket Noisy/Total Images bucket Noisy\",\n",
    "    x_col=\"fname\",\n",
    "    y_col=None,\n",
    "    batch_size=64,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "   # color_mode=\"grayscale\",\n",
    "    target_size=(128,128))\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:40.662898Z",
     "iopub.status.busy": "2020-10-04T17:50:40.662287Z",
     "iopub.status.idle": "2020-10-04T17:50:40.716674Z",
     "shell.execute_reply": "2020-10-04T17:50:40.716116Z"
    },
    "papermill": {
     "duration": 0.112732,
     "end_time": "2020-10-04T17:50:40.716771",
     "exception": false,
     "start_time": "2020-10-04T17:50:40.604039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping \n",
    "from tensorflow.keras.layers import Dense, Flatten, LSTM, Conv2D, MaxPooling2D, Dropout, Activation, Input,BatchNormalization, AveragePooling2D,GlobalMaxPool2D,PReLU\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "from tensorflow.keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n",
    "                             EarlyStopping, ReduceLROnPlateau,CSVLogger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:40.827336Z",
     "iopub.status.busy": "2020-10-04T17:50:40.826728Z",
     "iopub.status.idle": "2020-10-04T17:50:50.010613Z",
     "shell.execute_reply": "2020-10-04T17:50:50.009899Z"
    },
    "papermill": {
     "duration": 9.237177,
     "end_time": "2020-10-04T17:50:50.010729",
     "exception": false,
     "start_time": "2020-10-04T17:50:40.773552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels.h5\n",
      "33193984/33188688 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#last_layer = model.get_layer('avg_pool').output\n",
    "\n",
    "image_input = Input(shape=(128,128, 3))\n",
    "model = tf.keras.applications.DenseNet121(input_tensor=image_input, include_top=True)\n",
    "last_layer = model.get_layer('avg_pool').output\n",
    "x= Flatten(name='flatten')(last_layer)\n",
    "#model=\n",
    "\n",
    "\n",
    "#output = Dense(80, activation='sigmoid', name='output_layer')(model.layers[-2].output)\n",
    "x= Dense(80)(x)\n",
    "output = Activation('sigmoid')(x)\n",
    "#out = Dense(num_classes, activation='softmax', name='output_layer')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:50.116332Z",
     "iopub.status.busy": "2020-10-04T17:50:50.115686Z",
     "iopub.status.idle": "2020-10-04T17:50:50.121670Z",
     "shell.execute_reply": "2020-10-04T17:50:50.121125Z"
    },
    "papermill": {
     "duration": 0.06082,
     "end_time": "2020-10-04T17:50:50.121777",
     "exception": false,
     "start_time": "2020-10-04T17:50:50.060957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf20286e90>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fcf20289990>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x7fcf20289ed0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fcf20291790>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:50.227663Z",
     "iopub.status.busy": "2020-10-04T17:50:50.227074Z",
     "iopub.status.idle": "2020-10-04T17:50:50.232719Z",
     "shell.execute_reply": "2020-10-04T17:50:50.233315Z"
    },
    "papermill": {
     "duration": 0.060814,
     "end_time": "2020-10-04T17:50:50.233436",
     "exception": false,
     "start_time": "2020-10-04T17:50:50.172622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fcf20286e90>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fcf20289990>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x7fcf20289ed0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fcf20291790>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:50.345599Z",
     "iopub.status.busy": "2020-10-04T17:50:50.344718Z",
     "iopub.status.idle": "2020-10-04T17:50:50.569709Z",
     "shell.execute_reply": "2020-10-04T17:50:50.570444Z"
    },
    "papermill": {
     "duration": 0.286952,
     "end_time": "2020-10-04T17:50:50.570617",
     "exception": false,
     "start_time": "2020-10-04T17:50:50.283665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 134, 134, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 64, 64, 64)   9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 64, 64, 64)   256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 64, 64, 64)   0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 66, 66, 64)   0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 32, 32, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 32, 32, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 32, 32, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 32, 32, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 32, 32, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 32, 32, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 32, 32, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 32, 32, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 32, 32, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 32, 32, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 32, 32, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 32, 32, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 32, 32, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 32, 32, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 32, 32, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 32, 32, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 32, 32, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 32, 32, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 32, 32, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 32, 32, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 32, 32, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 32, 32, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 32, 32, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 32, 32, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 32, 32, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 32, 32, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 32, 32, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 32, 32, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 32, 32, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 32, 32, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 32, 32, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 32, 32, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 32, 32, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 16, 16, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 16, 16, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 16, 16, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 16, 16, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 16, 16, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 16, 16, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 16, 16, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 16, 16, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 16, 16, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 16, 16, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 16, 16, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 16, 16, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 16, 16, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 16, 16, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 16, 16, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 16, 16, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 16, 16, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 16, 16, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 16, 16, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 16, 16, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 16, 16, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 16, 16, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 16, 16, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 16, 16, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 16, 16, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 16, 16, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 16, 16, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 16, 16, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 16, 16, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 16, 16, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 16, 16, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 16, 16, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 16, 16, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 16, 16, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 16, 16, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 16, 16, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 16, 16, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 16, 16, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 16, 16, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 16, 16, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 16, 16, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 16, 16, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 16, 16, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 16, 16, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 16, 16, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 16, 16, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 16, 16, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 16, 16, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 16, 16, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 16, 16, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 16, 16, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 16, 16, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 16, 16, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 16, 16, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 16, 16, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 16, 16, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 16, 16, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 16, 16, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 16, 16, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 16, 16, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 16, 16, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 8, 8, 256)    0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 8, 8, 256)    0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 8, 8, 128)    32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 8, 8, 128)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 8, 8, 288)    0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 8, 8, 288)    1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 8, 8, 288)    0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 8, 8, 128)    36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 8, 8, 128)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 8, 8, 320)    0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 8, 8, 320)    1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 8, 8, 320)    0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 8, 8, 128)    40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 8, 8, 128)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 8, 8, 352)    0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 8, 8, 352)    1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 8, 8, 352)    0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 8, 8, 128)    45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 8, 8, 128)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 8, 8, 384)    0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 8, 8, 384)    1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 8, 8, 384)    0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 8, 8, 128)    49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 8, 8, 128)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 8, 8, 416)    0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 8, 8, 416)    1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 8, 8, 416)    0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 8, 8, 128)    53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 8, 8, 128)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 8, 8, 448)    0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 8, 8, 448)    1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 8, 8, 448)    0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 8, 8, 128)    57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 8, 8, 128)    0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 8, 8, 480)    0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 8, 8, 480)    1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 8, 8, 480)    0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 8, 8, 128)    61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 8, 8, 128)    0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 8, 8, 512)    0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 8, 8, 512)    2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 8, 8, 512)    0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 8, 8, 128)    65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 8, 8, 128)    0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 8, 8, 544)    0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 8, 8, 544)    2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 8, 8, 544)    0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 8, 8, 128)    69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 8, 8, 576)    0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 8, 8, 576)    2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 8, 8, 576)    0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 8, 8, 128)    73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 8, 8, 608)    0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 8, 8, 608)    2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 8, 8, 608)    0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 8, 8, 128)    77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 8, 8, 640)    0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 8, 8, 640)    2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 8, 8, 640)    0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 8, 8, 128)    81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 8, 8, 672)    0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 8, 8, 672)    2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 8, 8, 672)    0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 8, 8, 128)    86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 8, 8, 704)    0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 8, 8, 704)    2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 8, 8, 704)    0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 8, 8, 128)    90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 8, 8, 736)    0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 8, 8, 736)    2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 8, 8, 736)    0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 8, 8, 128)    94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 8, 8, 768)    0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 8, 8, 768)    3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 8, 8, 768)    0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 8, 8, 128)    98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 8, 8, 800)    0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 8, 8, 800)    3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 8, 8, 800)    0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 8, 8, 128)    102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 8, 8, 832)    0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 8, 8, 832)    3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 8, 8, 832)    0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 8, 8, 128)    106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 8, 8, 864)    0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 8, 8, 864)    3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 8, 8, 864)    0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 8, 8, 128)    110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 8, 8, 896)    0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 8, 8, 896)    3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 8, 8, 896)    0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 8, 8, 128)    114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 8, 8, 928)    0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 8, 8, 928)    3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 8, 8, 928)    0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 8, 8, 128)    118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 8, 8, 960)    0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 8, 8, 960)    3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 8, 8, 960)    0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 8, 8, 128)    122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 8, 8, 992)    0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 8, 8, 992)    3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 8, 8, 992)    0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 8, 8, 128)    126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 8, 8, 1024)   0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 8, 8, 1024)   4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 8, 8, 1024)   0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 8, 8, 512)    524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 4, 4, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 4, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 4, 4, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 4, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 4, 4, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 4, 4, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 4, 4, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 4, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 4, 4, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 4, 4, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 4, 4, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 4, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 4, 4, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 4, 4, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 4, 4, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 4, 4, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 4, 4, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 4, 4, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 4, 4, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 4, 4, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 4, 4, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 4, 4, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 4, 4, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 4, 4, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 4, 4, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 4, 4, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 4, 4, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 4, 4, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 4, 4, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 4, 4, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 4, 4, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 4, 4, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 4, 4, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 4, 4, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 4, 4, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 4, 4, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 4, 4, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 4, 4, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 4, 4, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 4, 4, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 4, 4, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 4, 4, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 4, 4, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 4, 4, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 4, 4, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 4, 4, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 4, 4, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 4, 4, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 4, 4, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 4, 4, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 4, 4, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 4, 4, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 4, 4, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 4, 4, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 4, 4, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 4, 4, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 4, 4, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 4, 4, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 4, 4, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 4, 4, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 4, 4, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 4, 4, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 4, 4, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 4, 4, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 4, 4, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 4, 4, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 4, 4, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 4, 4, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 4, 4, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 4, 4, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 4, 4, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 4, 4, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 4, 4, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 4, 4, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 4, 4, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 4, 4, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 4, 4, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 4, 4, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1024)         0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1024)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 80)           82000       flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 80)           0           dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 7,119,504\n",
      "Trainable params: 7,035,856\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_densenet169_model = Model(inputs=image_input,outputs= output)\n",
    "custom_densenet169_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:50.781309Z",
     "iopub.status.busy": "2020-10-04T17:50:50.780397Z",
     "iopub.status.idle": "2020-10-04T17:50:50.785627Z",
     "shell.execute_reply": "2020-10-04T17:50:50.786317Z"
    },
    "papermill": {
     "duration": 0.135137,
     "end_time": "2020-10-04T17:50:50.786511",
     "exception": false,
     "start_time": "2020-10-04T17:50:50.651374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from tensorflow.keras.utils import plot_model\n",
    "#plot_model(custom_densenet169_model, 'model_resnet50.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:50.940595Z",
     "iopub.status.busy": "2020-10-04T17:50:50.935633Z",
     "iopub.status.idle": "2020-10-04T17:50:50.955370Z",
     "shell.execute_reply": "2020-10-04T17:50:50.954721Z"
    },
    "papermill": {
     "duration": 0.101664,
     "end_time": "2020-10-04T17:50:50.955480",
     "exception": false,
     "start_time": "2020-10-04T17:50:50.853816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr=0.0009)#tf.keras.optimizers.RMSprop(lr=0.3, decay=1e-6) \n",
    "#tf.keras.optimizers.Adam(lr=0.001)#RMSprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "custom_densenet169_model.compile(loss=tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.SUM),#,label_smoothing=0.7#'categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "               metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:51.065940Z",
     "iopub.status.busy": "2020-10-04T17:50:51.065325Z",
     "iopub.status.idle": "2020-10-04T17:50:51.069685Z",
     "shell.execute_reply": "2020-10-04T17:50:51.069189Z"
    },
    "papermill": {
     "duration": 0.061248,
     "end_time": "2020-10-04T17:50:51.069775",
     "exception": false,
     "start_time": "2020-10-04T17:50:51.008527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Fitting keras model, no test gen for now\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "#STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:51.181268Z",
     "iopub.status.busy": "2020-10-04T17:50:51.180513Z",
     "iopub.status.idle": "2020-10-04T17:50:51.183975Z",
     "shell.execute_reply": "2020-10-04T17:50:51.184434Z"
    },
    "papermill": {
     "duration": 0.062207,
     "end_time": "2020-10-04T17:50:51.184546",
     "exception": false,
     "start_time": "2020-10-04T17:50:51.122339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:51.300229Z",
     "iopub.status.busy": "2020-10-04T17:50:51.298520Z",
     "iopub.status.idle": "2020-10-04T17:50:51.300962Z",
     "shell.execute_reply": "2020-10-04T17:50:51.301426Z"
    },
    "papermill": {
     "duration": 0.063556,
     "end_time": "2020-10-04T17:50:51.301534",
     "exception": false,
     "start_time": "2020-10-04T17:50:51.237978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# simple early stopping\n",
    "#earlyStop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100,)\n",
    "#https://machinelearningmastery.com/check-point-deep-learning-models-keras/\n",
    "\n",
    "\n",
    "#model_checkpoint = ModelCheckpoint('weights_cnn_lstm.best.hdf5', monitor='val_categorical_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "#filepath=\"weights-improvement-{epoch:02d}-{val_categorical_accuracy:.2f}.hdf5\"\n",
    "\n",
    "\n",
    "csv_logger = CSVLogger(filename='../working/training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.6,\n",
    "                              patience=6, min_lr=0,verbose=1)\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\"DenseNer201.best_weights-128.hdf5\", monitor='val_categorical_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "# fit model\n",
    "\n",
    "#es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20, min_delta=0.001 )\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', mode='max', verbose=1, patience=30, min_delta=0.001 )\n",
    "\n",
    "callbacks_list = [model_checkpoint, csv_logger, reduceLROnPlat,es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:51.411422Z",
     "iopub.status.busy": "2020-10-04T17:50:51.410689Z",
     "iopub.status.idle": "2020-10-04T17:50:51.414549Z",
     "shell.execute_reply": "2020-10-04T17:50:51.414047Z"
    },
    "papermill": {
     "duration": 0.060087,
     "end_time": "2020-10-04T17:50:51.414641",
     "exception": false,
     "start_time": "2020-10-04T17:50:51.354554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#custom_densenet169_model.load_weights(\"../input/sc2weights/total.best_weights.hdf5\")\n",
    "#custom_densenet169_model.load_weights(\"../input/sc2weights/total.best_weights_iter2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T17:50:51.531135Z",
     "iopub.status.busy": "2020-10-04T17:50:51.530531Z",
     "iopub.status.idle": "2020-10-04T23:23:46.416223Z",
     "shell.execute_reply": "2020-10-04T23:23:46.417377Z"
    },
    "papermill": {
     "duration": 19974.949051,
     "end_time": "2020-10-04T23:23:46.417547",
     "exception": false,
     "start_time": "2020-10-04T17:50:51.468496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 4.8347 - categorical_accuracy: 0.1271\n",
      "Epoch 00001: val_categorical_accuracy improved from -inf to 0.11812, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 144s 475ms/step - loss: 4.8347 - categorical_accuracy: 0.1271 - val_loss: 4.4728 - val_categorical_accuracy: 0.1181\n",
      "Epoch 2/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 3.7624 - categorical_accuracy: 0.2167\n",
      "Epoch 00002: val_categorical_accuracy improved from 0.11812 to 0.15104, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 129s 426ms/step - loss: 3.7624 - categorical_accuracy: 0.2167 - val_loss: 4.1778 - val_categorical_accuracy: 0.1510\n",
      "Epoch 3/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 3.5361 - categorical_accuracy: 0.2609\n",
      "Epoch 00003: val_categorical_accuracy improved from 0.15104 to 0.19479, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 130s 431ms/step - loss: 3.5361 - categorical_accuracy: 0.2609 - val_loss: 3.9896 - val_categorical_accuracy: 0.1948\n",
      "Epoch 4/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 3.3648 - categorical_accuracy: 0.2920\n",
      "Epoch 00004: val_categorical_accuracy did not improve from 0.19479\n",
      "303/303 [==============================] - 128s 424ms/step - loss: 3.3648 - categorical_accuracy: 0.2920 - val_loss: 4.4082 - val_categorical_accuracy: 0.1606\n",
      "Epoch 5/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 3.2233 - categorical_accuracy: 0.3232\n",
      "Epoch 00005: val_categorical_accuracy improved from 0.19479 to 0.24083, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 136s 449ms/step - loss: 3.2233 - categorical_accuracy: 0.3232 - val_loss: 3.7242 - val_categorical_accuracy: 0.2408\n",
      "Epoch 6/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 3.0902 - categorical_accuracy: 0.3501\n",
      "Epoch 00006: val_categorical_accuracy did not improve from 0.24083\n",
      "303/303 [==============================] - 133s 439ms/step - loss: 3.0902 - categorical_accuracy: 0.3501 - val_loss: 3.8273 - val_categorical_accuracy: 0.2252\n",
      "Epoch 7/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 2.9584 - categorical_accuracy: 0.3726\n",
      "Epoch 00007: val_categorical_accuracy did not improve from 0.24083\n",
      "303/303 [==============================] - 136s 448ms/step - loss: 2.9584 - categorical_accuracy: 0.3726 - val_loss: 4.0705 - val_categorical_accuracy: 0.2354\n",
      "Epoch 8/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 2.8302 - categorical_accuracy: 0.3927\n",
      "Epoch 00008: val_categorical_accuracy improved from 0.24083 to 0.28771, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 142s 469ms/step - loss: 2.8302 - categorical_accuracy: 0.3927 - val_loss: 3.7572 - val_categorical_accuracy: 0.2877\n",
      "Epoch 9/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 2.6991 - categorical_accuracy: 0.4281\n",
      "Epoch 00009: val_categorical_accuracy improved from 0.28771 to 0.30562, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 145s 478ms/step - loss: 2.6991 - categorical_accuracy: 0.4281 - val_loss: 3.5162 - val_categorical_accuracy: 0.3056\n",
      "Epoch 10/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 2.5477 - categorical_accuracy: 0.4532\n",
      "Epoch 00010: val_categorical_accuracy did not improve from 0.30562\n",
      "303/303 [==============================] - 145s 478ms/step - loss: 2.5477 - categorical_accuracy: 0.4532 - val_loss: 3.6784 - val_categorical_accuracy: 0.2865\n",
      "Epoch 11/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 2.3770 - categorical_accuracy: 0.4887\n",
      "Epoch 00011: val_categorical_accuracy did not improve from 0.30562\n",
      "303/303 [==============================] - 146s 480ms/step - loss: 2.3770 - categorical_accuracy: 0.4887 - val_loss: 3.7722 - val_categorical_accuracy: 0.2798\n",
      "Epoch 12/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 2.2273 - categorical_accuracy: 0.5197\n",
      "Epoch 00012: val_categorical_accuracy did not improve from 0.30562\n",
      "303/303 [==============================] - 145s 477ms/step - loss: 2.2273 - categorical_accuracy: 0.5197 - val_loss: 4.2471 - val_categorical_accuracy: 0.2419\n",
      "Epoch 13/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 2.0772 - categorical_accuracy: 0.5531\n",
      "Epoch 00013: val_categorical_accuracy did not improve from 0.30562\n",
      "303/303 [==============================] - 151s 498ms/step - loss: 2.0772 - categorical_accuracy: 0.5531 - val_loss: 3.8645 - val_categorical_accuracy: 0.2788\n",
      "Epoch 14/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.8975 - categorical_accuracy: 0.5880\n",
      "Epoch 00014: val_categorical_accuracy did not improve from 0.30562\n",
      "303/303 [==============================] - 153s 503ms/step - loss: 1.8975 - categorical_accuracy: 0.5880 - val_loss: 4.0178 - val_categorical_accuracy: 0.2775\n",
      "Epoch 15/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.7794 - categorical_accuracy: 0.6187\n",
      "Epoch 00015: val_categorical_accuracy did not improve from 0.30562\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0005399999907240271.\n",
      "303/303 [==============================] - 155s 511ms/step - loss: 1.7794 - categorical_accuracy: 0.6187 - val_loss: 4.6298 - val_categorical_accuracy: 0.2283\n",
      "Epoch 16/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.2627 - categorical_accuracy: 0.7299\n",
      "Epoch 00016: val_categorical_accuracy improved from 0.30562 to 0.34833, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 153s 505ms/step - loss: 1.2627 - categorical_accuracy: 0.7299 - val_loss: 3.5433 - val_categorical_accuracy: 0.3483\n",
      "Epoch 17/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 1.0045 - categorical_accuracy: 0.7843\n",
      "Epoch 00017: val_categorical_accuracy improved from 0.34833 to 0.37896, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 151s 497ms/step - loss: 1.0045 - categorical_accuracy: 0.7843 - val_loss: 3.5554 - val_categorical_accuracy: 0.3790\n",
      "Epoch 18/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.8729 - categorical_accuracy: 0.8059\n",
      "Epoch 00018: val_categorical_accuracy improved from 0.37896 to 0.38688, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 154s 509ms/step - loss: 0.8729 - categorical_accuracy: 0.8059 - val_loss: 3.5054 - val_categorical_accuracy: 0.3869\n",
      "Epoch 19/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.7614 - categorical_accuracy: 0.8283\n",
      "Epoch 00019: val_categorical_accuracy did not improve from 0.38688\n",
      "303/303 [==============================] - 150s 496ms/step - loss: 0.7614 - categorical_accuracy: 0.8283 - val_loss: 3.9680 - val_categorical_accuracy: 0.3440\n",
      "Epoch 20/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.6953 - categorical_accuracy: 0.8421\n",
      "Epoch 00020: val_categorical_accuracy did not improve from 0.38688\n",
      "303/303 [==============================] - 151s 498ms/step - loss: 0.6953 - categorical_accuracy: 0.8421 - val_loss: 4.1112 - val_categorical_accuracy: 0.3400\n",
      "Epoch 21/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.6006 - categorical_accuracy: 0.8547\n",
      "Epoch 00021: val_categorical_accuracy improved from 0.38688 to 0.38875, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 149s 492ms/step - loss: 0.6006 - categorical_accuracy: 0.8547 - val_loss: 3.8636 - val_categorical_accuracy: 0.3887\n",
      "Epoch 22/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.5587 - categorical_accuracy: 0.8590\n",
      "Epoch 00022: val_categorical_accuracy did not improve from 0.38875\n",
      "303/303 [==============================] - 143s 472ms/step - loss: 0.5587 - categorical_accuracy: 0.8590 - val_loss: 4.4314 - val_categorical_accuracy: 0.3350\n",
      "Epoch 23/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.5010 - categorical_accuracy: 0.8659\n",
      "Epoch 00023: val_categorical_accuracy did not improve from 0.38875\n",
      "303/303 [==============================] - 141s 466ms/step - loss: 0.5010 - categorical_accuracy: 0.8659 - val_loss: 4.1489 - val_categorical_accuracy: 0.3794\n",
      "Epoch 24/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.4651 - categorical_accuracy: 0.8693\n",
      "Epoch 00024: val_categorical_accuracy improved from 0.38875 to 0.41000, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 140s 461ms/step - loss: 0.4651 - categorical_accuracy: 0.8693 - val_loss: 4.1263 - val_categorical_accuracy: 0.4100\n",
      "Epoch 25/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.4398 - categorical_accuracy: 0.8749\n",
      "Epoch 00025: val_categorical_accuracy did not improve from 0.41000\n",
      "303/303 [==============================] - 137s 451ms/step - loss: 0.4398 - categorical_accuracy: 0.8749 - val_loss: 4.2994 - val_categorical_accuracy: 0.3752\n",
      "Epoch 26/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.4048 - categorical_accuracy: 0.8784\n",
      "Epoch 00026: val_categorical_accuracy improved from 0.41000 to 0.41646, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 137s 452ms/step - loss: 0.4048 - categorical_accuracy: 0.8784 - val_loss: 4.2680 - val_categorical_accuracy: 0.4165\n",
      "Epoch 27/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3565 - categorical_accuracy: 0.8869\n",
      "Epoch 00027: val_categorical_accuracy did not improve from 0.41646\n",
      "303/303 [==============================] - 136s 449ms/step - loss: 0.3565 - categorical_accuracy: 0.8869 - val_loss: 5.2219 - val_categorical_accuracy: 0.3044\n",
      "Epoch 28/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3706 - categorical_accuracy: 0.8849\n",
      "Epoch 00028: val_categorical_accuracy did not improve from 0.41646\n",
      "303/303 [==============================] - 136s 448ms/step - loss: 0.3706 - categorical_accuracy: 0.8849 - val_loss: 4.6022 - val_categorical_accuracy: 0.3654\n",
      "Epoch 29/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3426 - categorical_accuracy: 0.8827\n",
      "Epoch 00029: val_categorical_accuracy did not improve from 0.41646\n",
      "303/303 [==============================] - 136s 449ms/step - loss: 0.3426 - categorical_accuracy: 0.8827 - val_loss: 4.7837 - val_categorical_accuracy: 0.3956\n",
      "Epoch 30/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.3290 - categorical_accuracy: 0.8879\n",
      "Epoch 00030: val_categorical_accuracy did not improve from 0.41646\n",
      "303/303 [==============================] - 135s 447ms/step - loss: 0.3290 - categorical_accuracy: 0.8879 - val_loss: 4.5188 - val_categorical_accuracy: 0.4131\n",
      "Epoch 31/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.2985 - categorical_accuracy: 0.8917\n",
      "Epoch 00031: val_categorical_accuracy did not improve from 0.41646\n",
      "303/303 [==============================] - 135s 446ms/step - loss: 0.2985 - categorical_accuracy: 0.8917 - val_loss: 5.1756 - val_categorical_accuracy: 0.3537\n",
      "Epoch 32/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.2906 - categorical_accuracy: 0.8914\n",
      "Epoch 00032: val_categorical_accuracy did not improve from 0.41646\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.00032399998744949695.\n",
      "303/303 [==============================] - 135s 447ms/step - loss: 0.2906 - categorical_accuracy: 0.8914 - val_loss: 4.8673 - val_categorical_accuracy: 0.3856\n",
      "Epoch 33/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.1754 - categorical_accuracy: 0.9025\n",
      "Epoch 00033: val_categorical_accuracy improved from 0.41646 to 0.44604, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 137s 451ms/step - loss: 0.1754 - categorical_accuracy: 0.9025 - val_loss: 4.3829 - val_categorical_accuracy: 0.4460\n",
      "Epoch 34/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.1126 - categorical_accuracy: 0.9082\n",
      "Epoch 00034: val_categorical_accuracy improved from 0.44604 to 0.46583, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 137s 454ms/step - loss: 0.1126 - categorical_accuracy: 0.9082 - val_loss: 4.2668 - val_categorical_accuracy: 0.4658\n",
      "Epoch 35/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.1035 - categorical_accuracy: 0.9084\n",
      "Epoch 00035: val_categorical_accuracy improved from 0.46583 to 0.46750, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 138s 457ms/step - loss: 0.1035 - categorical_accuracy: 0.9084 - val_loss: 4.3147 - val_categorical_accuracy: 0.4675\n",
      "Epoch 36/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0937 - categorical_accuracy: 0.9095\n",
      "Epoch 00036: val_categorical_accuracy improved from 0.46750 to 0.47708, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 150s 497ms/step - loss: 0.0937 - categorical_accuracy: 0.9095 - val_loss: 4.2816 - val_categorical_accuracy: 0.4771\n",
      "Epoch 37/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0894 - categorical_accuracy: 0.9109\n",
      "Epoch 00037: val_categorical_accuracy did not improve from 0.47708\n",
      "303/303 [==============================] - 147s 484ms/step - loss: 0.0894 - categorical_accuracy: 0.9109 - val_loss: 4.5790 - val_categorical_accuracy: 0.4465\n",
      "Epoch 38/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.1001 - categorical_accuracy: 0.9107\n",
      "Epoch 00038: val_categorical_accuracy did not improve from 0.47708\n",
      "303/303 [==============================] - 152s 502ms/step - loss: 0.1001 - categorical_accuracy: 0.9107 - val_loss: 4.5635 - val_categorical_accuracy: 0.4498\n",
      "Epoch 39/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.1074 - categorical_accuracy: 0.9065\n",
      "Epoch 00039: val_categorical_accuracy did not improve from 0.47708\n",
      "303/303 [==============================] - 152s 502ms/step - loss: 0.1074 - categorical_accuracy: 0.9065 - val_loss: 4.9717 - val_categorical_accuracy: 0.4277\n",
      "Epoch 40/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.1052 - categorical_accuracy: 0.9111\n",
      "Epoch 00040: val_categorical_accuracy did not improve from 0.47708\n",
      "303/303 [==============================] - 149s 491ms/step - loss: 0.1052 - categorical_accuracy: 0.9111 - val_loss: 4.7311 - val_categorical_accuracy: 0.4581\n",
      "Epoch 41/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.1115 - categorical_accuracy: 0.9096\n",
      "Epoch 00041: val_categorical_accuracy did not improve from 0.47708\n",
      "303/303 [==============================] - 148s 489ms/step - loss: 0.1115 - categorical_accuracy: 0.9096 - val_loss: 4.7237 - val_categorical_accuracy: 0.4475\n",
      "Epoch 42/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.1130 - categorical_accuracy: 0.9104\n",
      "Epoch 00042: val_categorical_accuracy did not improve from 0.47708\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00019439999596215785.\n",
      "303/303 [==============================] - 147s 485ms/step - loss: 0.1130 - categorical_accuracy: 0.9104 - val_loss: 4.9557 - val_categorical_accuracy: 0.4294\n",
      "Epoch 43/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0745 - categorical_accuracy: 0.9100\n",
      "Epoch 00043: val_categorical_accuracy did not improve from 0.47708\n",
      "303/303 [==============================] - 137s 454ms/step - loss: 0.0745 - categorical_accuracy: 0.9100 - val_loss: 4.7995 - val_categorical_accuracy: 0.4479\n",
      "Epoch 44/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0482 - categorical_accuracy: 0.9104\n",
      "Epoch 00044: val_categorical_accuracy did not improve from 0.47708\n",
      "303/303 [==============================] - 142s 470ms/step - loss: 0.0482 - categorical_accuracy: 0.9104 - val_loss: 4.6299 - val_categorical_accuracy: 0.4704\n",
      "Epoch 45/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0469 - categorical_accuracy: 0.9117\n",
      "Epoch 00045: val_categorical_accuracy did not improve from 0.47708\n",
      "303/303 [==============================] - 139s 460ms/step - loss: 0.0469 - categorical_accuracy: 0.9117 - val_loss: 4.9659 - val_categorical_accuracy: 0.4485\n",
      "Epoch 46/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0419 - categorical_accuracy: 0.9123\n",
      "Epoch 00046: val_categorical_accuracy did not improve from 0.47708\n",
      "303/303 [==============================] - 139s 458ms/step - loss: 0.0419 - categorical_accuracy: 0.9123 - val_loss: 4.8737 - val_categorical_accuracy: 0.4485\n",
      "Epoch 47/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0424 - categorical_accuracy: 0.9129\n",
      "Epoch 00047: val_categorical_accuracy improved from 0.47708 to 0.47875, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 142s 468ms/step - loss: 0.0424 - categorical_accuracy: 0.9129 - val_loss: 4.7062 - val_categorical_accuracy: 0.4787\n",
      "Epoch 48/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0424 - categorical_accuracy: 0.9110\n",
      "Epoch 00048: val_categorical_accuracy did not improve from 0.47875\n",
      "303/303 [==============================] - 140s 462ms/step - loss: 0.0424 - categorical_accuracy: 0.9110 - val_loss: 4.9043 - val_categorical_accuracy: 0.4679\n",
      "Epoch 49/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0400 - categorical_accuracy: 0.9120\n",
      "Epoch 00049: val_categorical_accuracy did not improve from 0.47875\n",
      "303/303 [==============================] - 142s 468ms/step - loss: 0.0400 - categorical_accuracy: 0.9120 - val_loss: 5.0460 - val_categorical_accuracy: 0.4527\n",
      "Epoch 50/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0428 - categorical_accuracy: 0.9115\n",
      "Epoch 00050: val_categorical_accuracy did not improve from 0.47875\n",
      "303/303 [==============================] - 144s 476ms/step - loss: 0.0428 - categorical_accuracy: 0.9115 - val_loss: 4.8782 - val_categorical_accuracy: 0.4727\n",
      "Epoch 51/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0421 - categorical_accuracy: 0.9110\n",
      "Epoch 00051: val_categorical_accuracy did not improve from 0.47875\n",
      "303/303 [==============================] - 145s 478ms/step - loss: 0.0421 - categorical_accuracy: 0.9110 - val_loss: 5.3267 - val_categorical_accuracy: 0.4423\n",
      "Epoch 52/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0428 - categorical_accuracy: 0.9109\n",
      "Epoch 00052: val_categorical_accuracy did not improve from 0.47875\n",
      "303/303 [==============================] - 147s 487ms/step - loss: 0.0428 - categorical_accuracy: 0.9109 - val_loss: 5.5513 - val_categorical_accuracy: 0.4169\n",
      "Epoch 53/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0467 - categorical_accuracy: 0.9116\n",
      "Epoch 00053: val_categorical_accuracy did not improve from 0.47875\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0001166399975772947.\n",
      "303/303 [==============================] - 148s 489ms/step - loss: 0.0467 - categorical_accuracy: 0.9116 - val_loss: 5.0192 - val_categorical_accuracy: 0.4552\n",
      "Epoch 54/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0296 - categorical_accuracy: 0.9105\n",
      "Epoch 00054: val_categorical_accuracy improved from 0.47875 to 0.48521, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 143s 471ms/step - loss: 0.0296 - categorical_accuracy: 0.9105 - val_loss: 4.8471 - val_categorical_accuracy: 0.4852\n",
      "Epoch 55/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0231 - categorical_accuracy: 0.9124\n",
      "Epoch 00055: val_categorical_accuracy improved from 0.48521 to 0.50354, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 138s 457ms/step - loss: 0.0231 - categorical_accuracy: 0.9124 - val_loss: 4.7257 - val_categorical_accuracy: 0.5035\n",
      "Epoch 56/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0214 - categorical_accuracy: 0.9096\n",
      "Epoch 00056: val_categorical_accuracy improved from 0.50354 to 0.50542, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 136s 449ms/step - loss: 0.0214 - categorical_accuracy: 0.9096 - val_loss: 4.7354 - val_categorical_accuracy: 0.5054\n",
      "Epoch 57/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0203 - categorical_accuracy: 0.9105\n",
      "Epoch 00057: val_categorical_accuracy did not improve from 0.50542\n",
      "303/303 [==============================] - 136s 449ms/step - loss: 0.0203 - categorical_accuracy: 0.9105 - val_loss: 5.2330 - val_categorical_accuracy: 0.4569\n",
      "Epoch 58/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0192 - categorical_accuracy: 0.9121\n",
      "Epoch 00058: val_categorical_accuracy did not improve from 0.50542\n",
      "303/303 [==============================] - 136s 449ms/step - loss: 0.0192 - categorical_accuracy: 0.9121 - val_loss: 4.7983 - val_categorical_accuracy: 0.5004\n",
      "Epoch 59/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0192 - categorical_accuracy: 0.9119\n",
      "Epoch 00059: val_categorical_accuracy did not improve from 0.50542\n",
      "303/303 [==============================] - 135s 446ms/step - loss: 0.0192 - categorical_accuracy: 0.9119 - val_loss: 4.8647 - val_categorical_accuracy: 0.4896\n",
      "Epoch 60/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0180 - categorical_accuracy: 0.9122\n",
      "Epoch 00060: val_categorical_accuracy did not improve from 0.50542\n",
      "303/303 [==============================] - 136s 448ms/step - loss: 0.0180 - categorical_accuracy: 0.9122 - val_loss: 5.3201 - val_categorical_accuracy: 0.4596\n",
      "Epoch 61/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0187 - categorical_accuracy: 0.9118\n",
      "Epoch 00061: val_categorical_accuracy did not improve from 0.50542\n",
      "303/303 [==============================] - 137s 451ms/step - loss: 0.0187 - categorical_accuracy: 0.9118 - val_loss: 4.9876 - val_categorical_accuracy: 0.4873\n",
      "Epoch 62/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0177 - categorical_accuracy: 0.9156\n",
      "Epoch 00062: val_categorical_accuracy did not improve from 0.50542\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 6.998399767326191e-05.\n",
      "303/303 [==============================] - 137s 451ms/step - loss: 0.0177 - categorical_accuracy: 0.9156 - val_loss: 5.1035 - val_categorical_accuracy: 0.4765\n",
      "Epoch 63/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0137 - categorical_accuracy: 0.9137\n",
      "Epoch 00063: val_categorical_accuracy did not improve from 0.50542\n",
      "303/303 [==============================] - 138s 455ms/step - loss: 0.0137 - categorical_accuracy: 0.9137 - val_loss: 5.1466 - val_categorical_accuracy: 0.4729\n",
      "Epoch 64/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0133 - categorical_accuracy: 0.9116\n",
      "Epoch 00064: val_categorical_accuracy did not improve from 0.50542\n",
      "303/303 [==============================] - 141s 464ms/step - loss: 0.0133 - categorical_accuracy: 0.9116 - val_loss: 5.1035 - val_categorical_accuracy: 0.4785\n",
      "Epoch 65/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0103 - categorical_accuracy: 0.9126\n",
      "Epoch 00065: val_categorical_accuracy did not improve from 0.50542\n",
      "303/303 [==============================] - 140s 463ms/step - loss: 0.0103 - categorical_accuracy: 0.9126 - val_loss: 4.8819 - val_categorical_accuracy: 0.5052\n",
      "Epoch 66/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0116 - categorical_accuracy: 0.9134\n",
      "Epoch 00066: val_categorical_accuracy did not improve from 0.50542\n",
      "303/303 [==============================] - 141s 467ms/step - loss: 0.0116 - categorical_accuracy: 0.9134 - val_loss: 4.9052 - val_categorical_accuracy: 0.5044\n",
      "Epoch 67/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0106 - categorical_accuracy: 0.9115\n",
      "Epoch 00067: val_categorical_accuracy improved from 0.50542 to 0.51146, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 144s 477ms/step - loss: 0.0106 - categorical_accuracy: 0.9115 - val_loss: 4.8847 - val_categorical_accuracy: 0.5115\n",
      "Epoch 68/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0105 - categorical_accuracy: 0.9130\n",
      "Epoch 00068: val_categorical_accuracy did not improve from 0.51146\n",
      "303/303 [==============================] - 144s 474ms/step - loss: 0.0105 - categorical_accuracy: 0.9130 - val_loss: 5.0418 - val_categorical_accuracy: 0.4919\n",
      "Epoch 69/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0087 - categorical_accuracy: 0.9134\n",
      "Epoch 00069: val_categorical_accuracy improved from 0.51146 to 0.51458, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 147s 484ms/step - loss: 0.0087 - categorical_accuracy: 0.9134 - val_loss: 4.8912 - val_categorical_accuracy: 0.5146\n",
      "Epoch 70/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0092 - categorical_accuracy: 0.9117\n",
      "Epoch 00070: val_categorical_accuracy did not improve from 0.51458\n",
      "303/303 [==============================] - 145s 478ms/step - loss: 0.0092 - categorical_accuracy: 0.9117 - val_loss: 4.8929 - val_categorical_accuracy: 0.5104\n",
      "Epoch 71/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0102 - categorical_accuracy: 0.9149\n",
      "Epoch 00071: val_categorical_accuracy did not improve from 0.51458\n",
      "303/303 [==============================] - 146s 481ms/step - loss: 0.0102 - categorical_accuracy: 0.9149 - val_loss: 5.1758 - val_categorical_accuracy: 0.4904\n",
      "Epoch 72/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0100 - categorical_accuracy: 0.9118\n",
      "Epoch 00072: val_categorical_accuracy did not improve from 0.51458\n",
      "303/303 [==============================] - 148s 488ms/step - loss: 0.0100 - categorical_accuracy: 0.9118 - val_loss: 4.9485 - val_categorical_accuracy: 0.5015\n",
      "Epoch 73/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0088 - categorical_accuracy: 0.9142\n",
      "Epoch 00073: val_categorical_accuracy did not improve from 0.51458\n",
      "303/303 [==============================] - 149s 491ms/step - loss: 0.0088 - categorical_accuracy: 0.9142 - val_loss: 5.1306 - val_categorical_accuracy: 0.4935\n",
      "Epoch 74/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0071 - categorical_accuracy: 0.9132\n",
      "Epoch 00074: val_categorical_accuracy did not improve from 0.51458\n",
      "303/303 [==============================] - 152s 501ms/step - loss: 0.0071 - categorical_accuracy: 0.9132 - val_loss: 5.0583 - val_categorical_accuracy: 0.4954\n",
      "Epoch 75/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0091 - categorical_accuracy: 0.9107\n",
      "Epoch 00075: val_categorical_accuracy did not improve from 0.51458\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 4.199039685772732e-05.\n",
      "303/303 [==============================] - 149s 493ms/step - loss: 0.0091 - categorical_accuracy: 0.9107 - val_loss: 5.0471 - val_categorical_accuracy: 0.5054\n",
      "Epoch 76/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0081 - categorical_accuracy: 0.9116\n",
      "Epoch 00076: val_categorical_accuracy improved from 0.51458 to 0.51917, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 151s 498ms/step - loss: 0.0081 - categorical_accuracy: 0.9116 - val_loss: 4.9074 - val_categorical_accuracy: 0.5192\n",
      "Epoch 77/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0074 - categorical_accuracy: 0.9127\n",
      "Epoch 00077: val_categorical_accuracy did not improve from 0.51917\n",
      "303/303 [==============================] - 149s 493ms/step - loss: 0.0074 - categorical_accuracy: 0.9127 - val_loss: 5.0243 - val_categorical_accuracy: 0.5079\n",
      "Epoch 78/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0063 - categorical_accuracy: 0.9126\n",
      "Epoch 00078: val_categorical_accuracy did not improve from 0.51917\n",
      "303/303 [==============================] - 144s 474ms/step - loss: 0.0063 - categorical_accuracy: 0.9126 - val_loss: 5.0054 - val_categorical_accuracy: 0.5152\n",
      "Epoch 79/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0059 - categorical_accuracy: 0.9119\n",
      "Epoch 00079: val_categorical_accuracy did not improve from 0.51917\n",
      "303/303 [==============================] - 144s 474ms/step - loss: 0.0059 - categorical_accuracy: 0.9119 - val_loss: 4.9266 - val_categorical_accuracy: 0.5190\n",
      "Epoch 80/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0064 - categorical_accuracy: 0.9126\n",
      "Epoch 00080: val_categorical_accuracy did not improve from 0.51917\n",
      "303/303 [==============================] - 144s 477ms/step - loss: 0.0064 - categorical_accuracy: 0.9126 - val_loss: 5.1726 - val_categorical_accuracy: 0.4996\n",
      "Epoch 81/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0053 - categorical_accuracy: 0.9124\n",
      "Epoch 00081: val_categorical_accuracy did not improve from 0.51917\n",
      "303/303 [==============================] - 145s 478ms/step - loss: 0.0053 - categorical_accuracy: 0.9124 - val_loss: 5.0760 - val_categorical_accuracy: 0.5077\n",
      "Epoch 82/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0055 - categorical_accuracy: 0.9151\n",
      "Epoch 00082: val_categorical_accuracy did not improve from 0.51917\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 2.519423724152148e-05.\n",
      "303/303 [==============================] - 145s 477ms/step - loss: 0.0055 - categorical_accuracy: 0.9151 - val_loss: 4.9735 - val_categorical_accuracy: 0.5131\n",
      "Epoch 83/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0045 - categorical_accuracy: 0.9128\n",
      "Epoch 00083: val_categorical_accuracy did not improve from 0.51917\n",
      "303/303 [==============================] - 145s 479ms/step - loss: 0.0045 - categorical_accuracy: 0.9128 - val_loss: 5.0684 - val_categorical_accuracy: 0.5094\n",
      "Epoch 84/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0046 - categorical_accuracy: 0.9133\n",
      "Epoch 00084: val_categorical_accuracy did not improve from 0.51917\n",
      "303/303 [==============================] - 145s 477ms/step - loss: 0.0046 - categorical_accuracy: 0.9133 - val_loss: 5.0410 - val_categorical_accuracy: 0.5106\n",
      "Epoch 85/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0043 - categorical_accuracy: 0.9131\n",
      "Epoch 00085: val_categorical_accuracy did not improve from 0.51917\n",
      "303/303 [==============================] - 149s 493ms/step - loss: 0.0043 - categorical_accuracy: 0.9131 - val_loss: 5.0792 - val_categorical_accuracy: 0.5127\n",
      "Epoch 86/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0045 - categorical_accuracy: 0.9121\n",
      "Epoch 00086: val_categorical_accuracy did not improve from 0.51917\n",
      "303/303 [==============================] - 143s 473ms/step - loss: 0.0045 - categorical_accuracy: 0.9121 - val_loss: 5.0831 - val_categorical_accuracy: 0.5119\n",
      "Epoch 87/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0041 - categorical_accuracy: 0.9124\n",
      "Epoch 00087: val_categorical_accuracy did not improve from 0.51917\n",
      "303/303 [==============================] - 146s 481ms/step - loss: 0.0041 - categorical_accuracy: 0.9124 - val_loss: 5.1429 - val_categorical_accuracy: 0.5117\n",
      "Epoch 88/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0039 - categorical_accuracy: 0.9117\n",
      "Epoch 00088: val_categorical_accuracy improved from 0.51917 to 0.52125, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 145s 479ms/step - loss: 0.0039 - categorical_accuracy: 0.9117 - val_loss: 5.0339 - val_categorical_accuracy: 0.5213\n",
      "Epoch 89/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0049 - categorical_accuracy: 0.9123\n",
      "Epoch 00089: val_categorical_accuracy did not improve from 0.52125\n",
      "303/303 [==============================] - 143s 472ms/step - loss: 0.0049 - categorical_accuracy: 0.9123 - val_loss: 5.0717 - val_categorical_accuracy: 0.5173\n",
      "Epoch 90/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0044 - categorical_accuracy: 0.9112\n",
      "Epoch 00090: val_categorical_accuracy did not improve from 0.52125\n",
      "303/303 [==============================] - 143s 471ms/step - loss: 0.0044 - categorical_accuracy: 0.9112 - val_loss: 5.1153 - val_categorical_accuracy: 0.5131\n",
      "Epoch 91/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0039 - categorical_accuracy: 0.9104\n",
      "Epoch 00091: val_categorical_accuracy did not improve from 0.52125\n",
      "303/303 [==============================] - 142s 470ms/step - loss: 0.0039 - categorical_accuracy: 0.9104 - val_loss: 5.0214 - val_categorical_accuracy: 0.5204\n",
      "Epoch 92/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0036 - categorical_accuracy: 0.9116\n",
      "Epoch 00092: val_categorical_accuracy did not improve from 0.52125\n",
      "303/303 [==============================] - 143s 473ms/step - loss: 0.0036 - categorical_accuracy: 0.9116 - val_loss: 5.1717 - val_categorical_accuracy: 0.5121\n",
      "Epoch 93/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0035 - categorical_accuracy: 0.9120\n",
      "Epoch 00093: val_categorical_accuracy did not improve from 0.52125\n",
      "303/303 [==============================] - 142s 469ms/step - loss: 0.0035 - categorical_accuracy: 0.9120 - val_loss: 5.0773 - val_categorical_accuracy: 0.5167\n",
      "Epoch 94/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0035 - categorical_accuracy: 0.9123\n",
      "Epoch 00094: val_categorical_accuracy did not improve from 0.52125\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 1.511654190835543e-05.\n",
      "303/303 [==============================] - 144s 474ms/step - loss: 0.0035 - categorical_accuracy: 0.9123 - val_loss: 5.1679 - val_categorical_accuracy: 0.5123\n",
      "Epoch 95/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0041 - categorical_accuracy: 0.9099\n",
      "Epoch 00095: val_categorical_accuracy did not improve from 0.52125\n",
      "303/303 [==============================] - 141s 466ms/step - loss: 0.0041 - categorical_accuracy: 0.9099 - val_loss: 5.0778 - val_categorical_accuracy: 0.5177\n",
      "Epoch 96/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0038 - categorical_accuracy: 0.9094\n",
      "Epoch 00096: val_categorical_accuracy did not improve from 0.52125\n",
      "303/303 [==============================] - 139s 460ms/step - loss: 0.0038 - categorical_accuracy: 0.9094 - val_loss: 5.0885 - val_categorical_accuracy: 0.5210\n",
      "Epoch 97/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0035 - categorical_accuracy: 0.9124\n",
      "Epoch 00097: val_categorical_accuracy did not improve from 0.52125\n",
      "303/303 [==============================] - 138s 454ms/step - loss: 0.0035 - categorical_accuracy: 0.9124 - val_loss: 5.1612 - val_categorical_accuracy: 0.5142\n",
      "Epoch 98/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0036 - categorical_accuracy: 0.9129\n",
      "Epoch 00098: val_categorical_accuracy did not improve from 0.52125\n",
      "303/303 [==============================] - 140s 461ms/step - loss: 0.0036 - categorical_accuracy: 0.9129 - val_loss: 5.0825 - val_categorical_accuracy: 0.5188\n",
      "Epoch 99/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0032 - categorical_accuracy: 0.9120\n",
      "Epoch 00099: val_categorical_accuracy did not improve from 0.52125\n",
      "303/303 [==============================] - 139s 460ms/step - loss: 0.0032 - categorical_accuracy: 0.9120 - val_loss: 5.1555 - val_categorical_accuracy: 0.5173\n",
      "Epoch 100/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0033 - categorical_accuracy: 0.9137\n",
      "Epoch 00100: val_categorical_accuracy improved from 0.52125 to 0.52146, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 140s 461ms/step - loss: 0.0033 - categorical_accuracy: 0.9137 - val_loss: 5.1112 - val_categorical_accuracy: 0.5215\n",
      "Epoch 101/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0033 - categorical_accuracy: 0.9126\n",
      "Epoch 00101: val_categorical_accuracy did not improve from 0.52146\n",
      "303/303 [==============================] - 140s 462ms/step - loss: 0.0033 - categorical_accuracy: 0.9126 - val_loss: 5.1858 - val_categorical_accuracy: 0.5125\n",
      "Epoch 102/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0029 - categorical_accuracy: 0.9118\n",
      "Epoch 00102: val_categorical_accuracy did not improve from 0.52146\n",
      "303/303 [==============================] - 139s 457ms/step - loss: 0.0029 - categorical_accuracy: 0.9118 - val_loss: 5.1558 - val_categorical_accuracy: 0.5179\n",
      "Epoch 103/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0035 - categorical_accuracy: 0.9127\n",
      "Epoch 00103: val_categorical_accuracy did not improve from 0.52146\n",
      "303/303 [==============================] - 138s 456ms/step - loss: 0.0035 - categorical_accuracy: 0.9127 - val_loss: 5.1859 - val_categorical_accuracy: 0.5177\n",
      "Epoch 104/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0029 - categorical_accuracy: 0.9103\n",
      "Epoch 00104: val_categorical_accuracy did not improve from 0.52146\n",
      "303/303 [==============================] - 139s 459ms/step - loss: 0.0029 - categorical_accuracy: 0.9103 - val_loss: 5.1587 - val_categorical_accuracy: 0.5206\n",
      "Epoch 105/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0026 - categorical_accuracy: 0.9103\n",
      "Epoch 00105: val_categorical_accuracy improved from 0.52146 to 0.52188, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 140s 460ms/step - loss: 0.0026 - categorical_accuracy: 0.9103 - val_loss: 5.1153 - val_categorical_accuracy: 0.5219\n",
      "Epoch 106/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0027 - categorical_accuracy: 0.9136\n",
      "Epoch 00106: val_categorical_accuracy did not improve from 0.52188\n",
      "303/303 [==============================] - 139s 458ms/step - loss: 0.0027 - categorical_accuracy: 0.9136 - val_loss: 5.1497 - val_categorical_accuracy: 0.5179\n",
      "Epoch 107/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0026 - categorical_accuracy: 0.9137\n",
      "Epoch 00107: val_categorical_accuracy did not improve from 0.52188\n",
      "303/303 [==============================] - 139s 459ms/step - loss: 0.0026 - categorical_accuracy: 0.9137 - val_loss: 5.2220 - val_categorical_accuracy: 0.5148\n",
      "Epoch 108/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0030 - categorical_accuracy: 0.9120\n",
      "Epoch 00108: val_categorical_accuracy did not improve from 0.52188\n",
      "303/303 [==============================] - 138s 456ms/step - loss: 0.0030 - categorical_accuracy: 0.9120 - val_loss: 5.2206 - val_categorical_accuracy: 0.5140\n",
      "Epoch 109/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0026 - categorical_accuracy: 0.9109\n",
      "Epoch 00109: val_categorical_accuracy did not improve from 0.52188\n",
      "303/303 [==============================] - 139s 458ms/step - loss: 0.0026 - categorical_accuracy: 0.9109 - val_loss: 5.1260 - val_categorical_accuracy: 0.5210\n",
      "Epoch 110/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0025 - categorical_accuracy: 0.9138\n",
      "Epoch 00110: val_categorical_accuracy improved from 0.52188 to 0.52271, saving model to DenseNer201.best_weights-128.hdf5\n",
      "303/303 [==============================] - 140s 463ms/step - loss: 0.0025 - categorical_accuracy: 0.9138 - val_loss: 5.1187 - val_categorical_accuracy: 0.5227\n",
      "Epoch 111/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0024 - categorical_accuracy: 0.9113\n",
      "Epoch 00111: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 138s 457ms/step - loss: 0.0024 - categorical_accuracy: 0.9113 - val_loss: 5.2510 - val_categorical_accuracy: 0.5144\n",
      "Epoch 112/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0028 - categorical_accuracy: 0.9110\n",
      "Epoch 00112: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 138s 457ms/step - loss: 0.0028 - categorical_accuracy: 0.9110 - val_loss: 5.1826 - val_categorical_accuracy: 0.5196\n",
      "Epoch 113/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0027 - categorical_accuracy: 0.9126\n",
      "Epoch 00113: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 138s 455ms/step - loss: 0.0027 - categorical_accuracy: 0.9126 - val_loss: 5.2262 - val_categorical_accuracy: 0.5156\n",
      "Epoch 114/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0030 - categorical_accuracy: 0.9123\n",
      "Epoch 00114: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 140s 461ms/step - loss: 0.0030 - categorical_accuracy: 0.9123 - val_loss: 5.2537 - val_categorical_accuracy: 0.5133\n",
      "Epoch 115/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0023 - categorical_accuracy: 0.9111\n",
      "Epoch 00115: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 139s 457ms/step - loss: 0.0023 - categorical_accuracy: 0.9111 - val_loss: 5.1672 - val_categorical_accuracy: 0.5196\n",
      "Epoch 116/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0027 - categorical_accuracy: 0.9117\n",
      "Epoch 00116: val_categorical_accuracy did not improve from 0.52271\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 9.069925363291987e-06.\n",
      "303/303 [==============================] - 140s 461ms/step - loss: 0.0027 - categorical_accuracy: 0.9117 - val_loss: 5.1751 - val_categorical_accuracy: 0.5198\n",
      "Epoch 117/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0027 - categorical_accuracy: 0.9101\n",
      "Epoch 00117: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 139s 458ms/step - loss: 0.0027 - categorical_accuracy: 0.9101 - val_loss: 5.1925 - val_categorical_accuracy: 0.5173\n",
      "Epoch 118/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0023 - categorical_accuracy: 0.9118\n",
      "Epoch 00118: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 139s 459ms/step - loss: 0.0023 - categorical_accuracy: 0.9118 - val_loss: 5.2076 - val_categorical_accuracy: 0.5183\n",
      "Epoch 119/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0024 - categorical_accuracy: 0.9131\n",
      "Epoch 00119: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 139s 460ms/step - loss: 0.0024 - categorical_accuracy: 0.9131 - val_loss: 5.2579 - val_categorical_accuracy: 0.5158\n",
      "Epoch 120/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0025 - categorical_accuracy: 0.9128\n",
      "Epoch 00120: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 140s 461ms/step - loss: 0.0025 - categorical_accuracy: 0.9128 - val_loss: 5.1802 - val_categorical_accuracy: 0.5200\n",
      "Epoch 121/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0022 - categorical_accuracy: 0.9117\n",
      "Epoch 00121: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 141s 465ms/step - loss: 0.0022 - categorical_accuracy: 0.9117 - val_loss: 5.2573 - val_categorical_accuracy: 0.5169\n",
      "Epoch 122/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0023 - categorical_accuracy: 0.9109\n",
      "Epoch 00122: val_categorical_accuracy did not improve from 0.52271\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 5.441954999696463e-06.\n",
      "303/303 [==============================] - 142s 468ms/step - loss: 0.0023 - categorical_accuracy: 0.9109 - val_loss: 5.2539 - val_categorical_accuracy: 0.5185\n",
      "Epoch 123/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0022 - categorical_accuracy: 0.9110\n",
      "Epoch 00123: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 142s 467ms/step - loss: 0.0022 - categorical_accuracy: 0.9110 - val_loss: 5.2302 - val_categorical_accuracy: 0.5163\n",
      "Epoch 124/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0024 - categorical_accuracy: 0.9100\n",
      "Epoch 00124: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 141s 464ms/step - loss: 0.0024 - categorical_accuracy: 0.9100 - val_loss: 5.2538 - val_categorical_accuracy: 0.5202\n",
      "Epoch 125/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0021 - categorical_accuracy: 0.9120\n",
      "Epoch 00125: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 142s 470ms/step - loss: 0.0021 - categorical_accuracy: 0.9120 - val_loss: 5.2367 - val_categorical_accuracy: 0.5202\n",
      "Epoch 126/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0020 - categorical_accuracy: 0.9101\n",
      "Epoch 00126: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 140s 463ms/step - loss: 0.0020 - categorical_accuracy: 0.9101 - val_loss: 5.2832 - val_categorical_accuracy: 0.5169\n",
      "Epoch 127/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0021 - categorical_accuracy: 0.9117\n",
      "Epoch 00127: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 142s 469ms/step - loss: 0.0021 - categorical_accuracy: 0.9117 - val_loss: 5.2486 - val_categorical_accuracy: 0.5194\n",
      "Epoch 128/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0022 - categorical_accuracy: 0.9099\n",
      "Epoch 00128: val_categorical_accuracy did not improve from 0.52271\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 3.265173108957242e-06.\n",
      "303/303 [==============================] - 141s 465ms/step - loss: 0.0022 - categorical_accuracy: 0.9099 - val_loss: 5.2611 - val_categorical_accuracy: 0.5208\n",
      "Epoch 129/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0025 - categorical_accuracy: 0.9117\n",
      "Epoch 00129: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 141s 467ms/step - loss: 0.0025 - categorical_accuracy: 0.9117 - val_loss: 5.2514 - val_categorical_accuracy: 0.5221\n",
      "Epoch 130/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0018 - categorical_accuracy: 0.9131\n",
      "Epoch 00130: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 142s 469ms/step - loss: 0.0018 - categorical_accuracy: 0.9131 - val_loss: 5.2451 - val_categorical_accuracy: 0.5217\n",
      "Epoch 131/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0023 - categorical_accuracy: 0.9115\n",
      "Epoch 00131: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 142s 467ms/step - loss: 0.0023 - categorical_accuracy: 0.9115 - val_loss: 5.2538 - val_categorical_accuracy: 0.5200\n",
      "Epoch 132/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0021 - categorical_accuracy: 0.9107\n",
      "Epoch 00132: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 142s 469ms/step - loss: 0.0021 - categorical_accuracy: 0.9107 - val_loss: 5.2772 - val_categorical_accuracy: 0.5185\n",
      "Epoch 133/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0020 - categorical_accuracy: 0.9129\n",
      "Epoch 00133: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 143s 472ms/step - loss: 0.0020 - categorical_accuracy: 0.9129 - val_loss: 5.2727 - val_categorical_accuracy: 0.5185\n",
      "Epoch 134/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0020 - categorical_accuracy: 0.9140\n",
      "Epoch 00134: val_categorical_accuracy did not improve from 0.52271\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 1.959103838089504e-06.\n",
      "303/303 [==============================] - 142s 468ms/step - loss: 0.0020 - categorical_accuracy: 0.9140 - val_loss: 5.2683 - val_categorical_accuracy: 0.5198\n",
      "Epoch 135/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0022 - categorical_accuracy: 0.9118\n",
      "Epoch 00135: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 142s 469ms/step - loss: 0.0022 - categorical_accuracy: 0.9118 - val_loss: 5.2838 - val_categorical_accuracy: 0.5188\n",
      "Epoch 136/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0020 - categorical_accuracy: 0.9129\n",
      "Epoch 00136: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 142s 470ms/step - loss: 0.0020 - categorical_accuracy: 0.9129 - val_loss: 5.2698 - val_categorical_accuracy: 0.5192\n",
      "Epoch 137/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0023 - categorical_accuracy: 0.9129\n",
      "Epoch 00137: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 142s 469ms/step - loss: 0.0023 - categorical_accuracy: 0.9129 - val_loss: 5.2732 - val_categorical_accuracy: 0.5185\n",
      "Epoch 138/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0019 - categorical_accuracy: 0.9095\n",
      "Epoch 00138: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 144s 475ms/step - loss: 0.0019 - categorical_accuracy: 0.9095 - val_loss: 5.2625 - val_categorical_accuracy: 0.5194\n",
      "Epoch 139/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0020 - categorical_accuracy: 0.9117\n",
      "Epoch 00139: val_categorical_accuracy did not improve from 0.52271\n",
      "303/303 [==============================] - 142s 468ms/step - loss: 0.0020 - categorical_accuracy: 0.9117 - val_loss: 5.2772 - val_categorical_accuracy: 0.5188\n",
      "Epoch 140/300\n",
      "303/303 [==============================] - ETA: 0s - loss: 0.0021 - categorical_accuracy: 0.9131\n",
      "Epoch 00140: val_categorical_accuracy did not improve from 0.52271\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 1.1754623301385436e-06.\n",
      "303/303 [==============================] - 143s 472ms/step - loss: 0.0021 - categorical_accuracy: 0.9131 - val_loss: 5.2644 - val_categorical_accuracy: 0.5194\n",
      "Epoch 00140: early stopping\n"
     ]
    }
   ],
   "source": [
    "history=custom_densenet169_model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=300,\n",
    "                    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:24:17.350041Z",
     "iopub.status.busy": "2020-10-04T23:24:17.349254Z",
     "iopub.status.idle": "2020-10-04T23:24:17.351195Z",
     "shell.execute_reply": "2020-10-04T23:24:17.350608Z"
    },
    "papermill": {
     "duration": 15.242058,
     "end_time": "2020-10-04T23:24:17.351303",
     "exception": false,
     "start_time": "2020-10-04T23:24:02.109245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:24:47.230394Z",
     "iopub.status.busy": "2020-10-04T23:24:47.229708Z",
     "iopub.status.idle": "2020-10-04T23:24:47.418059Z",
     "shell.execute_reply": "2020-10-04T23:24:47.418522Z"
    },
    "papermill": {
     "duration": 15.261161,
     "end_time": "2020-10-04T23:24:47.418658",
     "exception": false,
     "start_time": "2020-10-04T23:24:32.157497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "loss_train = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "#epochs = np.range(1,1)\n",
    "plt.plot(loss_train, 'g', label='Training loss')\n",
    "plt.plot(loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:25:18.388929Z",
     "iopub.status.busy": "2020-10-04T23:25:18.146832Z",
     "iopub.status.idle": "2020-10-04T23:25:18.562715Z",
     "shell.execute_reply": "2020-10-04T23:25:18.563268Z"
    },
    "papermill": {
     "duration": 15.441127,
     "end_time": "2020-10-04T23:25:18.563407",
     "exception": false,
     "start_time": "2020-10-04T23:25:03.122280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = history.history['categorical_accuracy']\n",
    "loss_val = history.history['val_categorical_accuracy']\n",
    "epochs = range(1,41)\n",
    "plt.plot(loss_train, 'g', label='Training accuracy')\n",
    "plt.plot(loss_val, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:25:48.460143Z",
     "iopub.status.busy": "2020-10-04T23:25:48.458879Z",
     "iopub.status.idle": "2020-10-04T23:26:00.222366Z",
     "shell.execute_reply": "2020-10-04T23:26:00.221802Z"
    },
    "papermill": {
     "duration": 26.46982,
     "end_time": "2020-10-04T23:26:00.222485",
     "exception": false,
     "start_time": "2020-10-04T23:25:33.752665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 9s 123ms/step\n"
     ]
    }
   ],
   "source": [
    "res = custom_densenet169_model.predict_generator(valid_generator, verbose=1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:26:30.717080Z",
     "iopub.status.busy": "2020-10-04T23:26:30.716000Z",
     "iopub.status.idle": "2020-10-04T23:26:53.056794Z",
     "shell.execute_reply": "2020-10-04T23:26:53.055996Z"
    },
    "papermill": {
     "duration": 37.76018,
     "end_time": "2020-10-04T23:26:53.057006",
     "exception": false,
     "start_time": "2020-10-04T23:26:15.296826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 20s 214ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "res_test=custom_densenet169_model.predict_generator(test_generator,\n",
    "#steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:27:23.209247Z",
     "iopub.status.busy": "2020-10-04T23:27:23.208125Z",
     "iopub.status.idle": "2020-10-04T23:27:32.202363Z",
     "shell.execute_reply": "2020-10-04T23:27:32.201681Z"
    },
    "papermill": {
     "duration": 23.981623,
     "end_time": "2020-10-04T23:27:32.202522",
     "exception": false,
     "start_time": "2020-10-04T23:27:08.220899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 9s 115ms/step\n"
     ]
    }
   ],
   "source": [
    "valid_generator.reset()\n",
    "res_cv=custom_densenet169_model.predict_generator(valid_generator,\n",
    "#steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:28:03.132070Z",
     "iopub.status.busy": "2020-10-04T23:28:03.130682Z",
     "iopub.status.idle": "2020-10-04T23:29:56.999437Z",
     "shell.execute_reply": "2020-10-04T23:29:56.998249Z"
    },
    "papermill": {
     "duration": 129.661979,
     "end_time": "2020-10-04T23:29:56.999571",
     "exception": false,
     "start_time": "2020-10-04T23:27:47.337592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304/304 [==============================] - 113s 372ms/step\n"
     ]
    }
   ],
   "source": [
    "train_generator.reset()\n",
    "res_train=custom_densenet169_model.predict_generator(train_generator,\n",
    "#steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:30:27.786711Z",
     "iopub.status.busy": "2020-10-04T23:30:27.785966Z",
     "iopub.status.idle": "2020-10-04T23:30:27.789102Z",
     "shell.execute_reply": "2020-10-04T23:30:27.789582Z"
    },
    "papermill": {
     "duration": 15.412527,
     "end_time": "2020-10-04T23:30:27.789708",
     "exception": false,
     "start_time": "2020-10-04T23:30:12.377181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6078, 80)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:30:58.838818Z",
     "iopub.status.busy": "2020-10-04T23:30:58.837650Z",
     "iopub.status.idle": "2020-10-04T23:30:59.150496Z",
     "shell.execute_reply": "2020-10-04T23:30:59.151020Z"
    },
    "papermill": {
     "duration": 16.31197,
     "end_time": "2020-10-04T23:30:59.151173",
     "exception": false,
     "start_time": "2020-10-04T23:30:42.839203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converting taget and identity columns to booleans\n",
    "\n",
    "target_columns=list(trainmultidf.columns)[:-1]\n",
    "\n",
    "def convert_to_bool(df, col_name):\n",
    "    df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n",
    "    \n",
    "def convert_dataframe_to_bool(df):\n",
    "    bool_df = df.copy()\n",
    "    for col in target_columns:\n",
    "        convert_to_bool(bool_df, col)\n",
    "    return bool_df\n",
    "\n",
    "test_bool = convert_dataframe_to_bool(testmultidf) \n",
    "test_lable_bool=test_bool[list(test_bool.columns)[:-1]].to_numpy()\n",
    "\n",
    "train_bool = convert_dataframe_to_bool(trainmultidf) \n",
    "train_lable_bool=train_bool[list(train_bool.columns)[:-1]].to_numpy()\n",
    "\n",
    "cv_bool = convert_dataframe_to_bool(cvmultidf) \n",
    "cv_lable_bool=cv_bool[list(cv_bool.columns)[:-1]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:31:29.604820Z",
     "iopub.status.busy": "2020-10-04T23:31:29.604030Z",
     "iopub.status.idle": "2020-10-04T23:31:29.607071Z",
     "shell.execute_reply": "2020-10-04T23:31:29.607543Z"
    },
    "papermill": {
     "duration": 15.010867,
     "end_time": "2020-10-04T23:31:29.607668",
     "exception": false,
     "start_time": "2020-10-04T23:31:14.596801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4862, 80)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_lable_bool.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 15.987452,
     "end_time": "2020-10-04T23:32:01.279613",
     "exception": false,
     "start_time": "2020-10-04T23:31:45.292161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:32:31.851813Z",
     "iopub.status.busy": "2020-10-04T23:32:31.850899Z",
     "iopub.status.idle": "2020-10-04T23:32:31.852740Z",
     "shell.execute_reply": "2020-10-04T23:32:31.853284Z"
    },
    "papermill": {
     "duration": 15.410113,
     "end_time": "2020-10-04T23:32:31.853408",
     "exception": false,
     "start_time": "2020-10-04T23:32:16.443295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:33:03.184642Z",
     "iopub.status.busy": "2020-10-04T23:33:03.183919Z",
     "iopub.status.idle": "2020-10-04T23:33:03.187597Z",
     "shell.execute_reply": "2020-10-04T23:33:03.187112Z"
    },
    "papermill": {
     "duration": 16.340057,
     "end_time": "2020-10-04T23:33:03.187701",
     "exception": false,
     "start_time": "2020-10-04T23:32:46.847644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Core calculation of label precisions for one test sample.\n",
    "\n",
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "  \"\"\"Calculate precisions for each true class for a single sample.\n",
    "  \n",
    "  Args:\n",
    "    scores: np.array of (num_classes,) giving the individual classifier scores.\n",
    "    truth: np.array of (num_classes,) bools indicating which classes are true.\n",
    "\n",
    "  Returns:\n",
    "    pos_class_indices: np.array of indices of the true classes for this sample.\n",
    "    pos_class_precisions: np.array of precisions corresponding to each of those\n",
    "      classes.\n",
    "  \"\"\"\n",
    "  num_classes = scores.shape[0]\n",
    "  pos_class_indices = np.flatnonzero(truth > 0)\n",
    "  # Only calculate precisions if there are some true classes.\n",
    "  if not len(pos_class_indices):\n",
    "    return pos_class_indices, np.zeros(0)\n",
    "  # Retrieval list of classes for this sample. \n",
    "  retrieved_classes = np.argsort(scores)[::-1]\n",
    "  # class_rankings[top_scoring_class_index] == 0 etc.\n",
    "  class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "  class_rankings[retrieved_classes] = range(num_classes)\n",
    "  # Which of these is a true label?\n",
    "  retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "  retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "  # Num hits for every truncated retrieval list.\n",
    "  retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "  # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
    "  precision_at_hits = (\n",
    "      retrieved_cumulative_hits[class_rankings[pos_class_indices]] / \n",
    "      (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "  return pos_class_indices, precision_at_hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:33:33.543928Z",
     "iopub.status.busy": "2020-10-04T23:33:33.542111Z",
     "iopub.status.idle": "2020-10-04T23:33:33.544609Z",
     "shell.execute_reply": "2020-10-04T23:33:33.545109Z"
    },
    "papermill": {
     "duration": 15.14754,
     "end_time": "2020-10-04T23:33:33.545241",
     "exception": false,
     "start_time": "2020-10-04T23:33:18.397701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# All-in-one calculation of per-class lwlrap.\n",
    "\n",
    "def calculate_per_class_lwlrap(truth, scores):\n",
    "  \"\"\"Calculate label-weighted label-ranking average precision.\n",
    "  \n",
    "  Arguments:\n",
    "    truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
    "      of presence of that class in that sample.\n",
    "    scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
    "      test's real-valued score for each class for each sample.\n",
    "  \n",
    "  Returns:\n",
    "    per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each \n",
    "      class.\n",
    "    weight_per_class: np.array of (num_classes,) giving the prior of each \n",
    "      class within the truth labels.  Then the overall unbalanced lwlrap is \n",
    "      simply np.sum(per_class_lwlrap * weight_per_class)\n",
    "  \"\"\"\n",
    "  assert truth.shape == scores.shape\n",
    "  num_samples, num_classes = scores.shape\n",
    "  # Space to store a distinct precision value for each class on each sample.\n",
    "  # Only the classes that are true for each sample will be filled in.\n",
    "  precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
    "  for sample_num in range(num_samples):\n",
    "    pos_class_indices, precision_at_hits = (\n",
    "      _one_sample_positive_class_precisions(scores[sample_num, :], \n",
    "                                            truth[sample_num, :]))\n",
    "    precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
    "        precision_at_hits)\n",
    "  labels_per_class = np.sum(truth > 0, axis=0)\n",
    "  weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
    "  # Form average of each column, i.e. all the precisions assigned to labels in\n",
    "  # a particular class.\n",
    "  per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) / \n",
    "                      np.maximum(1, labels_per_class))\n",
    "  # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
    "  #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
    "  #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
    "  #                = np.sum(per_class_lwlrap * weight_per_class)\n",
    "  return per_class_lwlrap, weight_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:34:04.766963Z",
     "iopub.status.busy": "2020-10-04T23:34:04.766213Z",
     "iopub.status.idle": "2020-10-04T23:34:04.769716Z",
     "shell.execute_reply": "2020-10-04T23:34:04.769226Z"
    },
    "papermill": {
     "duration": 16.014881,
     "end_time": "2020-10-04T23:34:04.769822",
     "exception": false,
     "start_time": "2020-10-04T23:33:48.754941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the overall lwlrap using sklearn.metrics function.\n",
    "\n",
    "def calculate_overall_lwlrap_sklearn(truth, scores):\n",
    "  \"\"\"Calculate the overall lwlrap using sklearn.metrics.lrap.\"\"\"\n",
    "  # sklearn doesn't correctly apply weighting to samples with no labels, so just skip them.\n",
    "  sample_weight = np.sum(truth > 0, axis=1)\n",
    "  nonzero_weight_sample_indices = np.flatnonzero(sample_weight > 0)\n",
    "  overall_lwlrap = sklearn.metrics.label_ranking_average_precision_score(\n",
    "      truth[nonzero_weight_sample_indices, :] > 0, \n",
    "      scores[nonzero_weight_sample_indices, :], \n",
    "      sample_weight=sample_weight[nonzero_weight_sample_indices])\n",
    "  return overall_lwlrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:34:35.329435Z",
     "iopub.status.busy": "2020-10-04T23:34:35.328486Z",
     "iopub.status.idle": "2020-10-04T23:34:35.331062Z",
     "shell.execute_reply": "2020-10-04T23:34:35.331520Z"
    },
    "papermill": {
     "duration": 15.164406,
     "end_time": "2020-10-04T23:34:35.331654",
     "exception": false,
     "start_time": "2020-10-04T23:34:20.167248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Accumulator object version.\n",
    "\n",
    "class lwlrap_accumulator(object):\n",
    "  \"\"\"Accumulate batches of test samples into per-class and overall lwlrap.\"\"\"  \n",
    "\n",
    "  def __init__(self):\n",
    "    self.num_classes = 0\n",
    "    self.total_num_samples = 0\n",
    "  \n",
    "  def accumulate_samples(self, batch_truth, batch_scores):\n",
    "    \"\"\"Cumulate a new batch of samples into the metric.\n",
    "    \n",
    "    Args:\n",
    "      truth: np.array of (num_samples, num_classes) giving boolean\n",
    "        ground-truth of presence of that class in that sample for this batch.\n",
    "      scores: np.array of (num_samples, num_classes) giving the \n",
    "        classifier-under-test's real-valued score for each class for each\n",
    "        sample.\n",
    "    \"\"\"\n",
    "    assert batch_scores.shape == batch_truth.shape\n",
    "    num_samples, num_classes = batch_truth.shape\n",
    "    if not self.num_classes:\n",
    "      self.num_classes = num_classes\n",
    "      self._per_class_cumulative_precision = np.zeros(self.num_classes)\n",
    "      self._per_class_cumulative_count = np.zeros(self.num_classes, \n",
    "                                                  dtype=np.int)\n",
    "    assert num_classes == self.num_classes\n",
    "    for truth, scores in zip(batch_truth, batch_scores):\n",
    "      pos_class_indices, precision_at_hits = (\n",
    "        _one_sample_positive_class_precisions(scores, truth))\n",
    "      self._per_class_cumulative_precision[pos_class_indices] += (\n",
    "        precision_at_hits)\n",
    "      self._per_class_cumulative_count[pos_class_indices] += 1\n",
    "    self.total_num_samples += num_samples\n",
    "\n",
    "  def per_class_lwlrap(self):\n",
    "    \"\"\"Return a vector of the per-class lwlraps for the accumulated samples.\"\"\"\n",
    "    return (self._per_class_cumulative_precision / \n",
    "            np.maximum(1, self._per_class_cumulative_count))\n",
    "\n",
    "  def per_class_weight(self):\n",
    "    \"\"\"Return a normalized weight vector for the contributions of each class.\"\"\"\n",
    "    return (self._per_class_cumulative_count / \n",
    "            float(np.sum(self._per_class_cumulative_count)))\n",
    "\n",
    "  def overall_lwlrap(self):\n",
    "    \"\"\"Return the scalar overall lwlrap for cumulated samples.\"\"\"\n",
    "    return np.sum(self.per_class_lwlrap() * self.per_class_weight())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:35:06.596543Z",
     "iopub.status.busy": "2020-10-04T23:35:06.595690Z",
     "iopub.status.idle": "2020-10-04T23:35:07.408856Z",
     "shell.execute_reply": "2020-10-04T23:35:07.408313Z"
    },
    "papermill": {
     "duration": 16.680604,
     "end_time": "2020-10-04T23:35:07.408988",
     "exception": false,
     "start_time": "2020-10-04T23:34:50.728384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lwlrap from sklearn.metrics = 0.6601395941805719\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/voglinio/keras-2d-model-5-fold-log-specgram-curated-only\n",
    "truth = test_lable_bool\n",
    "scores = res_test\n",
    "print(\"lwlrap from sklearn.metrics =\", calculate_overall_lwlrap_sklearn(truth, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:35:37.960052Z",
     "iopub.status.busy": "2020-10-04T23:35:37.959040Z",
     "iopub.status.idle": "2020-10-04T23:35:40.576521Z",
     "shell.execute_reply": "2020-10-04T23:35:40.576984Z"
    },
    "papermill": {
     "duration": 18.083576,
     "end_time": "2020-10-04T23:35:40.577127",
     "exception": false,
     "start_time": "2020-10-04T23:35:22.493551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lwlrap from sklearn.metrics = 0.9995719862620371\n"
     ]
    }
   ],
   "source": [
    "truth = train_lable_bool\n",
    "scores = res_train\n",
    "print(\"lwlrap from sklearn.metrics =\", calculate_overall_lwlrap_sklearn(truth, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:36:12.046340Z",
     "iopub.status.busy": "2020-10-04T23:36:12.045301Z",
     "iopub.status.idle": "2020-10-04T23:36:12.712003Z",
     "shell.execute_reply": "2020-10-04T23:36:12.712691Z"
    },
    "papermill": {
     "duration": 16.249914,
     "end_time": "2020-10-04T23:36:12.712836",
     "exception": false,
     "start_time": "2020-10-04T23:35:56.462922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lwlrap from sklearn.metrics = 0.6645574774981766\n"
     ]
    }
   ],
   "source": [
    "truth = cv_lable_bool\n",
    "scores = res_cv\n",
    "print(\"lwlrap from sklearn.metrics =\", calculate_overall_lwlrap_sklearn(truth, scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 15.466043,
     "end_time": "2020-10-04T23:36:43.273293",
     "exception": false,
     "start_time": "2020-10-04T23:36:27.807250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:37:14.814779Z",
     "iopub.status.busy": "2020-10-04T23:37:14.813900Z",
     "iopub.status.idle": "2020-10-04T23:37:15.377101Z",
     "shell.execute_reply": "2020-10-04T23:37:15.377559Z"
    },
    "papermill": {
     "duration": 15.946756,
     "end_time": "2020-10-04T23:37:15.377700",
     "exception": false,
     "start_time": "2020-10-04T23:36:59.430944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3361 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "sub_dataframe = pd.DataFrame({'fname':os.listdir('../input/sc2-total-aug-noisy-data/sub2/sub2')})\n",
    "\n",
    "sub_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "sub_generator=sub_datagen.flow_from_dataframe(\n",
    "    dataframe=sub_dataframe,\n",
    "    directory=\"../input/sc2-total-aug-noisy-data/sub2/sub2\",\n",
    "    x_col=\"fname\",\n",
    "    y_col=None,\n",
    "    batch_size=64,\n",
    "    seed=42,\n",
    "    shuffle=False,\n",
    "    class_mode=None,\n",
    "    target_size=(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:37:45.619114Z",
     "iopub.status.busy": "2020-10-04T23:37:45.618023Z",
     "iopub.status.idle": "2020-10-04T23:37:45.620082Z",
     "shell.execute_reply": "2020-10-04T23:37:45.620571Z"
    },
    "papermill": {
     "duration": 15.120634,
     "end_time": "2020-10-04T23:37:45.620700",
     "exception": false,
     "start_time": "2020-10-04T23:37:30.500066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "STEP_SIZE_SUB=sub_generator.n//sub_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:38:16.928500Z",
     "iopub.status.busy": "2020-10-04T23:38:16.926908Z",
     "iopub.status.idle": "2020-10-04T23:38:28.320688Z",
     "shell.execute_reply": "2020-10-04T23:38:28.319909Z"
    },
    "papermill": {
     "duration": 26.540859,
     "end_time": "2020-10-04T23:38:28.320796",
     "exception": false,
     "start_time": "2020-10-04T23:38:01.779937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 11s 208ms/step\n"
     ]
    }
   ],
   "source": [
    "sub_generator.reset()\n",
    "res_sub=custom_densenet169_model.predict_generator(sub_generator,\n",
    "#steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:38:59.532020Z",
     "iopub.status.busy": "2020-10-04T23:38:59.530336Z",
     "iopub.status.idle": "2020-10-04T23:38:59.534410Z",
     "shell.execute_reply": "2020-10-04T23:38:59.533895Z"
    },
    "papermill": {
     "duration": 16.027196,
     "end_time": "2020-10-04T23:38:59.534510",
     "exception": false,
     "start_time": "2020-10-04T23:38:43.507314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3361, 80)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:39:30.319002Z",
     "iopub.status.busy": "2020-10-04T23:39:30.317889Z",
     "iopub.status.idle": "2020-10-04T23:39:30.321380Z",
     "shell.execute_reply": "2020-10-04T23:39:30.320902Z"
    },
    "papermill": {
     "duration": 15.339437,
     "end_time": "2020-10-04T23:39:30.321486",
     "exception": false,
     "start_time": "2020-10-04T23:39:14.982049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit_data=pd.DataFrame(res_sub.astype(\"float64\"), columns=list(mlb_train.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:40:01.550946Z",
     "iopub.status.busy": "2020-10-04T23:40:01.550211Z",
     "iopub.status.idle": "2020-10-04T23:40:01.590476Z",
     "shell.execute_reply": "2020-10-04T23:40:01.589465Z"
    },
    "papermill": {
     "duration": 16.101675,
     "end_time": "2020-10-04T23:40:01.590592",
     "exception": false,
     "start_time": "2020-10-04T23:39:45.488917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>Accelerating_and_revving_and_vroom</th>\n",
       "      <th>Accordion</th>\n",
       "      <th>Acoustic_guitar</th>\n",
       "      <th>Applause</th>\n",
       "      <th>Bark</th>\n",
       "      <th>Bass_drum</th>\n",
       "      <th>Bass_guitar</th>\n",
       "      <th>Bathtub_(filling_or_washing)</th>\n",
       "      <th>Bicycle_bell</th>\n",
       "      <th>...</th>\n",
       "      <th>Toilet_flush</th>\n",
       "      <th>Traffic_noise_and_roadway_noise</th>\n",
       "      <th>Trickle_and_dribble</th>\n",
       "      <th>Walk_and_footsteps</th>\n",
       "      <th>Water_tap_and_faucet</th>\n",
       "      <th>Waves_and_surf</th>\n",
       "      <th>Whispering</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Yell</th>\n",
       "      <th>Zipper_(clothing)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dce682d5.wav</td>\n",
       "      <td>4.137620e-10</td>\n",
       "      <td>7.108237e-11</td>\n",
       "      <td>3.462702e-07</td>\n",
       "      <td>2.556699e-11</td>\n",
       "      <td>1.013348e-15</td>\n",
       "      <td>2.085511e-08</td>\n",
       "      <td>3.700971e-05</td>\n",
       "      <td>7.733534e-16</td>\n",
       "      <td>7.162033e-11</td>\n",
       "      <td>...</td>\n",
       "      <td>7.585250e-10</td>\n",
       "      <td>3.669595e-11</td>\n",
       "      <td>5.168941e-11</td>\n",
       "      <td>1.227743e-11</td>\n",
       "      <td>3.978246e-10</td>\n",
       "      <td>6.320731e-13</td>\n",
       "      <td>1.288904e-11</td>\n",
       "      <td>6.217031e-17</td>\n",
       "      <td>2.537294e-09</td>\n",
       "      <td>1.343917e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98b6c051.wav</td>\n",
       "      <td>9.305710e-09</td>\n",
       "      <td>2.978599e-06</td>\n",
       "      <td>2.557842e-10</td>\n",
       "      <td>1.660068e-08</td>\n",
       "      <td>2.656906e-07</td>\n",
       "      <td>4.502222e-13</td>\n",
       "      <td>4.693850e-07</td>\n",
       "      <td>1.046097e-08</td>\n",
       "      <td>1.839665e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.063964e-08</td>\n",
       "      <td>1.151405e-09</td>\n",
       "      <td>2.157254e-09</td>\n",
       "      <td>1.071941e-09</td>\n",
       "      <td>1.055001e-07</td>\n",
       "      <td>1.173688e-11</td>\n",
       "      <td>5.032265e-07</td>\n",
       "      <td>1.021240e-07</td>\n",
       "      <td>2.692661e-11</td>\n",
       "      <td>1.569220e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8f3daeef.wav</td>\n",
       "      <td>6.425969e-12</td>\n",
       "      <td>1.013548e-10</td>\n",
       "      <td>8.354530e-09</td>\n",
       "      <td>4.369745e-07</td>\n",
       "      <td>3.473760e-11</td>\n",
       "      <td>2.416422e-11</td>\n",
       "      <td>5.920892e-03</td>\n",
       "      <td>3.835493e-10</td>\n",
       "      <td>1.120827e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>9.031652e-11</td>\n",
       "      <td>1.301577e-11</td>\n",
       "      <td>1.555395e-17</td>\n",
       "      <td>1.518637e-13</td>\n",
       "      <td>8.633089e-13</td>\n",
       "      <td>3.062208e-09</td>\n",
       "      <td>5.826706e-07</td>\n",
       "      <td>2.559157e-08</td>\n",
       "      <td>1.308419e-12</td>\n",
       "      <td>2.795931e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6c1fb4b7.wav</td>\n",
       "      <td>5.464790e-08</td>\n",
       "      <td>2.192034e-08</td>\n",
       "      <td>3.897299e-07</td>\n",
       "      <td>1.335367e-10</td>\n",
       "      <td>1.106292e-05</td>\n",
       "      <td>6.294042e-11</td>\n",
       "      <td>2.927124e-11</td>\n",
       "      <td>1.227314e-08</td>\n",
       "      <td>1.049259e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>6.391638e-07</td>\n",
       "      <td>2.070807e-10</td>\n",
       "      <td>7.557386e-12</td>\n",
       "      <td>5.524569e-08</td>\n",
       "      <td>1.487001e-07</td>\n",
       "      <td>7.858405e-09</td>\n",
       "      <td>1.548955e-10</td>\n",
       "      <td>8.753948e-10</td>\n",
       "      <td>3.717480e-10</td>\n",
       "      <td>7.779273e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>762b355c.wav</td>\n",
       "      <td>9.279783e-08</td>\n",
       "      <td>7.195926e-14</td>\n",
       "      <td>3.069510e-10</td>\n",
       "      <td>1.414878e-12</td>\n",
       "      <td>1.390625e-08</td>\n",
       "      <td>2.917625e-12</td>\n",
       "      <td>1.321907e-08</td>\n",
       "      <td>4.943209e-15</td>\n",
       "      <td>6.028901e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.060743e-07</td>\n",
       "      <td>2.300433e-11</td>\n",
       "      <td>4.043342e-12</td>\n",
       "      <td>4.562980e-13</td>\n",
       "      <td>2.115061e-13</td>\n",
       "      <td>9.629338e-11</td>\n",
       "      <td>9.194286e-11</td>\n",
       "      <td>1.747147e-14</td>\n",
       "      <td>1.996244e-10</td>\n",
       "      <td>5.693573e-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname  Accelerating_and_revving_and_vroom     Accordion  \\\n",
       "0  dce682d5.wav                        4.137620e-10  7.108237e-11   \n",
       "1  98b6c051.wav                        9.305710e-09  2.978599e-06   \n",
       "2  8f3daeef.wav                        6.425969e-12  1.013548e-10   \n",
       "3  6c1fb4b7.wav                        5.464790e-08  2.192034e-08   \n",
       "4  762b355c.wav                        9.279783e-08  7.195926e-14   \n",
       "\n",
       "   Acoustic_guitar      Applause          Bark     Bass_drum   Bass_guitar  \\\n",
       "0     3.462702e-07  2.556699e-11  1.013348e-15  2.085511e-08  3.700971e-05   \n",
       "1     2.557842e-10  1.660068e-08  2.656906e-07  4.502222e-13  4.693850e-07   \n",
       "2     8.354530e-09  4.369745e-07  3.473760e-11  2.416422e-11  5.920892e-03   \n",
       "3     3.897299e-07  1.335367e-10  1.106292e-05  6.294042e-11  2.927124e-11   \n",
       "4     3.069510e-10  1.414878e-12  1.390625e-08  2.917625e-12  1.321907e-08   \n",
       "\n",
       "   Bathtub_(filling_or_washing)  Bicycle_bell  ...  Toilet_flush  \\\n",
       "0                  7.733534e-16  7.162033e-11  ...  7.585250e-10   \n",
       "1                  1.046097e-08  1.839665e-10  ...  2.063964e-08   \n",
       "2                  3.835493e-10  1.120827e-07  ...  9.031652e-11   \n",
       "3                  1.227314e-08  1.049259e-06  ...  6.391638e-07   \n",
       "4                  4.943209e-15  6.028901e-10  ...  1.060743e-07   \n",
       "\n",
       "   Traffic_noise_and_roadway_noise  Trickle_and_dribble  Walk_and_footsteps  \\\n",
       "0                     3.669595e-11         5.168941e-11        1.227743e-11   \n",
       "1                     1.151405e-09         2.157254e-09        1.071941e-09   \n",
       "2                     1.301577e-11         1.555395e-17        1.518637e-13   \n",
       "3                     2.070807e-10         7.557386e-12        5.524569e-08   \n",
       "4                     2.300433e-11         4.043342e-12        4.562980e-13   \n",
       "\n",
       "   Water_tap_and_faucet  Waves_and_surf    Whispering       Writing  \\\n",
       "0          3.978246e-10    6.320731e-13  1.288904e-11  6.217031e-17   \n",
       "1          1.055001e-07    1.173688e-11  5.032265e-07  1.021240e-07   \n",
       "2          8.633089e-13    3.062208e-09  5.826706e-07  2.559157e-08   \n",
       "3          1.487001e-07    7.858405e-09  1.548955e-10  8.753948e-10   \n",
       "4          2.115061e-13    9.629338e-11  9.194286e-11  1.747147e-14   \n",
       "\n",
       "           Yell  Zipper_(clothing)  \n",
       "0  2.537294e-09       1.343917e-09  \n",
       "1  2.692661e-11       1.569220e-11  \n",
       "2  1.308419e-12       2.795931e-09  \n",
       "3  3.717480e-10       7.779273e-05  \n",
       "4  1.996244e-10       5.693573e-11  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_data.insert(0, 'fname', os.listdir('../input/sc2-total-aug-noisy-data/sub2/sub2'))\n",
    "submit_data[\"fname\"]=submit_data[\"fname\"].apply(lambda x: x.split(\".\")[0]+\".wav\")\n",
    "submit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-04T23:40:32.049908Z",
     "iopub.status.busy": "2020-10-04T23:40:32.049181Z",
     "iopub.status.idle": "2020-10-04T23:40:33.010339Z",
     "shell.execute_reply": "2020-10-04T23:40:33.009756Z"
    },
    "papermill": {
     "duration": 16.138353,
     "end_time": "2020-10-04T23:40:33.010458",
     "exception": false,
     "start_time": "2020-10-04T23:40:16.872105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit_data.to_csv(\"submissionDenseNoisyCV_4.csv\",index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 16.310664,
     "end_time": "2020-10-04T23:41:04.423711",
     "exception": false,
     "start_time": "2020-10-04T23:40:48.113047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 21059.511664,
   "end_time": "2020-10-04T23:41:21.820142",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-04T17:50:22.308478",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
