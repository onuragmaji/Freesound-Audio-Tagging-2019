{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:27.586084Z",
     "iopub.status.busy": "2020-10-03T12:18:27.585015Z",
     "iopub.status.idle": "2020-10-03T12:18:27.588339Z",
     "shell.execute_reply": "2020-10-03T12:18:27.587626Z"
    },
    "id": "SQF09QseVK2o",
    "papermill": {
     "duration": 0.051614,
     "end_time": "2020-10-03T12:18:27.588453",
     "exception": false,
     "start_time": "2020-10-03T12:18:27.536839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:27.677638Z",
     "iopub.status.busy": "2020-10-03T12:18:27.676959Z",
     "iopub.status.idle": "2020-10-03T12:18:27.721890Z",
     "shell.execute_reply": "2020-10-03T12:18:27.721214Z"
    },
    "id": "p7iYDRlSXG6E",
    "papermill": {
     "duration": 0.092738,
     "end_time": "2020-10-03T12:18:27.722003",
     "exception": false,
     "start_time": "2020-10-03T12:18:27.629265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "traindf_noisy=pd.read_csv('../input/freesound-audio-tagging-2019/train_noisy.csv',dtype=str)\n",
    "\n",
    "traindf_curated=pd.read_csv('../input/freesound-audio-tagging-2019/train_curated.csv',dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:27.817962Z",
     "iopub.status.busy": "2020-10-03T12:18:27.817125Z",
     "iopub.status.idle": "2020-10-03T12:18:27.825807Z",
     "shell.execute_reply": "2020-10-03T12:18:27.825226Z"
    },
    "id": "U4bc985UXfC9",
    "outputId": "fc67be4a-3be0-4bfe-faf8-078bdb911416",
    "papermill": {
     "duration": 0.062304,
     "end_time": "2020-10-03T12:18:27.825898",
     "exception": false,
     "start_time": "2020-10-03T12:18:27.763594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00097e21.wav</td>\n",
       "      <td>Bathtub_(filling_or_washing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000b6cfb.wav</td>\n",
       "      <td>Motorcycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00116cd2.wav</td>\n",
       "      <td>Marimba_and_xylophone,Glockenspiel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00127d14.wav</td>\n",
       "      <td>Water_tap_and_faucet,Sink_(filling_or_washing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0019adae.wav</td>\n",
       "      <td>Raindrop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname                                          labels\n",
       "0  00097e21.wav                    Bathtub_(filling_or_washing)\n",
       "1  000b6cfb.wav                                      Motorcycle\n",
       "2  00116cd2.wav              Marimba_and_xylophone,Glockenspiel\n",
       "3  00127d14.wav  Water_tap_and_faucet,Sink_(filling_or_washing)\n",
       "4  0019adae.wav                                        Raindrop"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf_noisy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading 0-K Fold Curated Train, CV and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:27.923703Z",
     "iopub.status.busy": "2020-10-03T12:18:27.923022Z",
     "iopub.status.idle": "2020-10-03T12:18:27.941425Z",
     "shell.execute_reply": "2020-10-03T12:18:27.940906Z"
    },
    "id": "BED77XJyFvrQ",
    "outputId": "79f2cdec-9af6-4626-ccfd-8e117548ff34",
    "papermill": {
     "duration": 0.073162,
     "end_time": "2020-10-03T12:18:27.941527",
     "exception": false,
     "start_time": "2020-10-03T12:18:27.868365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d349d1c7_aug.jpg</td>\n",
       "      <td>Cutlery_and_silverware,Dishes_and_pots_and_pans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e1c41fe6_aug.jpg</td>\n",
       "      <td>Burping_and_eructation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d8b54599.jpg</td>\n",
       "      <td>Accelerating_and_revving_and_vroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15d94574_aug.jpg</td>\n",
       "      <td>Mechanical_fan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05be25ad.jpg</td>\n",
       "      <td>Shatter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              fname                                           labels\n",
       "0  d349d1c7_aug.jpg  Cutlery_and_silverware,Dishes_and_pots_and_pans\n",
       "1  e1c41fe6_aug.jpg                           Burping_and_eructation\n",
       "2      d8b54599.jpg               Accelerating_and_revving_and_vroom\n",
       "3  15d94574_aug.jpg                                   Mechanical_fan\n",
       "4      05be25ad.jpg                                          Shatter"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../input/sc2-total-aug-noisy-data/K_fold_data/K_fold_data/Curated/Curated_train_0.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:28.032107Z",
     "iopub.status.busy": "2020-10-03T12:18:28.031176Z",
     "iopub.status.idle": "2020-10-03T12:18:28.035468Z",
     "shell.execute_reply": "2020-10-03T12:18:28.034954Z"
    },
    "id": "WH505SeqZkQt",
    "outputId": "3f186139-021d-4747-9e8b-7ecdf0043405",
    "papermill": {
     "duration": 0.051871,
     "end_time": "2020-10-03T12:18:28.035569",
     "exception": false,
     "start_time": "2020-10-03T12:18:27.983698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6251, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:28.127733Z",
     "iopub.status.busy": "2020-10-03T12:18:28.127113Z",
     "iopub.status.idle": "2020-10-03T12:18:28.137809Z",
     "shell.execute_reply": "2020-10-03T12:18:28.137204Z"
    },
    "id": "CyzXJYqRZw08",
    "outputId": "be29fa6d-abdf-4008-d807-f4e8c3297941",
    "papermill": {
     "duration": 0.059113,
     "end_time": "2020-10-03T12:18:28.137917",
     "exception": false,
     "start_time": "2020-10-03T12:18:28.078804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1563, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df = pd.read_csv(\"../input/sc2-total-aug-noisy-data/K_fold_data/K_fold_data/Curated/Curated_cv_0.csv\")\n",
    "cv_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:28.231652Z",
     "iopub.status.busy": "2020-10-03T12:18:28.230833Z",
     "iopub.status.idle": "2020-10-03T12:18:28.240544Z",
     "shell.execute_reply": "2020-10-03T12:18:28.239864Z"
    },
    "id": "PbRmGQZPZ4X8",
    "outputId": "95e57da4-a520-4b4c-f798-7a8499a1bf3a",
    "papermill": {
     "duration": 0.058634,
     "end_time": "2020-10-03T12:18:28.240649",
     "exception": false,
     "start_time": "2020-10-03T12:18:28.182015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1380, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "test_df = pd.read_csv(\"../input/sc2-total-aug-noisy-data/K_fold_data/K_fold_data/Curated/Curated_test.csv\") \n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn MultiLabelBinarizer to One-hot encode the multilablles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:28.336954Z",
     "iopub.status.busy": "2020-10-03T12:18:28.336073Z",
     "iopub.status.idle": "2020-10-03T12:18:29.323690Z",
     "shell.execute_reply": "2020-10-03T12:18:29.322703Z"
    },
    "id": "PhcbdXiAaFg8",
    "papermill": {
     "duration": 1.039068,
     "end_time": "2020-10-03T12:18:29.323812",
     "exception": false,
     "start_time": "2020-10-03T12:18:28.284744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb_train = MultiLabelBinarizer()\n",
    "\n",
    "\n",
    "labels_train = mlb_train.fit_transform([ i.split(\",\") for i in list(train_df[\"labels\"])])\n",
    "\n",
    "\n",
    "labels_test = mlb_train.transform([ i.split(\",\") for i in list(test_df[\"labels\"])])\n",
    "\n",
    "\n",
    "#mlb_cv = MultiLabelBinarizer()\n",
    "labels_cv = mlb_train.transform([ i.split(\",\") for i in list(cv_df[\"labels\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:29.421332Z",
     "iopub.status.busy": "2020-10-03T12:18:29.420661Z",
     "iopub.status.idle": "2020-10-03T12:18:29.426390Z",
     "shell.execute_reply": "2020-10-03T12:18:29.426851Z"
    },
    "id": "SezKbmekzxuZ",
    "outputId": "4d82a251-2985-4bdd-eb6d-97e83646c797",
    "papermill": {
     "duration": 0.05658,
     "end_time": "2020-10-03T12:18:29.426990",
     "exception": false,
     "start_time": "2020-10-03T12:18:29.370410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:29.528793Z",
     "iopub.status.busy": "2020-10-03T12:18:29.527778Z",
     "iopub.status.idle": "2020-10-03T12:18:29.536527Z",
     "shell.execute_reply": "2020-10-03T12:18:29.535915Z"
    },
    "id": "hNrk7jvNaP6L",
    "papermill": {
     "duration": 0.064732,
     "end_time": "2020-10-03T12:18:29.536637",
     "exception": false,
     "start_time": "2020-10-03T12:18:29.471905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainmultidf=pd.DataFrame(data=labels_train,columns=list(mlb_train.classes_))\n",
    "trainmultidf[\"fname\"]=list(train_df[\"fname\"])\n",
    "\n",
    "testmultidf=pd.DataFrame(data=labels_test,columns=list(mlb_train.classes_))\n",
    "testmultidf[\"fname\"]=list(test_df[\"fname\"])\n",
    "\n",
    "\n",
    "cvmultidf=pd.DataFrame(data=labels_cv,columns=list(mlb_train.classes_))\n",
    "cvmultidf[\"fname\"]=list(cv_df[\"fname\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:29.635159Z",
     "iopub.status.busy": "2020-10-03T12:18:29.634194Z",
     "iopub.status.idle": "2020-10-03T12:18:29.638622Z",
     "shell.execute_reply": "2020-10-03T12:18:29.638019Z"
    },
    "id": "ULDTeP4OVRnF",
    "outputId": "d58a1c76-726b-4bec-de07-4b4560452359",
    "papermill": {
     "duration": 0.056403,
     "end_time": "2020-10-03T12:18:29.638727",
     "exception": false,
     "start_time": "2020-10-03T12:18:29.582324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1563, 81)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvmultidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:29.737033Z",
     "iopub.status.busy": "2020-10-03T12:18:29.736044Z",
     "iopub.status.idle": "2020-10-03T12:18:29.754004Z",
     "shell.execute_reply": "2020-10-03T12:18:29.754574Z"
    },
    "id": "6hroRXb30BX3",
    "outputId": "2d3868dd-fd8e-4527-90fe-0ff594e931c0",
    "papermill": {
     "duration": 0.070138,
     "end_time": "2020-10-03T12:18:29.754690",
     "exception": false,
     "start_time": "2020-10-03T12:18:29.684552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accelerating_and_revving_and_vroom</th>\n",
       "      <th>Accordion</th>\n",
       "      <th>Acoustic_guitar</th>\n",
       "      <th>Applause</th>\n",
       "      <th>Bark</th>\n",
       "      <th>Bass_drum</th>\n",
       "      <th>Bass_guitar</th>\n",
       "      <th>Bathtub_(filling_or_washing)</th>\n",
       "      <th>Bicycle_bell</th>\n",
       "      <th>Burping_and_eructation</th>\n",
       "      <th>...</th>\n",
       "      <th>Traffic_noise_and_roadway_noise</th>\n",
       "      <th>Trickle_and_dribble</th>\n",
       "      <th>Walk_and_footsteps</th>\n",
       "      <th>Water_tap_and_faucet</th>\n",
       "      <th>Waves_and_surf</th>\n",
       "      <th>Whispering</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Yell</th>\n",
       "      <th>Zipper_(clothing)</th>\n",
       "      <th>fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>e9889c78.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a06afbf0_aug.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>a9e97fb7.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b855f490_aug.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ec447208_aug.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accelerating_and_revving_and_vroom  Accordion  Acoustic_guitar  Applause  \\\n",
       "0                                   0          0                0         0   \n",
       "1                                   0          0                0         0   \n",
       "2                                   0          0                0         0   \n",
       "3                                   0          0                0         0   \n",
       "4                                   0          0                0         0   \n",
       "\n",
       "   Bark  Bass_drum  Bass_guitar  Bathtub_(filling_or_washing)  Bicycle_bell  \\\n",
       "0     0          0            0                             0             0   \n",
       "1     0          0            0                             0             0   \n",
       "2     0          0            0                             0             0   \n",
       "3     0          0            0                             0             0   \n",
       "4     0          0            0                             0             0   \n",
       "\n",
       "   Burping_and_eructation  ...  Traffic_noise_and_roadway_noise  \\\n",
       "0                       0  ...                                0   \n",
       "1                       0  ...                                0   \n",
       "2                       0  ...                                0   \n",
       "3                       0  ...                                0   \n",
       "4                       0  ...                                0   \n",
       "\n",
       "   Trickle_and_dribble  Walk_and_footsteps  Water_tap_and_faucet  \\\n",
       "0                    0                   0                     0   \n",
       "1                    1                   0                     0   \n",
       "2                    0                   0                     0   \n",
       "3                    1                   0                     0   \n",
       "4                    0                   0                     0   \n",
       "\n",
       "   Waves_and_surf  Whispering  Writing  Yell  Zipper_(clothing)  \\\n",
       "0               0           0        0     0                  0   \n",
       "1               0           0        0     0                  0   \n",
       "2               0           0        0     0                  1   \n",
       "3               0           0        0     0                  0   \n",
       "4               0           0        0     0                  0   \n",
       "\n",
       "              fname  \n",
       "0      e9889c78.jpg  \n",
       "1  a06afbf0_aug.jpg  \n",
       "2      a9e97fb7.jpg  \n",
       "3  b855f490_aug.jpg  \n",
       "4  ec447208_aug.jpg  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmultidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Preprocessed Spectrogram Images via ImageDataGenerator and adding augumnetation to train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:29.856177Z",
     "iopub.status.busy": "2020-10-03T12:18:29.855541Z",
     "iopub.status.idle": "2020-10-03T12:18:37.340980Z",
     "shell.execute_reply": "2020-10-03T12:18:37.340433Z"
    },
    "id": "6Oskr5b4aVK7",
    "outputId": "a70dc23f-d9dd-48a7-f851-7e7c064c8c7a",
    "papermill": {
     "duration": 7.539312,
     "end_time": "2020-10-03T12:18:37.341090",
     "exception": false,
     "start_time": "2020-10-03T12:18:29.801778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6251 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "#We change the ids for the images in the csv files to reflect their new status as jpgs\n",
    "#https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "datagen=ImageDataGenerator(rescale=1./255.,zoom_range=[0.5,1.0],brightness_range=[0.8,1.4])\n",
    "\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "    dataframe=trainmultidf,\n",
    "    directory=\"../input/sc2-total-aug-noisy-data/Total images Bucket Curated/Total images Bucket Curated\",\n",
    "    x_col=\"fname\",\n",
    "    y_col=list(mlb_train.classes_),\n",
    "    subset=\"training\",\n",
    "    batch_size=64,\n",
    "    seed=42,\n",
    "    shuffle=False,#True,\n",
    "    class_mode=\"raw\",\n",
    "    color_mode=\"grayscale\",\n",
    "    target_size=(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:37.442628Z",
     "iopub.status.busy": "2020-10-03T12:18:37.441673Z",
     "iopub.status.idle": "2020-10-03T12:18:37.445931Z",
     "shell.execute_reply": "2020-10-03T12:18:37.445401Z"
    },
    "id": "m9hJ7VZvalMr",
    "outputId": "f24bccc8-b3a6-4af2-baf4-d81fa450dddf",
    "papermill": {
     "duration": 0.05699,
     "end_time": "2020-10-03T12:18:37.446050",
     "exception": false,
     "start_time": "2020-10-03T12:18:37.389060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6251"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:37.543722Z",
     "iopub.status.busy": "2020-10-03T12:18:37.542912Z",
     "iopub.status.idle": "2020-10-03T12:18:37.546959Z",
     "shell.execute_reply": "2020-10-03T12:18:37.546440Z"
    },
    "id": "biqrZ_RkapeK",
    "outputId": "0f9f318a-e34a-40a4-b5a7-e004f5d3ae55",
    "papermill": {
     "duration": 0.054392,
     "end_time": "2020-10-03T12:18:37.547068",
     "exception": false,
     "start_time": "2020-10-03T12:18:37.492676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1563, 81)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvmultidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:37.649451Z",
     "iopub.status.busy": "2020-10-03T12:18:37.648545Z",
     "iopub.status.idle": "2020-10-03T12:18:38.069187Z",
     "shell.execute_reply": "2020-10-03T12:18:38.068578Z"
    },
    "id": "Ml0cOSOEasCK",
    "outputId": "e6060ca3-f9f5-4e8c-a168-8887b04ffc17",
    "papermill": {
     "duration": 0.474913,
     "end_time": "2020-10-03T12:18:38.069323",
     "exception": false,
     "start_time": "2020-10-03T12:18:37.594410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1563 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "valid_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "valid_generator=valid_datagen.flow_from_dataframe(\n",
    "    dataframe=cvmultidf,\n",
    "    directory=\"../input/sc2-total-aug-noisy-data/Total images Bucket Curated/Total images Bucket Curated\",\n",
    "    x_col=\"fname\",\n",
    "    y_col=list(mlb_train.classes_),\n",
    "   # subset=\"validation\",\n",
    "    batch_size=64,\n",
    "    seed=42,\n",
    "    shuffle=False,#shuffle=True,\n",
    "    class_mode=\"raw\",\n",
    "    color_mode=\"grayscale\",\n",
    "    target_size=(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:38.175396Z",
     "iopub.status.busy": "2020-10-03T12:18:38.174520Z",
     "iopub.status.idle": "2020-10-03T12:18:38.537823Z",
     "shell.execute_reply": "2020-10-03T12:18:38.538337Z"
    },
    "id": "vJ9HZWmNay8K",
    "outputId": "1b85a1e9-8927-4008-d7b2-c7e526ce725e",
    "papermill": {
     "duration": 0.418635,
     "end_time": "2020-10-03T12:18:38.538526",
     "exception": false,
     "start_time": "2020-10-03T12:18:38.119891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1380 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "    dataframe=testmultidf,\n",
    "    directory=\"../input/sc2-total-aug-noisy-data/Total images Bucket Curated/Total images Bucket Curated\",\n",
    "    x_col=\"fname\",\n",
    "    y_col=None,\n",
    "    batch_size=64,\n",
    "    seed=42,\n",
    "    shuffle=False,#shuffle=False,\n",
    "    class_mode=None,\n",
    "    color_mode=\"grayscale\",\n",
    "    target_size=(128,128))\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:38.645348Z",
     "iopub.status.busy": "2020-10-03T12:18:38.644425Z",
     "iopub.status.idle": "2020-10-03T12:18:38.658132Z",
     "shell.execute_reply": "2020-10-03T12:18:38.657552Z"
    },
    "id": "H8D4GwERoIKQ",
    "outputId": "7093389e-1007-4454-b118-7d0076045a0f",
    "papermill": {
     "duration": 0.071292,
     "end_time": "2020-10-03T12:18:38.658252",
     "exception": false,
     "start_time": "2020-10-03T12:18:38.586960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accelerating_and_revving_and_vroom</th>\n",
       "      <th>Accordion</th>\n",
       "      <th>Acoustic_guitar</th>\n",
       "      <th>Applause</th>\n",
       "      <th>Bark</th>\n",
       "      <th>Bass_drum</th>\n",
       "      <th>Bass_guitar</th>\n",
       "      <th>Bathtub_(filling_or_washing)</th>\n",
       "      <th>Bicycle_bell</th>\n",
       "      <th>Burping_and_eructation</th>\n",
       "      <th>...</th>\n",
       "      <th>Traffic_noise_and_roadway_noise</th>\n",
       "      <th>Trickle_and_dribble</th>\n",
       "      <th>Walk_and_footsteps</th>\n",
       "      <th>Water_tap_and_faucet</th>\n",
       "      <th>Waves_and_surf</th>\n",
       "      <th>Whispering</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Yell</th>\n",
       "      <th>Zipper_(clothing)</th>\n",
       "      <th>fname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9a93c380.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0ab47a4c.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8f5bf633_aug.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>e07009c1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>877562da_aug.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accelerating_and_revving_and_vroom  Accordion  Acoustic_guitar  Applause  \\\n",
       "0                                   0          0                0         0   \n",
       "1                                   0          0                0         0   \n",
       "2                                   0          0                0         0   \n",
       "3                                   0          0                0         0   \n",
       "4                                   0          0                0         0   \n",
       "\n",
       "   Bark  Bass_drum  Bass_guitar  Bathtub_(filling_or_washing)  Bicycle_bell  \\\n",
       "0     0          0            1                             0             0   \n",
       "1     0          0            0                             0             0   \n",
       "2     0          0            0                             0             0   \n",
       "3     0          0            0                             0             0   \n",
       "4     0          0            0                             0             0   \n",
       "\n",
       "   Burping_and_eructation  ...  Traffic_noise_and_roadway_noise  \\\n",
       "0                       0  ...                                0   \n",
       "1                       0  ...                                0   \n",
       "2                       1  ...                                0   \n",
       "3                       0  ...                                0   \n",
       "4                       0  ...                                0   \n",
       "\n",
       "   Trickle_and_dribble  Walk_and_footsteps  Water_tap_and_faucet  \\\n",
       "0                    0                   0                     0   \n",
       "1                    0                   0                     0   \n",
       "2                    0                   0                     0   \n",
       "3                    0                   0                     0   \n",
       "4                    0                   0                     0   \n",
       "\n",
       "   Waves_and_surf  Whispering  Writing  Yell  Zipper_(clothing)  \\\n",
       "0               0           0        0     0                  0   \n",
       "1               0           0        0     0                  0   \n",
       "2               0           0        0     0                  0   \n",
       "3               0           0        0     0                  0   \n",
       "4               0           0        1     0                  0   \n",
       "\n",
       "              fname  \n",
       "0      9a93c380.jpg  \n",
       "1      0ab47a4c.jpg  \n",
       "2  8f5bf633_aug.jpg  \n",
       "3      e07009c1.jpg  \n",
       "4  877562da_aug.jpg  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvmultidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Custom Model and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:38.767793Z",
     "iopub.status.busy": "2020-10-03T12:18:38.767090Z",
     "iopub.status.idle": "2020-10-03T12:18:38.821553Z",
     "shell.execute_reply": "2020-10-03T12:18:38.820994Z"
    },
    "id": "t5F8tvzLa3SK",
    "papermill": {
     "duration": 0.11387,
     "end_time": "2020-10-03T12:18:38.821658",
     "exception": false,
     "start_time": "2020-10-03T12:18:38.707788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, LSTM, Conv2D, MaxPooling2D, Dropout, Activation, Input,BatchNormalization, AveragePooling2D,GlobalMaxPool2D,PReLU\n",
    "\n",
    "from tensorflow.keras.models import model_from_json  \n",
    "from tensorflow.keras.applications import DenseNet169\n",
    "\n",
    "from tensorflow.keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n",
    "                             EarlyStopping, ReduceLROnPlateau,CSVLogger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:38.930422Z",
     "iopub.status.busy": "2020-10-03T12:18:38.929541Z",
     "iopub.status.idle": "2020-10-03T12:18:38.932077Z",
     "shell.execute_reply": "2020-10-03T12:18:38.932638Z"
    },
    "id": "pkma1Jy6a6l5",
    "papermill": {
     "duration": 0.060989,
     "end_time": "2020-10-03T12:18:38.932748",
     "exception": false,
     "start_time": "2020-10-03T12:18:38.871759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convBlock(x, num_filter):\n",
    "                                     conv1 = Conv2D(num_filter,1,\n",
    "                                                    kernel_initializer=tf.keras.initializers.GlorotNormal(seed=42))(x)\n",
    "                                                    \n",
    "                                     conv1 = tf.keras.layers.LeakyReLU()(conv1)\n",
    "                                     \n",
    "                                     conv2 = Conv2D(num_filter,1,kernel_initializer=tf.keras.initializers.GlorotNormal(seed=48))(conv1)\n",
    "                                     conv2 = BatchNormalization()(conv2)\n",
    "                                     \n",
    "                                     conv2 = tf.keras.layers.LeakyReLU()(conv2)\n",
    "                                     \n",
    "                                     block_add = layers.add([conv2, conv1])\n",
    "                                     block_add = AveragePooling2D((2,2))(block_add)   \n",
    "\n",
    "\n",
    "                                     return block_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:39.048157Z",
     "iopub.status.busy": "2020-10-03T12:18:39.047459Z",
     "iopub.status.idle": "2020-10-03T12:18:42.489404Z",
     "shell.execute_reply": "2020-10-03T12:18:42.488789Z"
    },
    "id": "gCVmZrO7a_qa",
    "papermill": {
     "duration": 3.501694,
     "end_time": "2020-10-03T12:18:42.489526",
     "exception": false,
     "start_time": "2020-10-03T12:18:38.987832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input = Input(shape=(128,128, 1))\n",
    "\n",
    "x = convBlock(input,32)\n",
    "x = convBlock(x,64)\n",
    "x = convBlock(x,128)\n",
    "x = convBlock(x,256)\n",
    "x = convBlock(x,512)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "\n",
    "#https://stackoverflow.com/questions/52934764/keras-adaptive-max-pooling\n",
    "x = GlobalMaxPool2D()(x)\n",
    "x = Dense(1024)(x)\n",
    "x = PReLU()(x)\n",
    "#x= Dropout(0.1)(x)\n",
    "x = Dense(256)(x)\n",
    "#x = Activation('relu')(x)\n",
    "x = PReLU()(x)\n",
    "x= Dense(80)(x)\n",
    "output = Activation('sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=input,outputs=output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-igFElH419dL",
    "papermill": {
     "duration": 0.050961,
     "end_time": "2020-10-03T12:18:42.591084",
     "exception": false,
     "start_time": "2020-10-03T12:18:42.540123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:42.709192Z",
     "iopub.status.busy": "2020-10-03T12:18:42.708578Z",
     "iopub.status.idle": "2020-10-03T12:18:42.718339Z",
     "shell.execute_reply": "2020-10-03T12:18:42.717760Z"
    },
    "id": "rWRVnx0zz_mG",
    "papermill": {
     "duration": 0.074723,
     "end_time": "2020-10-03T12:18:42.718464",
     "exception": false,
     "start_time": "2020-10-03T12:18:42.643741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr=0.0009)#tf.keras.optimizers.RMSprop(lr=0.3, decay=1e-6) \n",
    "model.compile(loss=  tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.SUM,\n",
    "                                                        label_smoothing=0.7),#custom_loss_noisy_2,#custom_loss,#'categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "               metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:42.823998Z",
     "iopub.status.busy": "2020-10-03T12:18:42.823432Z",
     "iopub.status.idle": "2020-10-03T12:18:42.851432Z",
     "shell.execute_reply": "2020-10-03T12:18:42.850573Z"
    },
    "id": "xHHXlmxrBObq",
    "outputId": "28832a2c-2125-41a4-bacf-f6eac45f840c",
    "papermill": {
     "duration": 0.08357,
     "end_time": "2020-10-03T12:18:42.851537",
     "exception": false,
     "start_time": "2020-10-03T12:18:42.767967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:42.955460Z",
     "iopub.status.busy": "2020-10-03T12:18:42.954763Z",
     "iopub.status.idle": "2020-10-03T12:18:42.959074Z",
     "shell.execute_reply": "2020-10-03T12:18:42.958613Z"
    },
    "id": "yPvkxuClbEf6",
    "outputId": "986699f6-34b5-483e-9bdf-822bc8c1b8ab",
    "papermill": {
     "duration": 0.057678,
     "end_time": "2020-10-03T12:18:42.959171",
     "exception": false,
     "start_time": "2020-10-03T12:18:42.901493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:43.128005Z",
     "iopub.status.busy": "2020-10-03T12:18:43.126872Z",
     "iopub.status.idle": "2020-10-03T12:18:43.129749Z",
     "shell.execute_reply": "2020-10-03T12:18:43.128906Z"
    },
    "id": "Ny1ELGuV9CLQ",
    "papermill": {
     "duration": 0.090895,
     "end_time": "2020-10-03T12:18:43.129918",
     "exception": false,
     "start_time": "2020-10-03T12:18:43.039023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tf.keras.utils.plot_model(model, 'discriminator.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:43.292299Z",
     "iopub.status.busy": "2020-10-03T12:18:43.291388Z",
     "iopub.status.idle": "2020-10-03T12:18:43.294051Z",
     "shell.execute_reply": "2020-10-03T12:18:43.295027Z"
    },
    "id": "Hs9u-idqbeiL",
    "papermill": {
     "duration": 0.086314,
     "end_time": "2020-10-03T12:18:43.295302",
     "exception": false,
     "start_time": "2020-10-03T12:18:43.208988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:43.487882Z",
     "iopub.status.busy": "2020-10-03T12:18:43.486990Z",
     "iopub.status.idle": "2020-10-03T12:18:43.493598Z",
     "shell.execute_reply": "2020-10-03T12:18:43.492848Z"
    },
    "id": "Jjr_WMybA6XZ",
    "outputId": "a6d0c162-51bc-444b-c8e0-4b9962b1feef",
    "papermill": {
     "duration": 0.115987,
     "end_time": "2020-10-03T12:18:43.493732",
     "exception": false,
     "start_time": "2020-10-03T12:18:43.377745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:43.647658Z",
     "iopub.status.busy": "2020-10-03T12:18:43.646924Z",
     "iopub.status.idle": "2020-10-03T12:18:43.719645Z",
     "shell.execute_reply": "2020-10-03T12:18:43.718478Z"
    },
    "papermill": {
     "duration": 0.15123,
     "end_time": "2020-10-03T12:18:43.719770",
     "exception": false,
     "start_time": "2020-10-03T12:18:43.568540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"../input/sc2newfinalweights/Custom_2_total.best_weightsNoisy2BN.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:43.833656Z",
     "iopub.status.busy": "2020-10-03T12:18:43.832945Z",
     "iopub.status.idle": "2020-10-03T12:18:43.836535Z",
     "shell.execute_reply": "2020-10-03T12:18:43.836997Z"
    },
    "id": "7sBXMkLybjHp",
    "papermill": {
     "duration": 0.063723,
     "end_time": "2020-10-03T12:18:43.837128",
     "exception": false,
     "start_time": "2020-10-03T12:18:43.773405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger(filename='training_log.csv',\n",
    "                       separator=',',\n",
    "                       append=True)\n",
    "#https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='loss', factor=0.6,\n",
    "                              patience=6, min_lr=0,verbose=1)\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\"total.best_weightsNoisy2BN.hdf5\", monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "# fit model\n",
    "\n",
    "#es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20, min_delta=0.001 )\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_categorical_accuracy', mode='max', verbose=1, patience=40, min_delta=0.001 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:43.956147Z",
     "iopub.status.busy": "2020-10-03T12:18:43.955365Z",
     "iopub.status.idle": "2020-10-03T12:18:43.958720Z",
     "shell.execute_reply": "2020-10-03T12:18:43.958196Z"
    },
    "id": "Wc40dl_zbvhk",
    "papermill": {
     "duration": 0.068066,
     "end_time": "2020-10-03T12:18:43.958833",
     "exception": false,
     "start_time": "2020-10-03T12:18:43.890767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime, os\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "callbacks_list = [model_checkpoint, csv_logger, reduceLROnPlat,tensorboard_callback,es]#es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:44.068653Z",
     "iopub.status.busy": "2020-10-03T12:18:44.067955Z",
     "iopub.status.idle": "2020-10-03T12:18:48.616771Z",
     "shell.execute_reply": "2020-10-03T12:18:48.616176Z"
    },
    "id": "OGiAJFTpcmDL",
    "outputId": "061499a4-65c3-4520-924f-05fdc91d06b2",
    "papermill": {
     "duration": 4.605717,
     "end_time": "2020-10-03T12:18:48.616906",
     "exception": false,
     "start_time": "2020-10-03T12:18:44.011189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-971899cdec53c3d0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-971899cdec53c3d0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:48.730714Z",
     "iopub.status.busy": "2020-10-03T12:18:48.729480Z",
     "iopub.status.idle": "2020-10-03T12:18:48.734407Z",
     "shell.execute_reply": "2020-10-03T12:18:48.733870Z"
    },
    "id": "ZiFqwN52i5ml",
    "outputId": "dd056941-fb6c-494c-e5f5-9fe279d521c6",
    "papermill": {
     "duration": 0.062453,
     "end_time": "2020-10-03T12:18:48.734514",
     "exception": false,
     "start_time": "2020-10-03T12:18:48.672061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_VALID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T12:18:48.846540Z",
     "iopub.status.busy": "2020-10-03T12:18:48.845773Z",
     "iopub.status.idle": "2020-10-03T14:05:37.231956Z",
     "shell.execute_reply": "2020-10-03T14:05:37.230468Z"
    },
    "id": "ZrGneuQvbrKY",
    "outputId": "8b17a4d1-1b11-45ff-e7d7-c0c6ebfde83f",
    "papermill": {
     "duration": 6408.444349,
     "end_time": "2020-10-03T14:05:37.232083",
     "exception": false,
     "start_time": "2020-10-03T12:18:48.787734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5528 - categorical_accuracy: 0.0205\n",
      "Epoch 00001: val_loss improved from inf to 41.67288, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 37s 384ms/step - loss: 41.5528 - categorical_accuracy: 0.0205 - val_loss: 41.6729 - val_categorical_accuracy: 0.0176\n",
      "Epoch 2/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5217 - categorical_accuracy: 0.0310\n",
      "Epoch 00002: val_loss did not improve from 41.67288\n",
      "97/97 [==============================] - 26s 266ms/step - loss: 41.5217 - categorical_accuracy: 0.0310 - val_loss: 41.7053 - val_categorical_accuracy: 0.0189\n",
      "Epoch 3/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5189 - categorical_accuracy: 0.0357\n",
      "Epoch 00003: val_loss improved from 41.67288 to 41.64147, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 26s 272ms/step - loss: 41.5189 - categorical_accuracy: 0.0357 - val_loss: 41.6415 - val_categorical_accuracy: 0.0267\n",
      "Epoch 4/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5172 - categorical_accuracy: 0.0307\n",
      "Epoch 00004: val_loss improved from 41.64147 to 41.62410, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 25s 259ms/step - loss: 41.5172 - categorical_accuracy: 0.0307 - val_loss: 41.6241 - val_categorical_accuracy: 0.0260\n",
      "Epoch 5/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5161 - categorical_accuracy: 0.0394\n",
      "Epoch 00005: val_loss did not improve from 41.62410\n",
      "97/97 [==============================] - 26s 270ms/step - loss: 41.5161 - categorical_accuracy: 0.0394 - val_loss: 41.6367 - val_categorical_accuracy: 0.0286\n",
      "Epoch 6/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5166 - categorical_accuracy: 0.0399\n",
      "Epoch 00006: val_loss improved from 41.62410 to 41.61873, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 26s 263ms/step - loss: 41.5166 - categorical_accuracy: 0.0399 - val_loss: 41.6187 - val_categorical_accuracy: 0.0228\n",
      "Epoch 7/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5170 - categorical_accuracy: 0.0419\n",
      "Epoch 00007: val_loss improved from 41.61873 to 41.61361, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 27s 276ms/step - loss: 41.5170 - categorical_accuracy: 0.0419 - val_loss: 41.6136 - val_categorical_accuracy: 0.0234\n",
      "Epoch 8/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5162 - categorical_accuracy: 0.0398\n",
      "Epoch 00008: val_loss did not improve from 41.61361\n",
      "97/97 [==============================] - 26s 265ms/step - loss: 41.5162 - categorical_accuracy: 0.0398 - val_loss: 41.6308 - val_categorical_accuracy: 0.0345\n",
      "Epoch 9/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5154 - categorical_accuracy: 0.0451\n",
      "Epoch 00009: val_loss improved from 41.61361 to 41.61276, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 27s 275ms/step - loss: 41.5154 - categorical_accuracy: 0.0451 - val_loss: 41.6128 - val_categorical_accuracy: 0.0365\n",
      "Epoch 10/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5144 - categorical_accuracy: 0.0457\n",
      "Epoch 00010: val_loss did not improve from 41.61276\n",
      "97/97 [==============================] - 25s 262ms/step - loss: 41.5144 - categorical_accuracy: 0.0457 - val_loss: 41.6169 - val_categorical_accuracy: 0.0339\n",
      "Epoch 11/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5134 - categorical_accuracy: 0.0469\n",
      "Epoch 00011: val_loss did not improve from 41.61276\n",
      "97/97 [==============================] - 26s 266ms/step - loss: 41.5134 - categorical_accuracy: 0.0469 - val_loss: 41.6227 - val_categorical_accuracy: 0.0365\n",
      "Epoch 12/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5129 - categorical_accuracy: 0.0444\n",
      "Epoch 00012: val_loss did not improve from 41.61276\n",
      "97/97 [==============================] - 26s 269ms/step - loss: 41.5129 - categorical_accuracy: 0.0444 - val_loss: 41.6141 - val_categorical_accuracy: 0.0332\n",
      "Epoch 13/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5128 - categorical_accuracy: 0.0487\n",
      "Epoch 00013: val_loss improved from 41.61276 to 41.61151, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 26s 269ms/step - loss: 41.5128 - categorical_accuracy: 0.0487 - val_loss: 41.6115 - val_categorical_accuracy: 0.0391\n",
      "Epoch 14/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5120 - categorical_accuracy: 0.0532\n",
      "Epoch 00014: val_loss did not improve from 41.61151\n",
      "97/97 [==============================] - 27s 277ms/step - loss: 41.5120 - categorical_accuracy: 0.0532 - val_loss: 41.6147 - val_categorical_accuracy: 0.0371\n",
      "Epoch 15/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5121 - categorical_accuracy: 0.0480\n",
      "Epoch 00015: val_loss did not improve from 41.61151\n",
      "97/97 [==============================] - 26s 269ms/step - loss: 41.5121 - categorical_accuracy: 0.0480 - val_loss: 41.6126 - val_categorical_accuracy: 0.0410\n",
      "Epoch 16/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5115 - categorical_accuracy: 0.0587\n",
      "Epoch 00016: val_loss did not improve from 41.61151\n",
      "97/97 [==============================] - 27s 276ms/step - loss: 41.5115 - categorical_accuracy: 0.0587 - val_loss: 41.6116 - val_categorical_accuracy: 0.0345\n",
      "Epoch 17/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5113 - categorical_accuracy: 0.0522\n",
      "Epoch 00017: val_loss did not improve from 41.61151\n",
      "97/97 [==============================] - 26s 266ms/step - loss: 41.5113 - categorical_accuracy: 0.0522 - val_loss: 41.6358 - val_categorical_accuracy: 0.0254\n",
      "Epoch 18/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5112 - categorical_accuracy: 0.0504\n",
      "Epoch 00018: val_loss did not improve from 41.61151\n",
      "97/97 [==============================] - 26s 273ms/step - loss: 41.5112 - categorical_accuracy: 0.0504 - val_loss: 41.6645 - val_categorical_accuracy: 0.0202\n",
      "Epoch 19/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5115 - categorical_accuracy: 0.0537\n",
      "Epoch 00019: val_loss did not improve from 41.61151\n",
      "97/97 [==============================] - 26s 266ms/step - loss: 41.5115 - categorical_accuracy: 0.0537 - val_loss: 41.6136 - val_categorical_accuracy: 0.0312\n",
      "Epoch 20/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.6054 - categorical_accuracy: 0.0611\n",
      "Epoch 00020: val_loss did not improve from 41.61151\n",
      "97/97 [==============================] - 26s 267ms/step - loss: 41.6054 - categorical_accuracy: 0.0611 - val_loss: 41.6124 - val_categorical_accuracy: 0.0286\n",
      "Epoch 21/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5114 - categorical_accuracy: 0.0650\n",
      "Epoch 00021: val_loss improved from 41.61151 to 41.61119, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 26s 273ms/step - loss: 41.5114 - categorical_accuracy: 0.0650 - val_loss: 41.6112 - val_categorical_accuracy: 0.0456\n",
      "Epoch 22/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5105 - categorical_accuracy: 0.0616\n",
      "Epoch 00022: val_loss did not improve from 41.61119\n",
      "97/97 [==============================] - 26s 264ms/step - loss: 41.5105 - categorical_accuracy: 0.0616 - val_loss: 41.6134 - val_categorical_accuracy: 0.0365\n",
      "Epoch 23/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5095 - categorical_accuracy: 0.0590\n",
      "Epoch 00023: val_loss improved from 41.61119 to 41.60965, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 27s 281ms/step - loss: 41.5095 - categorical_accuracy: 0.0590 - val_loss: 41.6097 - val_categorical_accuracy: 0.0378\n",
      "Epoch 24/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5102 - categorical_accuracy: 0.0626\n",
      "Epoch 00024: val_loss did not improve from 41.60965\n",
      "97/97 [==============================] - 25s 256ms/step - loss: 41.5102 - categorical_accuracy: 0.0626 - val_loss: 41.6105 - val_categorical_accuracy: 0.0332\n",
      "Epoch 25/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5090 - categorical_accuracy: 0.0651\n",
      "Epoch 00025: val_loss did not improve from 41.60965\n",
      "97/97 [==============================] - 27s 277ms/step - loss: 41.5090 - categorical_accuracy: 0.0651 - val_loss: 41.6111 - val_categorical_accuracy: 0.0514\n",
      "Epoch 26/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5090 - categorical_accuracy: 0.0680\n",
      "Epoch 00026: val_loss did not improve from 41.60965\n",
      "97/97 [==============================] - 26s 267ms/step - loss: 41.5090 - categorical_accuracy: 0.0680 - val_loss: 41.6138 - val_categorical_accuracy: 0.0404\n",
      "Epoch 27/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5091 - categorical_accuracy: 0.0755\n",
      "Epoch 00027: val_loss did not improve from 41.60965\n",
      "97/97 [==============================] - 26s 263ms/step - loss: 41.5091 - categorical_accuracy: 0.0755 - val_loss: 41.6702 - val_categorical_accuracy: 0.0267\n",
      "Epoch 28/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5093 - categorical_accuracy: 0.0708\n",
      "Epoch 00028: val_loss did not improve from 41.60965\n",
      "97/97 [==============================] - 27s 275ms/step - loss: 41.5093 - categorical_accuracy: 0.0708 - val_loss: 41.6115 - val_categorical_accuracy: 0.0319\n",
      "Epoch 29/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5086 - categorical_accuracy: 0.0698\n",
      "Epoch 00029: val_loss did not improve from 41.60965\n",
      "97/97 [==============================] - 26s 272ms/step - loss: 41.5086 - categorical_accuracy: 0.0698 - val_loss: 41.6108 - val_categorical_accuracy: 0.0469\n",
      "Epoch 30/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5085 - categorical_accuracy: 0.0740\n",
      "Epoch 00030: val_loss did not improve from 41.60965\n",
      "97/97 [==============================] - 28s 284ms/step - loss: 41.5085 - categorical_accuracy: 0.0740 - val_loss: 41.6310 - val_categorical_accuracy: 0.0234\n",
      "Epoch 31/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5094 - categorical_accuracy: 0.0695\n",
      "Epoch 00031: val_loss did not improve from 41.60965\n",
      "97/97 [==============================] - 26s 273ms/step - loss: 41.5094 - categorical_accuracy: 0.0695 - val_loss: 41.6164 - val_categorical_accuracy: 0.0365\n",
      "Epoch 32/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5090 - categorical_accuracy: 0.0705\n",
      "Epoch 00032: val_loss did not improve from 41.60965\n",
      "97/97 [==============================] - 27s 280ms/step - loss: 41.5090 - categorical_accuracy: 0.0705 - val_loss: 41.6120 - val_categorical_accuracy: 0.0482\n",
      "Epoch 33/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5082 - categorical_accuracy: 0.0752\n",
      "Epoch 00033: val_loss did not improve from 41.60965\n",
      "97/97 [==============================] - 26s 269ms/step - loss: 41.5082 - categorical_accuracy: 0.0752 - val_loss: 41.6145 - val_categorical_accuracy: 0.0176\n",
      "Epoch 34/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5094 - categorical_accuracy: 0.0794\n",
      "Epoch 00034: val_loss did not improve from 41.60965\n",
      "97/97 [==============================] - 27s 281ms/step - loss: 41.5094 - categorical_accuracy: 0.0794 - val_loss: 41.8472 - val_categorical_accuracy: 0.0182\n",
      "Epoch 35/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5076 - categorical_accuracy: 0.0731\n",
      "Epoch 00035: val_loss did not improve from 41.60965\n",
      "97/97 [==============================] - 25s 258ms/step - loss: 41.5076 - categorical_accuracy: 0.0731 - val_loss: 41.6156 - val_categorical_accuracy: 0.0332\n",
      "Epoch 36/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5078 - categorical_accuracy: 0.0805\n",
      "Epoch 00036: val_loss did not improve from 41.60965\n",
      "97/97 [==============================] - 25s 262ms/step - loss: 41.5078 - categorical_accuracy: 0.0805 - val_loss: 41.6107 - val_categorical_accuracy: 0.0286\n",
      "Epoch 37/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5078 - categorical_accuracy: 0.0790\n",
      "Epoch 00037: val_loss did not improve from 41.60965\n",
      "97/97 [==============================] - 26s 268ms/step - loss: 41.5078 - categorical_accuracy: 0.0790 - val_loss: 41.6153 - val_categorical_accuracy: 0.0273\n",
      "Epoch 38/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5080 - categorical_accuracy: 0.0810\n",
      "Epoch 00038: val_loss did not improve from 41.60965\n",
      "97/97 [==============================] - 26s 264ms/step - loss: 41.5080 - categorical_accuracy: 0.0810 - val_loss: 41.6654 - val_categorical_accuracy: 0.0247\n",
      "Epoch 39/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5074 - categorical_accuracy: 0.0821\n",
      "Epoch 00039: val_loss did not improve from 41.60965\n",
      "97/97 [==============================] - 26s 271ms/step - loss: 41.5074 - categorical_accuracy: 0.0821 - val_loss: 41.6880 - val_categorical_accuracy: 0.0254\n",
      "Epoch 40/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5081 - categorical_accuracy: 0.0881\n",
      "Epoch 00040: val_loss improved from 41.60965 to 41.60816, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 25s 257ms/step - loss: 41.5081 - categorical_accuracy: 0.0881 - val_loss: 41.6082 - val_categorical_accuracy: 0.0358\n",
      "Epoch 41/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5070 - categorical_accuracy: 0.0837\n",
      "Epoch 00041: val_loss did not improve from 41.60816\n",
      "97/97 [==============================] - 26s 267ms/step - loss: 41.5070 - categorical_accuracy: 0.0837 - val_loss: 41.6091 - val_categorical_accuracy: 0.0456\n",
      "Epoch 42/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5076 - categorical_accuracy: 0.0852\n",
      "Epoch 00042: val_loss did not improve from 41.60816\n",
      "97/97 [==============================] - 25s 260ms/step - loss: 41.5076 - categorical_accuracy: 0.0852 - val_loss: 41.6367 - val_categorical_accuracy: 0.0273\n",
      "Epoch 43/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5074 - categorical_accuracy: 0.0886\n",
      "Epoch 00043: val_loss did not improve from 41.60816\n",
      "97/97 [==============================] - 27s 277ms/step - loss: 41.5074 - categorical_accuracy: 0.0886 - val_loss: 41.6107 - val_categorical_accuracy: 0.0521\n",
      "Epoch 44/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5069 - categorical_accuracy: 0.0858\n",
      "Epoch 00044: val_loss did not improve from 41.60816\n",
      "97/97 [==============================] - 26s 263ms/step - loss: 41.5069 - categorical_accuracy: 0.0858 - val_loss: 41.7591 - val_categorical_accuracy: 0.0234\n",
      "Epoch 45/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5063 - categorical_accuracy: 0.0933\n",
      "Epoch 00045: val_loss did not improve from 41.60816\n",
      "97/97 [==============================] - 25s 257ms/step - loss: 41.5063 - categorical_accuracy: 0.0933 - val_loss: 41.6094 - val_categorical_accuracy: 0.0658\n",
      "Epoch 46/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5068 - categorical_accuracy: 0.0895\n",
      "Epoch 00046: val_loss did not improve from 41.60816\n",
      "97/97 [==============================] - 27s 275ms/step - loss: 41.5068 - categorical_accuracy: 0.0895 - val_loss: 41.6103 - val_categorical_accuracy: 0.0540\n",
      "Epoch 47/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5065 - categorical_accuracy: 0.0905\n",
      "Epoch 00047: val_loss did not improve from 41.60816\n",
      "97/97 [==============================] - 26s 263ms/step - loss: 41.5065 - categorical_accuracy: 0.0905 - val_loss: 41.6622 - val_categorical_accuracy: 0.0195\n",
      "Epoch 48/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5205 - categorical_accuracy: 0.0706\n",
      "Epoch 00048: val_loss did not improve from 41.60816\n",
      "97/97 [==============================] - 27s 275ms/step - loss: 41.5205 - categorical_accuracy: 0.0706 - val_loss: 41.7602 - val_categorical_accuracy: 0.0247\n",
      "Epoch 49/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5139 - categorical_accuracy: 0.0422\n",
      "Epoch 00049: val_loss did not improve from 41.60816\n",
      "97/97 [==============================] - 26s 265ms/step - loss: 41.5139 - categorical_accuracy: 0.0422 - val_loss: 41.6201 - val_categorical_accuracy: 0.0306\n",
      "Epoch 50/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5112 - categorical_accuracy: 0.0572\n",
      "Epoch 00050: val_loss did not improve from 41.60816\n",
      "97/97 [==============================] - 26s 268ms/step - loss: 41.5112 - categorical_accuracy: 0.0572 - val_loss: 41.6131 - val_categorical_accuracy: 0.0397\n",
      "Epoch 51/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5104 - categorical_accuracy: 0.0601\n",
      "Epoch 00051: val_loss did not improve from 41.60816\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0005399999907240271.\n",
      "97/97 [==============================] - 25s 259ms/step - loss: 41.5104 - categorical_accuracy: 0.0601 - val_loss: 41.6104 - val_categorical_accuracy: 0.0417\n",
      "Epoch 52/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5088 - categorical_accuracy: 0.0616\n",
      "Epoch 00052: val_loss did not improve from 41.60816\n",
      "97/97 [==============================] - 26s 268ms/step - loss: 41.5088 - categorical_accuracy: 0.0616 - val_loss: 41.6088 - val_categorical_accuracy: 0.0436\n",
      "Epoch 53/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5080 - categorical_accuracy: 0.0647\n",
      "Epoch 00053: val_loss improved from 41.60816 to 41.60727, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 27s 278ms/step - loss: 41.5080 - categorical_accuracy: 0.0647 - val_loss: 41.6073 - val_categorical_accuracy: 0.0339\n",
      "Epoch 54/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5074 - categorical_accuracy: 0.0640\n",
      "Epoch 00054: val_loss did not improve from 41.60727\n",
      "97/97 [==============================] - 26s 268ms/step - loss: 41.5074 - categorical_accuracy: 0.0640 - val_loss: 41.6073 - val_categorical_accuracy: 0.0449\n",
      "Epoch 55/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5080 - categorical_accuracy: 0.0710\n",
      "Epoch 00055: val_loss did not improve from 41.60727\n",
      "97/97 [==============================] - 26s 267ms/step - loss: 41.5080 - categorical_accuracy: 0.0710 - val_loss: 41.6106 - val_categorical_accuracy: 0.0384\n",
      "Epoch 56/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5083 - categorical_accuracy: 0.0674\n",
      "Epoch 00056: val_loss did not improve from 41.60727\n",
      "97/97 [==============================] - 26s 269ms/step - loss: 41.5083 - categorical_accuracy: 0.0674 - val_loss: 41.6090 - val_categorical_accuracy: 0.0423\n",
      "Epoch 57/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5073 - categorical_accuracy: 0.0697\n",
      "Epoch 00057: val_loss did not improve from 41.60727\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.00032399998744949695.\n",
      "97/97 [==============================] - 27s 279ms/step - loss: 41.5073 - categorical_accuracy: 0.0697 - val_loss: 41.6078 - val_categorical_accuracy: 0.0404\n",
      "Epoch 58/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5063 - categorical_accuracy: 0.0766\n",
      "Epoch 00058: val_loss did not improve from 41.60727\n",
      "97/97 [==============================] - 27s 274ms/step - loss: 41.5063 - categorical_accuracy: 0.0766 - val_loss: 41.6075 - val_categorical_accuracy: 0.0391\n",
      "Epoch 59/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5063 - categorical_accuracy: 0.0750\n",
      "Epoch 00059: val_loss did not improve from 41.60727\n",
      "97/97 [==============================] - 27s 276ms/step - loss: 41.5063 - categorical_accuracy: 0.0750 - val_loss: 41.6081 - val_categorical_accuracy: 0.0449\n",
      "Epoch 60/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5065 - categorical_accuracy: 0.0773\n",
      "Epoch 00060: val_loss did not improve from 41.60727\n",
      "97/97 [==============================] - 25s 259ms/step - loss: 41.5065 - categorical_accuracy: 0.0773 - val_loss: 41.6110 - val_categorical_accuracy: 0.0404\n",
      "Epoch 61/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5060 - categorical_accuracy: 0.0797\n",
      "Epoch 00061: val_loss improved from 41.60727 to 41.60634, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 27s 278ms/step - loss: 41.5060 - categorical_accuracy: 0.0797 - val_loss: 41.6063 - val_categorical_accuracy: 0.0508\n",
      "Epoch 62/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5059 - categorical_accuracy: 0.0761\n",
      "Epoch 00062: val_loss did not improve from 41.60634\n",
      "97/97 [==============================] - 27s 275ms/step - loss: 41.5059 - categorical_accuracy: 0.0761 - val_loss: 41.6067 - val_categorical_accuracy: 0.0456\n",
      "Epoch 63/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5061 - categorical_accuracy: 0.0816\n",
      "Epoch 00063: val_loss did not improve from 41.60634\n",
      "97/97 [==============================] - 26s 269ms/step - loss: 41.5061 - categorical_accuracy: 0.0816 - val_loss: 41.6069 - val_categorical_accuracy: 0.0397\n",
      "Epoch 64/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5061 - categorical_accuracy: 0.0769\n",
      "Epoch 00064: val_loss did not improve from 41.60634\n",
      "97/97 [==============================] - 26s 266ms/step - loss: 41.5061 - categorical_accuracy: 0.0769 - val_loss: 41.6082 - val_categorical_accuracy: 0.0534\n",
      "Epoch 65/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5058 - categorical_accuracy: 0.0824\n",
      "Epoch 00065: val_loss did not improve from 41.60634\n",
      "97/97 [==============================] - 27s 274ms/step - loss: 41.5058 - categorical_accuracy: 0.0824 - val_loss: 41.6074 - val_categorical_accuracy: 0.0469\n",
      "Epoch 66/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5058 - categorical_accuracy: 0.0928\n",
      "Epoch 00066: val_loss did not improve from 41.60634\n",
      "97/97 [==============================] - 27s 283ms/step - loss: 41.5058 - categorical_accuracy: 0.0928 - val_loss: 41.6094 - val_categorical_accuracy: 0.0384\n",
      "Epoch 67/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5053 - categorical_accuracy: 0.0844\n",
      "Epoch 00067: val_loss did not improve from 41.60634\n",
      "97/97 [==============================] - 27s 274ms/step - loss: 41.5053 - categorical_accuracy: 0.0844 - val_loss: 41.6066 - val_categorical_accuracy: 0.0508\n",
      "Epoch 68/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5055 - categorical_accuracy: 0.0892\n",
      "Epoch 00068: val_loss did not improve from 41.60634\n",
      "97/97 [==============================] - 27s 281ms/step - loss: 41.5055 - categorical_accuracy: 0.0892 - val_loss: 41.6065 - val_categorical_accuracy: 0.0527\n",
      "Epoch 69/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5054 - categorical_accuracy: 0.0915\n",
      "Epoch 00069: val_loss did not improve from 41.60634\n",
      "97/97 [==============================] - 25s 253ms/step - loss: 41.5054 - categorical_accuracy: 0.0915 - val_loss: 41.6071 - val_categorical_accuracy: 0.0508\n",
      "Epoch 70/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5056 - categorical_accuracy: 0.0897\n",
      "Epoch 00070: val_loss did not improve from 41.60634\n",
      "97/97 [==============================] - 27s 279ms/step - loss: 41.5056 - categorical_accuracy: 0.0897 - val_loss: 41.6071 - val_categorical_accuracy: 0.0482\n",
      "Epoch 71/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5053 - categorical_accuracy: 0.0863\n",
      "Epoch 00071: val_loss did not improve from 41.60634\n",
      "97/97 [==============================] - 27s 277ms/step - loss: 41.5053 - categorical_accuracy: 0.0863 - val_loss: 41.6072 - val_categorical_accuracy: 0.0469\n",
      "Epoch 72/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5049 - categorical_accuracy: 0.0983\n",
      "Epoch 00072: val_loss did not improve from 41.60634\n",
      "97/97 [==============================] - 27s 275ms/step - loss: 41.5049 - categorical_accuracy: 0.0983 - val_loss: 41.6068 - val_categorical_accuracy: 0.0508\n",
      "Epoch 73/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5050 - categorical_accuracy: 0.0852\n",
      "Epoch 00073: val_loss did not improve from 41.60634\n",
      "97/97 [==============================] - 26s 268ms/step - loss: 41.5050 - categorical_accuracy: 0.0852 - val_loss: 41.6064 - val_categorical_accuracy: 0.0547\n",
      "Epoch 74/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5053 - categorical_accuracy: 0.0942\n",
      "Epoch 00074: val_loss did not improve from 41.60634\n",
      "97/97 [==============================] - 27s 273ms/step - loss: 41.5053 - categorical_accuracy: 0.0942 - val_loss: 41.6070 - val_categorical_accuracy: 0.0495\n",
      "Epoch 75/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5047 - categorical_accuracy: 0.0931\n",
      "Epoch 00075: val_loss did not improve from 41.60634\n",
      "97/97 [==============================] - 27s 283ms/step - loss: 41.5047 - categorical_accuracy: 0.0931 - val_loss: 41.6099 - val_categorical_accuracy: 0.0430\n",
      "Epoch 76/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5049 - categorical_accuracy: 0.0984\n",
      "Epoch 00076: val_loss did not improve from 41.60634\n",
      "97/97 [==============================] - 27s 275ms/step - loss: 41.5049 - categorical_accuracy: 0.0984 - val_loss: 41.6205 - val_categorical_accuracy: 0.0260\n",
      "Epoch 77/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5048 - categorical_accuracy: 0.1036\n",
      "Epoch 00077: val_loss did not improve from 41.60634\n",
      "97/97 [==============================] - 26s 264ms/step - loss: 41.5048 - categorical_accuracy: 0.1036 - val_loss: 41.6076 - val_categorical_accuracy: 0.0488\n",
      "Epoch 78/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5046 - categorical_accuracy: 0.1000\n",
      "Epoch 00078: val_loss did not improve from 41.60634\n",
      "97/97 [==============================] - 26s 271ms/step - loss: 41.5046 - categorical_accuracy: 0.1000 - val_loss: 41.6063 - val_categorical_accuracy: 0.0716\n",
      "Epoch 79/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5049 - categorical_accuracy: 0.1021\n",
      "Epoch 00079: val_loss did not improve from 41.60634\n",
      "97/97 [==============================] - 28s 284ms/step - loss: 41.5049 - categorical_accuracy: 0.1021 - val_loss: 41.6065 - val_categorical_accuracy: 0.0579\n",
      "Epoch 80/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5045 - categorical_accuracy: 0.0968\n",
      "Epoch 00080: val_loss improved from 41.60634 to 41.60609, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 27s 278ms/step - loss: 41.5045 - categorical_accuracy: 0.0968 - val_loss: 41.6061 - val_categorical_accuracy: 0.0566\n",
      "Epoch 81/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5045 - categorical_accuracy: 0.1030\n",
      "Epoch 00081: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 25s 257ms/step - loss: 41.5045 - categorical_accuracy: 0.1030 - val_loss: 41.6166 - val_categorical_accuracy: 0.0352\n",
      "Epoch 82/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5043 - categorical_accuracy: 0.0986\n",
      "Epoch 00082: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 27s 281ms/step - loss: 41.5043 - categorical_accuracy: 0.0986 - val_loss: 41.6081 - val_categorical_accuracy: 0.0508\n",
      "Epoch 83/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5045 - categorical_accuracy: 0.1051\n",
      "Epoch 00083: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 27s 275ms/step - loss: 41.5045 - categorical_accuracy: 0.1051 - val_loss: 41.6148 - val_categorical_accuracy: 0.0397\n",
      "Epoch 84/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5042 - categorical_accuracy: 0.1055\n",
      "Epoch 00084: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 27s 282ms/step - loss: 41.5042 - categorical_accuracy: 0.1055 - val_loss: 41.6067 - val_categorical_accuracy: 0.0645\n",
      "Epoch 85/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5042 - categorical_accuracy: 0.1068\n",
      "Epoch 00085: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 25s 259ms/step - loss: 41.5042 - categorical_accuracy: 0.1068 - val_loss: 41.6069 - val_categorical_accuracy: 0.0566\n",
      "Epoch 86/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5041 - categorical_accuracy: 0.1046\n",
      "Epoch 00086: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 27s 282ms/step - loss: 41.5041 - categorical_accuracy: 0.1046 - val_loss: 41.6150 - val_categorical_accuracy: 0.0391\n",
      "Epoch 87/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5038 - categorical_accuracy: 0.1064\n",
      "Epoch 00087: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 26s 271ms/step - loss: 41.5038 - categorical_accuracy: 0.1064 - val_loss: 41.6069 - val_categorical_accuracy: 0.0579\n",
      "Epoch 88/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5040 - categorical_accuracy: 0.1051\n",
      "Epoch 00088: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 27s 283ms/step - loss: 41.5040 - categorical_accuracy: 0.1051 - val_loss: 41.6215 - val_categorical_accuracy: 0.0410\n",
      "Epoch 89/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5036 - categorical_accuracy: 0.1072\n",
      "Epoch 00089: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 24s 251ms/step - loss: 41.5036 - categorical_accuracy: 0.1072 - val_loss: 41.6104 - val_categorical_accuracy: 0.0430\n",
      "Epoch 90/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5036 - categorical_accuracy: 0.1028\n",
      "Epoch 00090: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 27s 280ms/step - loss: 41.5036 - categorical_accuracy: 0.1028 - val_loss: 41.6104 - val_categorical_accuracy: 0.0423\n",
      "Epoch 91/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5037 - categorical_accuracy: 0.1109\n",
      "Epoch 00091: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 27s 277ms/step - loss: 41.5037 - categorical_accuracy: 0.1109 - val_loss: 41.6080 - val_categorical_accuracy: 0.0592\n",
      "Epoch 92/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5038 - categorical_accuracy: 0.1128\n",
      "Epoch 00092: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 27s 277ms/step - loss: 41.5038 - categorical_accuracy: 0.1128 - val_loss: 41.6088 - val_categorical_accuracy: 0.0690\n",
      "Epoch 93/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5039 - categorical_accuracy: 0.1086\n",
      "Epoch 00093: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 25s 262ms/step - loss: 41.5039 - categorical_accuracy: 0.1086 - val_loss: 41.6098 - val_categorical_accuracy: 0.0501\n",
      "Epoch 94/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5036 - categorical_accuracy: 0.1159\n",
      "Epoch 00094: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 26s 273ms/step - loss: 41.5036 - categorical_accuracy: 0.1159 - val_loss: 41.6067 - val_categorical_accuracy: 0.0540\n",
      "Epoch 95/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5034 - categorical_accuracy: 0.1109\n",
      "Epoch 00095: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 27s 281ms/step - loss: 41.5034 - categorical_accuracy: 0.1109 - val_loss: 41.6085 - val_categorical_accuracy: 0.0579\n",
      "Epoch 96/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5036 - categorical_accuracy: 0.1152\n",
      "Epoch 00096: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 27s 275ms/step - loss: 41.5036 - categorical_accuracy: 0.1152 - val_loss: 41.6086 - val_categorical_accuracy: 0.0566\n",
      "Epoch 97/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5032 - categorical_accuracy: 0.1190\n",
      "Epoch 00097: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 25s 262ms/step - loss: 41.5032 - categorical_accuracy: 0.1190 - val_loss: 41.6110 - val_categorical_accuracy: 0.0430\n",
      "Epoch 98/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5033 - categorical_accuracy: 0.1178\n",
      "Epoch 00098: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 27s 275ms/step - loss: 41.5033 - categorical_accuracy: 0.1178 - val_loss: 41.6154 - val_categorical_accuracy: 0.0423\n",
      "Epoch 99/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5033 - categorical_accuracy: 0.1169\n",
      "Epoch 00099: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 27s 279ms/step - loss: 41.5033 - categorical_accuracy: 0.1169 - val_loss: 41.6118 - val_categorical_accuracy: 0.0417\n",
      "Epoch 100/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5032 - categorical_accuracy: 0.1165\n",
      "Epoch 00100: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 27s 279ms/step - loss: 41.5032 - categorical_accuracy: 0.1165 - val_loss: 41.6270 - val_categorical_accuracy: 0.0397\n",
      "Epoch 101/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5026 - categorical_accuracy: 0.1172\n",
      "Epoch 00101: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 24s 250ms/step - loss: 41.5026 - categorical_accuracy: 0.1172 - val_loss: 41.6157 - val_categorical_accuracy: 0.0456\n",
      "Epoch 102/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5028 - categorical_accuracy: 0.1185\n",
      "Epoch 00102: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 28s 284ms/step - loss: 41.5028 - categorical_accuracy: 0.1185 - val_loss: 41.6246 - val_categorical_accuracy: 0.0397\n",
      "Epoch 103/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5029 - categorical_accuracy: 0.1194\n",
      "Epoch 00103: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 27s 274ms/step - loss: 41.5029 - categorical_accuracy: 0.1194 - val_loss: 41.6079 - val_categorical_accuracy: 0.0703\n",
      "Epoch 104/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5029 - categorical_accuracy: 0.1193\n",
      "Epoch 00104: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 28s 285ms/step - loss: 41.5029 - categorical_accuracy: 0.1193 - val_loss: 41.6818 - val_categorical_accuracy: 0.0378\n",
      "Epoch 105/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5026 - categorical_accuracy: 0.1264\n",
      "Epoch 00105: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 24s 251ms/step - loss: 41.5026 - categorical_accuracy: 0.1264 - val_loss: 41.6100 - val_categorical_accuracy: 0.0612\n",
      "Epoch 106/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5025 - categorical_accuracy: 0.1169\n",
      "Epoch 00106: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 27s 282ms/step - loss: 41.5025 - categorical_accuracy: 0.1169 - val_loss: 41.6082 - val_categorical_accuracy: 0.0645\n",
      "Epoch 107/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5027 - categorical_accuracy: 0.1207\n",
      "Epoch 00107: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 27s 277ms/step - loss: 41.5027 - categorical_accuracy: 0.1207 - val_loss: 41.6203 - val_categorical_accuracy: 0.0534\n",
      "Epoch 108/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5022 - categorical_accuracy: 0.1270\n",
      "Epoch 00108: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 25s 253ms/step - loss: 41.5022 - categorical_accuracy: 0.1270 - val_loss: 41.6113 - val_categorical_accuracy: 0.0599\n",
      "Epoch 109/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5027 - categorical_accuracy: 0.1288\n",
      "Epoch 00109: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 27s 283ms/step - loss: 41.5027 - categorical_accuracy: 0.1288 - val_loss: 41.6137 - val_categorical_accuracy: 0.0456\n",
      "Epoch 110/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5023 - categorical_accuracy: 0.1196\n",
      "Epoch 00110: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 27s 277ms/step - loss: 41.5023 - categorical_accuracy: 0.1196 - val_loss: 41.6071 - val_categorical_accuracy: 0.0553\n",
      "Epoch 111/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5021 - categorical_accuracy: 0.1267\n",
      "Epoch 00111: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 28s 288ms/step - loss: 41.5021 - categorical_accuracy: 0.1267 - val_loss: 41.6715 - val_categorical_accuracy: 0.0202\n",
      "Epoch 112/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5018 - categorical_accuracy: 0.1280\n",
      "Epoch 00112: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 24s 251ms/step - loss: 41.5018 - categorical_accuracy: 0.1280 - val_loss: 41.6070 - val_categorical_accuracy: 0.0527\n",
      "Epoch 113/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5019 - categorical_accuracy: 0.1324\n",
      "Epoch 00113: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 28s 292ms/step - loss: 41.5019 - categorical_accuracy: 0.1324 - val_loss: 41.6161 - val_categorical_accuracy: 0.0482\n",
      "Epoch 114/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5016 - categorical_accuracy: 0.1298\n",
      "Epoch 00114: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 28s 286ms/step - loss: 41.5016 - categorical_accuracy: 0.1298 - val_loss: 41.6266 - val_categorical_accuracy: 0.0391\n",
      "Epoch 115/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5021 - categorical_accuracy: 0.1248\n",
      "Epoch 00115: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 28s 293ms/step - loss: 41.5021 - categorical_accuracy: 0.1248 - val_loss: 41.6068 - val_categorical_accuracy: 0.0775\n",
      "Epoch 116/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5019 - categorical_accuracy: 0.1319\n",
      "Epoch 00116: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 24s 252ms/step - loss: 41.5019 - categorical_accuracy: 0.1319 - val_loss: 41.6082 - val_categorical_accuracy: 0.0599\n",
      "Epoch 117/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5018 - categorical_accuracy: 0.1287\n",
      "Epoch 00117: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 28s 288ms/step - loss: 41.5018 - categorical_accuracy: 0.1287 - val_loss: 41.6316 - val_categorical_accuracy: 0.0404\n",
      "Epoch 118/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5019 - categorical_accuracy: 0.1249\n",
      "Epoch 00118: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 27s 280ms/step - loss: 41.5019 - categorical_accuracy: 0.1249 - val_loss: 41.6077 - val_categorical_accuracy: 0.0592\n",
      "Epoch 119/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5014 - categorical_accuracy: 0.1342\n",
      "Epoch 00119: val_loss did not improve from 41.60609\n",
      "97/97 [==============================] - 25s 260ms/step - loss: 41.5014 - categorical_accuracy: 0.1342 - val_loss: 41.6094 - val_categorical_accuracy: 0.0599\n",
      "Epoch 120/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5017 - categorical_accuracy: 0.1354\n",
      "Epoch 00120: val_loss improved from 41.60609 to 41.60562, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 28s 284ms/step - loss: 41.5017 - categorical_accuracy: 0.1354 - val_loss: 41.6056 - val_categorical_accuracy: 0.0671\n",
      "Epoch 121/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5016 - categorical_accuracy: 0.1295\n",
      "Epoch 00121: val_loss improved from 41.60562 to 41.60548, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 28s 289ms/step - loss: 41.5016 - categorical_accuracy: 0.1295 - val_loss: 41.6055 - val_categorical_accuracy: 0.0710\n",
      "Epoch 122/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5014 - categorical_accuracy: 0.1319\n",
      "Epoch 00122: val_loss did not improve from 41.60548\n",
      "97/97 [==============================] - 25s 262ms/step - loss: 41.5014 - categorical_accuracy: 0.1319 - val_loss: 41.6099 - val_categorical_accuracy: 0.0592\n",
      "Epoch 123/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5015 - categorical_accuracy: 0.1343\n",
      "Epoch 00123: val_loss did not improve from 41.60548\n",
      "97/97 [==============================] - 24s 251ms/step - loss: 41.5015 - categorical_accuracy: 0.1343 - val_loss: 41.6065 - val_categorical_accuracy: 0.0612\n",
      "Epoch 124/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5015 - categorical_accuracy: 0.1317\n",
      "Epoch 00124: val_loss did not improve from 41.60548\n",
      "97/97 [==============================] - 28s 291ms/step - loss: 41.5015 - categorical_accuracy: 0.1317 - val_loss: 41.6137 - val_categorical_accuracy: 0.0579\n",
      "Epoch 125/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5013 - categorical_accuracy: 0.1324\n",
      "Epoch 00125: val_loss did not improve from 41.60548\n",
      "97/97 [==============================] - 25s 253ms/step - loss: 41.5013 - categorical_accuracy: 0.1324 - val_loss: 41.6061 - val_categorical_accuracy: 0.0690\n",
      "Epoch 126/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5009 - categorical_accuracy: 0.1358\n",
      "Epoch 00126: val_loss did not improve from 41.60548\n",
      "97/97 [==============================] - 28s 292ms/step - loss: 41.5009 - categorical_accuracy: 0.1358 - val_loss: 41.6075 - val_categorical_accuracy: 0.0671\n",
      "Epoch 127/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5012 - categorical_accuracy: 0.1343\n",
      "Epoch 00127: val_loss did not improve from 41.60548\n",
      "97/97 [==============================] - 25s 253ms/step - loss: 41.5012 - categorical_accuracy: 0.1343 - val_loss: 41.6055 - val_categorical_accuracy: 0.0768\n",
      "Epoch 128/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5009 - categorical_accuracy: 0.1330\n",
      "Epoch 00128: val_loss did not improve from 41.60548\n",
      "97/97 [==============================] - 25s 256ms/step - loss: 41.5009 - categorical_accuracy: 0.1330 - val_loss: 41.6086 - val_categorical_accuracy: 0.0586\n",
      "Epoch 129/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5011 - categorical_accuracy: 0.1367\n",
      "Epoch 00129: val_loss did not improve from 41.60548\n",
      "97/97 [==============================] - 29s 302ms/step - loss: 41.5011 - categorical_accuracy: 0.1367 - val_loss: 41.6221 - val_categorical_accuracy: 0.0462\n",
      "Epoch 130/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5005 - categorical_accuracy: 0.1400\n",
      "Epoch 00130: val_loss did not improve from 41.60548\n",
      "97/97 [==============================] - 26s 268ms/step - loss: 41.5005 - categorical_accuracy: 0.1400 - val_loss: 41.6082 - val_categorical_accuracy: 0.0540\n",
      "Epoch 131/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5008 - categorical_accuracy: 0.1392\n",
      "Epoch 00131: val_loss improved from 41.60548 to 41.60540, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 31s 317ms/step - loss: 41.5008 - categorical_accuracy: 0.1392 - val_loss: 41.6054 - val_categorical_accuracy: 0.0677\n",
      "Epoch 132/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5004 - categorical_accuracy: 0.1345\n",
      "Epoch 00132: val_loss did not improve from 41.60540\n",
      "97/97 [==============================] - 26s 267ms/step - loss: 41.5004 - categorical_accuracy: 0.1345 - val_loss: 41.6068 - val_categorical_accuracy: 0.0651\n",
      "Epoch 133/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5008 - categorical_accuracy: 0.1377\n",
      "Epoch 00133: val_loss did not improve from 41.60540\n",
      "97/97 [==============================] - 26s 269ms/step - loss: 41.5008 - categorical_accuracy: 0.1377 - val_loss: 41.6293 - val_categorical_accuracy: 0.0443\n",
      "Epoch 134/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5008 - categorical_accuracy: 0.1406\n",
      "Epoch 00134: val_loss improved from 41.60540 to 41.60520, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 29s 300ms/step - loss: 41.5008 - categorical_accuracy: 0.1406 - val_loss: 41.6052 - val_categorical_accuracy: 0.0645\n",
      "Epoch 135/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5002 - categorical_accuracy: 0.1403\n",
      "Epoch 00135: val_loss did not improve from 41.60520\n",
      "97/97 [==============================] - 26s 267ms/step - loss: 41.5002 - categorical_accuracy: 0.1403 - val_loss: 41.6073 - val_categorical_accuracy: 0.0605\n",
      "Epoch 136/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5005 - categorical_accuracy: 0.1447\n",
      "Epoch 00136: val_loss did not improve from 41.60520\n",
      "97/97 [==============================] - 28s 292ms/step - loss: 41.5005 - categorical_accuracy: 0.1447 - val_loss: 41.6098 - val_categorical_accuracy: 0.0605\n",
      "Epoch 137/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5006 - categorical_accuracy: 0.1385\n",
      "Epoch 00137: val_loss did not improve from 41.60520\n",
      "97/97 [==============================] - 26s 265ms/step - loss: 41.5006 - categorical_accuracy: 0.1385 - val_loss: 41.6201 - val_categorical_accuracy: 0.0592\n",
      "Epoch 138/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5002 - categorical_accuracy: 0.1398\n",
      "Epoch 00138: val_loss did not improve from 41.60520\n",
      "97/97 [==============================] - 25s 255ms/step - loss: 41.5002 - categorical_accuracy: 0.1398 - val_loss: 41.6115 - val_categorical_accuracy: 0.0690\n",
      "Epoch 139/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5002 - categorical_accuracy: 0.1466\n",
      "Epoch 00139: val_loss did not improve from 41.60520\n",
      "97/97 [==============================] - 29s 297ms/step - loss: 41.5002 - categorical_accuracy: 0.1466 - val_loss: 41.7642 - val_categorical_accuracy: 0.0423\n",
      "Epoch 140/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5001 - categorical_accuracy: 0.1427\n",
      "Epoch 00140: val_loss did not improve from 41.60520\n",
      "97/97 [==============================] - 25s 261ms/step - loss: 41.5001 - categorical_accuracy: 0.1427 - val_loss: 41.6089 - val_categorical_accuracy: 0.0632\n",
      "Epoch 141/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5007 - categorical_accuracy: 0.1430\n",
      "Epoch 00141: val_loss did not improve from 41.60520\n",
      "97/97 [==============================] - 28s 293ms/step - loss: 41.5007 - categorical_accuracy: 0.1430 - val_loss: 41.6103 - val_categorical_accuracy: 0.0632\n",
      "Epoch 142/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5006 - categorical_accuracy: 0.1406\n",
      "Epoch 00142: val_loss did not improve from 41.60520\n",
      "97/97 [==============================] - 26s 269ms/step - loss: 41.5006 - categorical_accuracy: 0.1406 - val_loss: 41.6084 - val_categorical_accuracy: 0.0599\n",
      "Epoch 143/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5004 - categorical_accuracy: 0.1429\n",
      "Epoch 00143: val_loss did not improve from 41.60520\n",
      "97/97 [==============================] - 25s 257ms/step - loss: 41.5004 - categorical_accuracy: 0.1429 - val_loss: 41.6268 - val_categorical_accuracy: 0.0625\n",
      "Epoch 144/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4998 - categorical_accuracy: 0.1430\n",
      "Epoch 00144: val_loss did not improve from 41.60520\n",
      "97/97 [==============================] - 29s 302ms/step - loss: 41.4998 - categorical_accuracy: 0.1430 - val_loss: 41.6065 - val_categorical_accuracy: 0.0742\n",
      "Epoch 145/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4999 - categorical_accuracy: 0.1451\n",
      "Epoch 00145: val_loss did not improve from 41.60520\n",
      "97/97 [==============================] - 25s 257ms/step - loss: 41.4999 - categorical_accuracy: 0.1451 - val_loss: 41.6058 - val_categorical_accuracy: 0.0775\n",
      "Epoch 146/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4992 - categorical_accuracy: 0.1456\n",
      "Epoch 00146: val_loss did not improve from 41.60520\n",
      "97/97 [==============================] - 28s 291ms/step - loss: 41.4992 - categorical_accuracy: 0.1456 - val_loss: 41.6208 - val_categorical_accuracy: 0.0553\n",
      "Epoch 147/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4997 - categorical_accuracy: 0.1445\n",
      "Epoch 00147: val_loss did not improve from 41.60520\n",
      "97/97 [==============================] - 25s 263ms/step - loss: 41.4997 - categorical_accuracy: 0.1445 - val_loss: 41.6205 - val_categorical_accuracy: 0.0553\n",
      "Epoch 148/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4999 - categorical_accuracy: 0.1440\n",
      "Epoch 00148: val_loss did not improve from 41.60520\n",
      "97/97 [==============================] - 26s 264ms/step - loss: 41.4999 - categorical_accuracy: 0.1440 - val_loss: 41.6441 - val_categorical_accuracy: 0.0397\n",
      "Epoch 149/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4998 - categorical_accuracy: 0.1396\n",
      "Epoch 00149: val_loss did not improve from 41.60520\n",
      "97/97 [==============================] - 29s 295ms/step - loss: 41.4998 - categorical_accuracy: 0.1396 - val_loss: 41.6169 - val_categorical_accuracy: 0.0443\n",
      "Epoch 150/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4996 - categorical_accuracy: 0.1474\n",
      "Epoch 00150: val_loss improved from 41.60520 to 41.60376, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 25s 256ms/step - loss: 41.4996 - categorical_accuracy: 0.1474 - val_loss: 41.6038 - val_categorical_accuracy: 0.0801\n",
      "Epoch 151/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4993 - categorical_accuracy: 0.1489\n",
      "Epoch 00151: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 26s 265ms/step - loss: 41.4993 - categorical_accuracy: 0.1489 - val_loss: 41.6120 - val_categorical_accuracy: 0.0560\n",
      "Epoch 152/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4996 - categorical_accuracy: 0.1490\n",
      "Epoch 00152: val_loss did not improve from 41.60376\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 0.00019439999596215785.\n",
      "97/97 [==============================] - 29s 295ms/step - loss: 41.4996 - categorical_accuracy: 0.1490 - val_loss: 41.6073 - val_categorical_accuracy: 0.0671\n",
      "Epoch 153/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4989 - categorical_accuracy: 0.1581\n",
      "Epoch 00153: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 26s 266ms/step - loss: 41.4989 - categorical_accuracy: 0.1581 - val_loss: 41.6063 - val_categorical_accuracy: 0.0755\n",
      "Epoch 154/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4985 - categorical_accuracy: 0.1576\n",
      "Epoch 00154: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 29s 302ms/step - loss: 41.4985 - categorical_accuracy: 0.1576 - val_loss: 41.6094 - val_categorical_accuracy: 0.0592\n",
      "Epoch 155/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4985 - categorical_accuracy: 0.1558\n",
      "Epoch 00155: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 26s 268ms/step - loss: 41.4985 - categorical_accuracy: 0.1558 - val_loss: 41.6055 - val_categorical_accuracy: 0.0788\n",
      "Epoch 156/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4983 - categorical_accuracy: 0.1529\n",
      "Epoch 00156: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 25s 257ms/step - loss: 41.4983 - categorical_accuracy: 0.1529 - val_loss: 41.6389 - val_categorical_accuracy: 0.0469\n",
      "Epoch 157/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4985 - categorical_accuracy: 0.1560\n",
      "Epoch 00157: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 30s 308ms/step - loss: 41.4985 - categorical_accuracy: 0.1560 - val_loss: 41.6060 - val_categorical_accuracy: 0.0710\n",
      "Epoch 158/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4983 - categorical_accuracy: 0.1502\n",
      "Epoch 00158: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 25s 257ms/step - loss: 41.4983 - categorical_accuracy: 0.1502 - val_loss: 41.6091 - val_categorical_accuracy: 0.0566\n",
      "Epoch 159/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4981 - categorical_accuracy: 0.1602\n",
      "Epoch 00159: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 29s 300ms/step - loss: 41.4981 - categorical_accuracy: 0.1602 - val_loss: 41.6445 - val_categorical_accuracy: 0.0475\n",
      "Epoch 160/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4980 - categorical_accuracy: 0.1602\n",
      "Epoch 00160: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 26s 266ms/step - loss: 41.4980 - categorical_accuracy: 0.1602 - val_loss: 41.6081 - val_categorical_accuracy: 0.0697\n",
      "Epoch 161/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4980 - categorical_accuracy: 0.1539\n",
      "Epoch 00161: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 24s 253ms/step - loss: 41.4980 - categorical_accuracy: 0.1539 - val_loss: 41.6051 - val_categorical_accuracy: 0.0807\n",
      "Epoch 162/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4980 - categorical_accuracy: 0.1566\n",
      "Epoch 00162: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 29s 299ms/step - loss: 41.4980 - categorical_accuracy: 0.1566 - val_loss: 41.6126 - val_categorical_accuracy: 0.0605\n",
      "Epoch 163/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4978 - categorical_accuracy: 0.1582\n",
      "Epoch 00163: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 24s 251ms/step - loss: 41.4978 - categorical_accuracy: 0.1582 - val_loss: 41.6041 - val_categorical_accuracy: 0.0872\n",
      "Epoch 164/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4977 - categorical_accuracy: 0.1613\n",
      "Epoch 00164: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 25s 256ms/step - loss: 41.4977 - categorical_accuracy: 0.1613 - val_loss: 41.6052 - val_categorical_accuracy: 0.0768\n",
      "Epoch 165/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4979 - categorical_accuracy: 0.1573\n",
      "Epoch 00165: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 28s 290ms/step - loss: 41.4979 - categorical_accuracy: 0.1573 - val_loss: 41.6078 - val_categorical_accuracy: 0.0684\n",
      "Epoch 166/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4979 - categorical_accuracy: 0.1584\n",
      "Epoch 00166: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 25s 260ms/step - loss: 41.4979 - categorical_accuracy: 0.1584 - val_loss: 41.6183 - val_categorical_accuracy: 0.0514\n",
      "Epoch 167/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4976 - categorical_accuracy: 0.1607\n",
      "Epoch 00167: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 29s 295ms/step - loss: 41.4976 - categorical_accuracy: 0.1607 - val_loss: 41.6056 - val_categorical_accuracy: 0.0775\n",
      "Epoch 168/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4977 - categorical_accuracy: 0.1616\n",
      "Epoch 00168: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 25s 255ms/step - loss: 41.4977 - categorical_accuracy: 0.1616 - val_loss: 41.6062 - val_categorical_accuracy: 0.0866\n",
      "Epoch 169/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4974 - categorical_accuracy: 0.1608\n",
      "Epoch 00169: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 24s 248ms/step - loss: 41.4974 - categorical_accuracy: 0.1608 - val_loss: 41.6054 - val_categorical_accuracy: 0.0794\n",
      "Epoch 170/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4976 - categorical_accuracy: 0.1615\n",
      "Epoch 00170: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 28s 285ms/step - loss: 41.4976 - categorical_accuracy: 0.1615 - val_loss: 41.6047 - val_categorical_accuracy: 0.0885\n",
      "Epoch 171/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4976 - categorical_accuracy: 0.1662\n",
      "Epoch 00171: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 25s 253ms/step - loss: 41.4976 - categorical_accuracy: 0.1662 - val_loss: 41.6059 - val_categorical_accuracy: 0.0846\n",
      "Epoch 172/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4976 - categorical_accuracy: 0.1647\n",
      "Epoch 00172: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 24s 246ms/step - loss: 41.4976 - categorical_accuracy: 0.1647 - val_loss: 41.6052 - val_categorical_accuracy: 0.0827\n",
      "Epoch 173/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4974 - categorical_accuracy: 0.1623\n",
      "Epoch 00173: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 30s 305ms/step - loss: 41.4974 - categorical_accuracy: 0.1623 - val_loss: 41.6051 - val_categorical_accuracy: 0.0853\n",
      "Epoch 174/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4980 - categorical_accuracy: 0.1637\n",
      "Epoch 00174: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 24s 251ms/step - loss: 41.4980 - categorical_accuracy: 0.1637 - val_loss: 41.6072 - val_categorical_accuracy: 0.0749\n",
      "Epoch 175/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4973 - categorical_accuracy: 0.1631\n",
      "Epoch 00175: val_loss did not improve from 41.60376\n",
      "\n",
      "Epoch 00175: ReduceLROnPlateau reducing learning rate to 0.0001166399975772947.\n",
      "97/97 [==============================] - 29s 302ms/step - loss: 41.4973 - categorical_accuracy: 0.1631 - val_loss: 41.6077 - val_categorical_accuracy: 0.0664\n",
      "Epoch 176/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4970 - categorical_accuracy: 0.1691\n",
      "Epoch 00176: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 25s 254ms/step - loss: 41.4970 - categorical_accuracy: 0.1691 - val_loss: 41.6127 - val_categorical_accuracy: 0.0697\n",
      "Epoch 177/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4970 - categorical_accuracy: 0.1670\n",
      "Epoch 00177: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 26s 267ms/step - loss: 41.4970 - categorical_accuracy: 0.1670 - val_loss: 41.6049 - val_categorical_accuracy: 0.0885\n",
      "Epoch 178/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4965 - categorical_accuracy: 0.1715\n",
      "Epoch 00178: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 31s 323ms/step - loss: 41.4965 - categorical_accuracy: 0.1715 - val_loss: 41.6045 - val_categorical_accuracy: 0.0820\n",
      "Epoch 179/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4969 - categorical_accuracy: 0.1668\n",
      "Epoch 00179: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 26s 273ms/step - loss: 41.4969 - categorical_accuracy: 0.1668 - val_loss: 41.6058 - val_categorical_accuracy: 0.0866\n",
      "Epoch 180/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4967 - categorical_accuracy: 0.1668\n",
      "Epoch 00180: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 30s 308ms/step - loss: 41.4967 - categorical_accuracy: 0.1668 - val_loss: 41.6043 - val_categorical_accuracy: 0.0859\n",
      "Epoch 181/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4966 - categorical_accuracy: 0.1642\n",
      "Epoch 00181: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 26s 266ms/step - loss: 41.4966 - categorical_accuracy: 0.1642 - val_loss: 41.6077 - val_categorical_accuracy: 0.0827\n",
      "Epoch 182/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4964 - categorical_accuracy: 0.1700\n",
      "Epoch 00182: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 26s 271ms/step - loss: 41.4964 - categorical_accuracy: 0.1700 - val_loss: 41.6055 - val_categorical_accuracy: 0.0827\n",
      "Epoch 183/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4966 - categorical_accuracy: 0.1670\n",
      "Epoch 00183: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 29s 302ms/step - loss: 41.4966 - categorical_accuracy: 0.1670 - val_loss: 41.6110 - val_categorical_accuracy: 0.0762\n",
      "Epoch 184/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4962 - categorical_accuracy: 0.1738\n",
      "Epoch 00184: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 26s 270ms/step - loss: 41.4962 - categorical_accuracy: 0.1738 - val_loss: 41.6072 - val_categorical_accuracy: 0.0781\n",
      "Epoch 185/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4965 - categorical_accuracy: 0.1778\n",
      "Epoch 00185: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 25s 261ms/step - loss: 41.4965 - categorical_accuracy: 0.1778 - val_loss: 41.6062 - val_categorical_accuracy: 0.0879\n",
      "Epoch 186/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4966 - categorical_accuracy: 0.1687\n",
      "Epoch 00186: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 30s 311ms/step - loss: 41.4966 - categorical_accuracy: 0.1687 - val_loss: 41.6061 - val_categorical_accuracy: 0.0833\n",
      "Epoch 187/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4967 - categorical_accuracy: 0.1741\n",
      "Epoch 00187: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 25s 261ms/step - loss: 41.4967 - categorical_accuracy: 0.1741 - val_loss: 41.6232 - val_categorical_accuracy: 0.0592\n",
      "Epoch 188/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4966 - categorical_accuracy: 0.1728\n",
      "Epoch 00188: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 31s 318ms/step - loss: 41.4966 - categorical_accuracy: 0.1728 - val_loss: 41.6162 - val_categorical_accuracy: 0.0677\n",
      "Epoch 189/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4965 - categorical_accuracy: 0.1683\n",
      "Epoch 00189: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 25s 259ms/step - loss: 41.4965 - categorical_accuracy: 0.1683 - val_loss: 41.6057 - val_categorical_accuracy: 0.0879\n",
      "Epoch 190/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4960 - categorical_accuracy: 0.1718\n",
      "Epoch 00190: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 25s 260ms/step - loss: 41.4960 - categorical_accuracy: 0.1718 - val_loss: 41.6044 - val_categorical_accuracy: 0.0892\n",
      "Epoch 191/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4959 - categorical_accuracy: 0.1747\n",
      "Epoch 00191: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 30s 309ms/step - loss: 41.4959 - categorical_accuracy: 0.1747 - val_loss: 41.6064 - val_categorical_accuracy: 0.0736\n",
      "Epoch 192/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4958 - categorical_accuracy: 0.1710\n",
      "Epoch 00192: val_loss did not improve from 41.60376\n",
      "97/97 [==============================] - 25s 258ms/step - loss: 41.4958 - categorical_accuracy: 0.1710 - val_loss: 41.6064 - val_categorical_accuracy: 0.0827\n",
      "Epoch 193/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4959 - categorical_accuracy: 0.1687\n",
      "Epoch 00193: val_loss improved from 41.60376 to 41.60360, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 30s 306ms/step - loss: 41.4959 - categorical_accuracy: 0.1687 - val_loss: 41.6036 - val_categorical_accuracy: 0.0879\n",
      "Epoch 194/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4961 - categorical_accuracy: 0.1707\n",
      "Epoch 00194: val_loss did not improve from 41.60360\n",
      "97/97 [==============================] - 27s 278ms/step - loss: 41.4961 - categorical_accuracy: 0.1707 - val_loss: 41.6039 - val_categorical_accuracy: 0.0885\n",
      "Epoch 195/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4961 - categorical_accuracy: 0.1796\n",
      "Epoch 00195: val_loss did not improve from 41.60360\n",
      "97/97 [==============================] - 26s 273ms/step - loss: 41.4961 - categorical_accuracy: 0.1796 - val_loss: 41.6083 - val_categorical_accuracy: 0.0762\n",
      "Epoch 196/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4958 - categorical_accuracy: 0.1736\n",
      "Epoch 00196: val_loss did not improve from 41.60360\n",
      "97/97 [==============================] - 30s 306ms/step - loss: 41.4958 - categorical_accuracy: 0.1736 - val_loss: 41.6049 - val_categorical_accuracy: 0.0872\n",
      "Epoch 197/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4958 - categorical_accuracy: 0.1767\n",
      "Epoch 00197: val_loss improved from 41.60360 to 41.60358, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 26s 266ms/step - loss: 41.4958 - categorical_accuracy: 0.1767 - val_loss: 41.6036 - val_categorical_accuracy: 0.1022\n",
      "Epoch 198/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4959 - categorical_accuracy: 0.1804\n",
      "Epoch 00198: val_loss did not improve from 41.60358\n",
      "\n",
      "Epoch 00198: ReduceLROnPlateau reducing learning rate to 6.998399767326191e-05.\n",
      "97/97 [==============================] - 25s 256ms/step - loss: 41.4959 - categorical_accuracy: 0.1804 - val_loss: 41.6038 - val_categorical_accuracy: 0.0885\n",
      "Epoch 199/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4956 - categorical_accuracy: 0.1781\n",
      "Epoch 00199: val_loss did not improve from 41.60358\n",
      "97/97 [==============================] - 31s 319ms/step - loss: 41.4956 - categorical_accuracy: 0.1781 - val_loss: 41.6053 - val_categorical_accuracy: 0.0957\n",
      "Epoch 200/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4954 - categorical_accuracy: 0.1783\n",
      "Epoch 00200: val_loss did not improve from 41.60358\n",
      "97/97 [==============================] - 25s 260ms/step - loss: 41.4954 - categorical_accuracy: 0.1783 - val_loss: 41.6042 - val_categorical_accuracy: 0.0833\n",
      "Epoch 201/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4954 - categorical_accuracy: 0.1822\n",
      "Epoch 00201: val_loss did not improve from 41.60358\n",
      "97/97 [==============================] - 30s 311ms/step - loss: 41.4954 - categorical_accuracy: 0.1822 - val_loss: 41.6057 - val_categorical_accuracy: 0.0872\n",
      "Epoch 202/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4954 - categorical_accuracy: 0.1854\n",
      "Epoch 00202: val_loss did not improve from 41.60358\n",
      "97/97 [==============================] - 26s 263ms/step - loss: 41.4954 - categorical_accuracy: 0.1854 - val_loss: 41.6054 - val_categorical_accuracy: 0.0846\n",
      "Epoch 203/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4953 - categorical_accuracy: 0.1831\n",
      "Epoch 00203: val_loss did not improve from 41.60358\n",
      "97/97 [==============================] - 25s 256ms/step - loss: 41.4953 - categorical_accuracy: 0.1831 - val_loss: 41.6068 - val_categorical_accuracy: 0.0827\n",
      "Epoch 204/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4955 - categorical_accuracy: 0.1792\n",
      "Epoch 00204: val_loss did not improve from 41.60358\n",
      "97/97 [==============================] - 30s 314ms/step - loss: 41.4955 - categorical_accuracy: 0.1792 - val_loss: 41.6058 - val_categorical_accuracy: 0.0807\n",
      "Epoch 205/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4949 - categorical_accuracy: 0.1867\n",
      "Epoch 00205: val_loss improved from 41.60358 to 41.60304, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 25s 260ms/step - loss: 41.4949 - categorical_accuracy: 0.1867 - val_loss: 41.6030 - val_categorical_accuracy: 0.0951\n",
      "Epoch 206/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4954 - categorical_accuracy: 0.1810\n",
      "Epoch 00206: val_loss improved from 41.60304 to 41.60265, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 26s 264ms/step - loss: 41.4954 - categorical_accuracy: 0.1810 - val_loss: 41.6027 - val_categorical_accuracy: 0.0944\n",
      "Epoch 207/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4947 - categorical_accuracy: 0.1809\n",
      "Epoch 00207: val_loss did not improve from 41.60265\n",
      "97/97 [==============================] - 30s 311ms/step - loss: 41.4947 - categorical_accuracy: 0.1809 - val_loss: 41.6082 - val_categorical_accuracy: 0.0872\n",
      "Epoch 208/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5899 - categorical_accuracy: 0.1844\n",
      "Epoch 00208: val_loss did not improve from 41.60265\n",
      "97/97 [==============================] - 26s 266ms/step - loss: 41.5899 - categorical_accuracy: 0.1844 - val_loss: 41.6037 - val_categorical_accuracy: 0.0983\n",
      "Epoch 209/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4956 - categorical_accuracy: 0.1828\n",
      "Epoch 00209: val_loss did not improve from 41.60265\n",
      "97/97 [==============================] - 29s 302ms/step - loss: 41.4956 - categorical_accuracy: 0.1828 - val_loss: 41.6048 - val_categorical_accuracy: 0.0762\n",
      "Epoch 210/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4949 - categorical_accuracy: 0.1809\n",
      "Epoch 00210: val_loss did not improve from 41.60265\n",
      "97/97 [==============================] - 26s 264ms/step - loss: 41.4949 - categorical_accuracy: 0.1809 - val_loss: 41.6042 - val_categorical_accuracy: 0.0866\n",
      "Epoch 211/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4949 - categorical_accuracy: 0.1846\n",
      "Epoch 00211: val_loss did not improve from 41.60265\n",
      "97/97 [==============================] - 25s 263ms/step - loss: 41.4949 - categorical_accuracy: 0.1846 - val_loss: 41.6071 - val_categorical_accuracy: 0.0807\n",
      "Epoch 212/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4946 - categorical_accuracy: 0.1875\n",
      "Epoch 00212: val_loss did not improve from 41.60265\n",
      "97/97 [==============================] - 33s 336ms/step - loss: 41.4946 - categorical_accuracy: 0.1875 - val_loss: 41.6041 - val_categorical_accuracy: 0.0905\n",
      "Epoch 213/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4947 - categorical_accuracy: 0.1925\n",
      "Epoch 00213: val_loss did not improve from 41.60265\n",
      "\n",
      "Epoch 00213: ReduceLROnPlateau reducing learning rate to 4.199039685772732e-05.\n",
      "97/97 [==============================] - 26s 269ms/step - loss: 41.4947 - categorical_accuracy: 0.1925 - val_loss: 41.6056 - val_categorical_accuracy: 0.0846\n",
      "Epoch 214/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4945 - categorical_accuracy: 0.1891\n",
      "Epoch 00214: val_loss did not improve from 41.60265\n",
      "97/97 [==============================] - 30s 304ms/step - loss: 41.4945 - categorical_accuracy: 0.1891 - val_loss: 41.6034 - val_categorical_accuracy: 0.0970\n",
      "Epoch 215/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4945 - categorical_accuracy: 0.1854\n",
      "Epoch 00215: val_loss did not improve from 41.60265\n",
      "97/97 [==============================] - 28s 289ms/step - loss: 41.4945 - categorical_accuracy: 0.1854 - val_loss: 41.6043 - val_categorical_accuracy: 0.0996\n",
      "Epoch 216/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4945 - categorical_accuracy: 0.1885\n",
      "Epoch 00216: val_loss did not improve from 41.60265\n",
      "97/97 [==============================] - 26s 265ms/step - loss: 41.4945 - categorical_accuracy: 0.1885 - val_loss: 41.6036 - val_categorical_accuracy: 0.1009\n",
      "Epoch 217/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4946 - categorical_accuracy: 0.1852\n",
      "Epoch 00217: val_loss did not improve from 41.60265\n",
      "97/97 [==============================] - 30s 312ms/step - loss: 41.4946 - categorical_accuracy: 0.1852 - val_loss: 41.6049 - val_categorical_accuracy: 0.0892\n",
      "Epoch 218/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4944 - categorical_accuracy: 0.1907\n",
      "Epoch 00218: val_loss did not improve from 41.60265\n",
      "97/97 [==============================] - 25s 254ms/step - loss: 41.4944 - categorical_accuracy: 0.1907 - val_loss: 41.6048 - val_categorical_accuracy: 0.0866\n",
      "Epoch 219/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4947 - categorical_accuracy: 0.1868\n",
      "Epoch 00219: val_loss did not improve from 41.60265\n",
      "97/97 [==============================] - 26s 270ms/step - loss: 41.4947 - categorical_accuracy: 0.1868 - val_loss: 41.6042 - val_categorical_accuracy: 0.0879\n",
      "Epoch 220/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4946 - categorical_accuracy: 0.1872\n",
      "Epoch 00220: val_loss improved from 41.60265 to 41.60233, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "\n",
      "Epoch 00220: ReduceLROnPlateau reducing learning rate to 2.519423724152148e-05.\n",
      "97/97 [==============================] - 31s 319ms/step - loss: 41.4946 - categorical_accuracy: 0.1872 - val_loss: 41.6023 - val_categorical_accuracy: 0.1009\n",
      "Epoch 221/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4943 - categorical_accuracy: 0.1910\n",
      "Epoch 00221: val_loss did not improve from 41.60233\n",
      "97/97 [==============================] - 27s 273ms/step - loss: 41.4943 - categorical_accuracy: 0.1910 - val_loss: 41.6026 - val_categorical_accuracy: 0.0957\n",
      "Epoch 222/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.5894 - categorical_accuracy: 0.1825\n",
      "Epoch 00222: val_loss did not improve from 41.60233\n",
      "97/97 [==============================] - 29s 296ms/step - loss: 41.5894 - categorical_accuracy: 0.1825 - val_loss: 41.6072 - val_categorical_accuracy: 0.0879\n",
      "Epoch 223/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4941 - categorical_accuracy: 0.1820\n",
      "Epoch 00223: val_loss did not improve from 41.60233\n",
      "97/97 [==============================] - 27s 281ms/step - loss: 41.4941 - categorical_accuracy: 0.1820 - val_loss: 41.6027 - val_categorical_accuracy: 0.0990\n",
      "Epoch 224/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4940 - categorical_accuracy: 0.1891\n",
      "Epoch 00224: val_loss did not improve from 41.60233\n",
      "97/97 [==============================] - 25s 256ms/step - loss: 41.4940 - categorical_accuracy: 0.1891 - val_loss: 41.6029 - val_categorical_accuracy: 0.0970\n",
      "Epoch 225/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4941 - categorical_accuracy: 0.1865\n",
      "Epoch 00225: val_loss did not improve from 41.60233\n",
      "97/97 [==============================] - 31s 320ms/step - loss: 41.4941 - categorical_accuracy: 0.1865 - val_loss: 41.6023 - val_categorical_accuracy: 0.0977\n",
      "Epoch 226/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4941 - categorical_accuracy: 0.1838\n",
      "Epoch 00226: val_loss did not improve from 41.60233\n",
      "97/97 [==============================] - 25s 253ms/step - loss: 41.4941 - categorical_accuracy: 0.1838 - val_loss: 41.6029 - val_categorical_accuracy: 0.0931\n",
      "Epoch 227/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4940 - categorical_accuracy: 0.1930\n",
      "Epoch 00227: val_loss did not improve from 41.60233\n",
      "97/97 [==============================] - 26s 263ms/step - loss: 41.4940 - categorical_accuracy: 0.1930 - val_loss: 41.6025 - val_categorical_accuracy: 0.0996\n",
      "Epoch 228/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4942 - categorical_accuracy: 0.1909\n",
      "Epoch 00228: val_loss did not improve from 41.60233\n",
      "97/97 [==============================] - 30s 310ms/step - loss: 41.4942 - categorical_accuracy: 0.1909 - val_loss: 41.6025 - val_categorical_accuracy: 0.0996\n",
      "Epoch 229/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4939 - categorical_accuracy: 0.1898\n",
      "Epoch 00229: val_loss did not improve from 41.60233\n",
      "97/97 [==============================] - 25s 262ms/step - loss: 41.4939 - categorical_accuracy: 0.1898 - val_loss: 41.6031 - val_categorical_accuracy: 0.0944\n",
      "Epoch 230/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4943 - categorical_accuracy: 0.1889\n",
      "Epoch 00230: val_loss improved from 41.60233 to 41.60230, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 27s 280ms/step - loss: 41.4943 - categorical_accuracy: 0.1889 - val_loss: 41.6023 - val_categorical_accuracy: 0.1003\n",
      "Epoch 231/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4942 - categorical_accuracy: 0.1872\n",
      "Epoch 00231: val_loss did not improve from 41.60230\n",
      "97/97 [==============================] - 28s 286ms/step - loss: 41.4942 - categorical_accuracy: 0.1872 - val_loss: 41.6027 - val_categorical_accuracy: 0.0951\n",
      "Epoch 232/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4941 - categorical_accuracy: 0.1864\n",
      "Epoch 00232: val_loss improved from 41.60230 to 41.60196, saving model to total.best_weightsNoisy2BN.hdf5\n",
      "97/97 [==============================] - 26s 265ms/step - loss: 41.4941 - categorical_accuracy: 0.1864 - val_loss: 41.6020 - val_categorical_accuracy: 0.0964\n",
      "Epoch 233/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4940 - categorical_accuracy: 0.1940\n",
      "Epoch 00233: val_loss did not improve from 41.60196\n",
      "97/97 [==============================] - 30s 314ms/step - loss: 41.4940 - categorical_accuracy: 0.1940 - val_loss: 41.6033 - val_categorical_accuracy: 0.0970\n",
      "Epoch 234/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4940 - categorical_accuracy: 0.1948\n",
      "Epoch 00234: val_loss did not improve from 41.60196\n",
      "97/97 [==============================] - 25s 262ms/step - loss: 41.4940 - categorical_accuracy: 0.1948 - val_loss: 41.6035 - val_categorical_accuracy: 0.0996\n",
      "Epoch 235/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4941 - categorical_accuracy: 0.1907\n",
      "Epoch 00235: val_loss did not improve from 41.60196\n",
      "\n",
      "Epoch 00235: ReduceLROnPlateau reducing learning rate to 1.511654190835543e-05.\n",
      "97/97 [==============================] - 25s 254ms/step - loss: 41.4941 - categorical_accuracy: 0.1907 - val_loss: 41.6025 - val_categorical_accuracy: 0.1003\n",
      "Epoch 236/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4938 - categorical_accuracy: 0.1940\n",
      "Epoch 00236: val_loss did not improve from 41.60196\n",
      "97/97 [==============================] - 31s 323ms/step - loss: 41.4938 - categorical_accuracy: 0.1940 - val_loss: 41.6022 - val_categorical_accuracy: 0.0996\n",
      "Epoch 237/300\n",
      "97/97 [==============================] - ETA: 0s - loss: 41.4940 - categorical_accuracy: 0.1936\n",
      "Epoch 00237: val_loss did not improve from 41.60196\n",
      "97/97 [==============================] - 25s 259ms/step - loss: 41.4940 - categorical_accuracy: 0.1936 - val_loss: 41.6025 - val_categorical_accuracy: 0.0970\n",
      "Epoch 00237: early stopping\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=300,\n",
    "                    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:05:55.122769Z",
     "iopub.status.busy": "2020-10-03T14:05:55.121734Z",
     "iopub.status.idle": "2020-10-03T14:05:55.334118Z",
     "shell.execute_reply": "2020-10-03T14:05:55.334702Z"
    },
    "papermill": {
     "duration": 9.426191,
     "end_time": "2020-10-03T14:05:55.334846",
     "exception": false,
     "start_time": "2020-10-03T14:05:45.908655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "loss_train = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "#epochs = np.range(1,1)\n",
    "plt.plot(loss_train, 'g', label='Training loss')\n",
    "plt.plot(loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:06:13.838684Z",
     "iopub.status.busy": "2020-10-03T14:06:13.831583Z",
     "iopub.status.idle": "2020-10-03T14:06:14.021147Z",
     "shell.execute_reply": "2020-10-03T14:06:14.021718Z"
    },
    "papermill": {
     "duration": 9.247442,
     "end_time": "2020-10-03T14:06:14.021860",
     "exception": false,
     "start_time": "2020-10-03T14:06:04.774418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydeVhVVdfAf4tJRBCRQUVRMOcBFHGeU1PLcsrSrNQys0yz4a1em2z6ehs1mzVLLcssc0zNnMscUJwnVEAFARGZUcb9/XEulwuCXo0rqPv3PPe55+zprH24nHXW2nuvLUopNBqNRqOxFrvyFkCj0Wg0NxZacWg0Go3mqtCKQ6PRaDRXhVYcGo1Go7kqtOLQaDQazVWhFYdGo9ForgqtODT/GhFZJSKjyrpseSIiUSLS2wbtbhSRsabjkSKyxpqy13CduiKSLiL21yqrRlMaWnHcopgeKgWffBG5YHE+8mraUkr1V0rNLeuyFRER+a+IbC4h3UtEskWkhbVtKaXmK6XuKCO5iig6pdQppZSrUiqvLNrXaCzRiuMWxfRQcVVKuQKngLst0uYXlBMRh/KTskLyPdBJRAKKpQ8H9iulDpSDTLcM+vdYMdCKQ1MEEekhItEi8qKIxAHfiYiHiKwQkQQRSTId17GoY+l+GS0if4vIh6aykSLS/xrLBojIZhFJE5G1IvK5iPxQitzWyPiWiGwxtbdGRLws8h8SkZMikigiL5d2f5RS0cB64KFiWQ8Dc68kRzGZR4vI3xbnfUTkiIikiMhngFjk3SYi603ynROR+SJSzZT3PVAXWG6yGF8QEX8RUQUPWhHxFZFlInJeRI6LyGMWbU8VkYUiMs90bw6KSEhp90BEPhGR0yKSKiK7RKSrRZ69iEwRkROmtnaJiJ8pr7mI/GmSIV5EppjS54jI2xZt9BCRaIvzKNPvcR+QISIOIvKSxTUOicjgYjI+JiKHLfKDReQ/IrKoWLlPRWR6aX3VlIxWHJqSqAlUB+oB4zB+J9+ZzusCF4DPLlO/PXAU8ALeB2aLiFxD2R+BHYAnMJVLH9aWWCPjA8AYwAdwAp4HEJFmwJem9n1N1yvxYW9irqUsItIYaAX8ZKUcl2BSYouAVzDuxQmgs2UR4F2TfE0BP4x7glLqIYpaje+XcImfgGhT/XuB/xORXhb59wALgGrAsivIHGrqb3WMv9EvIuJsynsWGAHcCVQFHgEyRcQNWAusNsnQAFh3uXtSjBHAXUA1pVQuxv3pCrgDbwA/iEgtABEZhnFvHjbJcA+QCPwA9LNQuA7A/RhWpOZqUErpzy3+AaKA3qbjHkA24HyZ8q2AJIvzjcBY0/Fo4LhFnguggJpXUxbjoZsLuFjk/wD8YGWfSpLxFYvzJ4HVpuPXgAUWeVVM96B3KW27AKlAJ9P5O8DSa7xXf5uOHwa2WZQTjAf92FLaHQTsLulvaDr3N91LBwwlkwe4WeS/C8wxHU8F1lrkNQMuXMXvJwkIMh0fBQaWUGaEpbzF8uYAb1uc9wCii/XtkSvIsKfgusAfwNOllFsFPGY6HgAcuh7/YzfbR1scmpJIUEpdLDgRERcR+drkykkFNgPVpPQZO3EFB0qpTNOh61WW9QXOW6QBnC5NYCtljLM4zrSQydeybaVUBsYbaomYZPoFeNhkHY3EsEKu5V4VUFwGZXkuIj4iskBEYkzt/oBhmVhDwb1Ms0g7CdS2OC9+b5yllPEEEXnO5AZKEZFkjLf+Aln8MKyB4pSWbi1F/vYi8rCI7BGRZJMMLayQAYy/04Om4wfR1sY1oRWHpiSKh0x+DmgMtFdKVQW6mdJLcz+VBbFAdRFxsUjzu0z5fyNjrGXbpmt6XqHOXOA+oA/gBqz4l3IUl0Eo2t93Mf4ugaZ2HyzW5uXCXJ/BuJduFml1gZgryHQJpvGMFzH67qGUqgakWMhyGrithKqlpQNkYFhxBdQsoYy5fyJSD5gFPAV4mmQ4YIUMAEuAQDFmvw0A5pdSTnMZtOLQWIMbhq8+WUSqA6/b+oJKqZPATmCqiDiJSEfgbhvJ+CswQES6iIgT8CZX/t/4C0gGZmK4ubL/pRy/A81FZIjpTX8SRR+gbkC6qd3awH+K1Y8H6pfUsFLqNPAP8K6IOItIIPAo1/bQdMNwISYADiLyGsY4QgHfAG+JSEMxCBQRTwzFWlNEJotIJRFxE5H2pjp7gDtFpLqI1AQmX0GGKhiKJAFARMZgWByWMjwvIm1MMjQwKRtMlvSvmMbPlFKnruEe3PJoxaGxhulAZeAcsA1jgPN6MBLoiOE2ehv4Gcgqpew1y6iUOghMwHiYxGL47KOvUEcB8zAGwef9WzmUUueAYcD/MPrbENhiUeQNIBjj7f534LdiTbwLvGJy3TxfwiVGYIx7nAEWA68rpf60RrZi/IExThCO4e66SFE30sfAQmANxjjQbKCyyU3WB0P5xwHHgJ6mOt8DezHGMtZg/J1LRSl1CPgI2IqhMFtica+UUr9gjDv9CKRhWBnVLZqYa6qj3VTXiJgGiTSaCo+I/AwcUUrZ3OLR3LyISF3gCMaEjdTyludGRFscmgqLiLQVY/2CnYj0AwZivD1qNNeEiNhhTBleoJXGtaNXYWoqMjUxXDKeGK6jJ5RSu8tXJM2NiohUwXBtnQT6lbM4NzTaVaXRaDSaq0K7qjQajUZzVdwSriovLy/l7+9f3mJoNBrNDcWuXbvOKaW8i6fbVHGYBjQ/AeyBb5RS/yuWPxJjMREYc9SfUErtvVxd09z4nzGmFkYB9ymlki4nh7+/Pzt37iyjXmk0Gs2tgYicLCndZq4qU4iFz4H+GLFvRpiCyVkSCXRXSgUCb2EsprpS3ZeAdUqphhhB0l6yVR80Go1Gcym2HONohxHALsK0qnYBxnRKM0qpfyyshW0URiS9XN2BmOICmb4H2bAPGo1GoymGLRVHbYquKI2maFC14jyKsSL1SnVrKKViAUzfPiU1JiLjRGSniOxMSEi4BvE1Go1GUxK2HOMoKahbiXN/RaQnhuLocrV1S0MpNROT6yskJOSSujk5OURHR3Px4sVL6mpuTZydnalTpw6Ojo7lLYpGU6GxpeKIpmh0zzoYcXKKYAq49g3QXymVaEXdeBGppZSKNW3ccvaahIuOxs3NDX9/f0rfY0hzq6CUIjExkejoaAICiu8Kq9FoLLGlqyoUaCjG9p9OGHsyL7MsYIoZ8xvwkFIq3Mq6y4BRpuNRwNJrEe7ixYt4enpqpaEBQETw9PTUFqhGYwU2sziUUrki8hRGNE174Ful1EERGW/K/wpj5zVP4AvTAzxXKRVSWl1T0/8DForIoxjbZQ67Vhm10tBYon8PGo112HQdh1JqJbCyWNpXFsdjgbHW1jWlJwK9Lq2h0Wg0ty4Xci4wf/98hjYdikdlD5teS4ccKScSExNp1aoVrVq1ombNmtSuXdt8np2dfdm6O3fuZNKkSVe8RqdOncpKXI1GU4GJTYul7ay2PLb8MT7a+hEHzh7gv2v/y6pjq8jMybxyA1fJLRFypCLi6enJnj17AJg6dSqurq48/3zh/ju5ubk4OJT85wkJCSEkJOSK1/jnn3/KRtjrSF5eHvb2V9qeW6O5tVBKMStsFkOaDsHL5dKt5hccWMDBhIMEVAtg1fFVHEw4yJIjS/jflv+x5P4lDGwysIRWrx1tcVQgRo8ezbPPPkvPnj158cUX2bFjB506daJ169Z06tSJo0ePArBx40YGDBgAGErnkUceoUePHtSvX58ZM2aY23N1dTWX79GjB/feey9NmjRh5MiRFERFXrlyJU2aNKFLly5MmjTJ3K4lUVFRdO3aleDgYIKDg4sopPfff5+WLVsSFBTESy8Zi/iPHz9O7969CQoKIjg4mBMnThSRGeCpp55izpw5gBES5s0336RLly788ssvzJo1i7Zt2xIUFMTQoUPJzDTemOLj4xk8eDBBQUEEBQXxzz//8Oqrr/LJJ5+Y23355ZeL3AONpjyJTYsl4JMAtp7e+q/aCU8M5/EVjzN5dcm76h5NPEr1ytUZGzyWsNgwfg//nSdDnuSPB/+gV/2y9+xriwOYvHoye+L2lGmbrWq2Ynq/6VddLzw8nLVr12Jvb09qaiqbN2/GwcGBtWvXMmXKFBYtWnRJnSNHjrBhwwbS0tJo3LgxTzzxxCVrEXbv3s3Bgwfx9fWlc+fObNmyhZCQEB5//HE2b95MQEAAI0aMKFEmHx8f/vzzT5ydnTl27BgjRoxg586drFq1iiVLlrB9+3ZcXFw4f/48ACNHjuSll15i8ODBXLx4kfz8fE6fPl1i2wU4Ozvz999/A4Yb77HHHgPglVdeYfbs2UycOJFJkybRvXt3Fi9eTF5eHunp6fj6+jJkyBCefvpp8vPzWbBgATt27Ljq+67R2IK1EWuJSo5iZthMOvp1vGzZI+eO4F7JnVputS7Ji0iKAGD+/vk80+EZ2vi2KZJ/NPEojT0b079Bf15e/zI5+Tk8GvwowbWCy64zFmjFUcEYNmyY2VWTkpLCqFGjOHbsGCJCTk5OiXXuuusuKlWqRKVKlfDx8SE+Pp46deoUKdOuXTtzWqtWrYiKisLV1ZX69eub1y2MGDGCmTNnXtJ+Tk4OTz31FHv27MHe3p7wcGPm9Nq1axkzZgwuLi4AVK9enbS0NGJiYhg8eDBgKARruP/++83HBw4c4JVXXiE5OZn09HT69u0LwPr165k3z9je297eHnd3d9zd3fH09GT37t3Ex8fTunVrPD09rbqmRmNrtpw2tkJffHgxX931FZUcKpnzJq2aREpWCnMHzSVf5dNzbk96+vfkx6E/XtJOVHIUAK5Orjy0+CHWj1pPTdea5vyj547St0FfWtVsRS3XWrg7u9O6Zmub9UsrDrgmy8BWVKlSxXz86quv0rNnTxYvXkxUVBQ9evQosU6lSoU/Rnt7e3Jzc60qY+0mXtOmTaNGjRrs3buX/Px8szJQSl0yhbW0Nh0cHMjPzzefF18vYdnv0aNHs2TJEoKCgpgzZw4bN268rHxjx45lzpw5xMXF8cgjj1jVJ43merDl9BY8nD1IupjEmhNruLvx3YDxf/LLoV84l3mOT/t/yqGEQ8Slx3Hk3BFz3YSMBDwqe+Bg50BUchRO9k4sG76Mu3+6my7fdmHBvQsI8Q0hNSuV2PRYGns2RkRYcO8CqjhWsen0cj3GUYFJSUmhdm0jRFfBeEBZ0qRJEyIiIoiKigLg559/LlWOWrVqYWdnx/fff09eXh4Ad9xxB99++615DOL8+fNUrVqVOnXqsGSJsTV4VlYWmZmZ1KtXj0OHDpGVlUVKSgrr1q0rVa60tDRq1apFTk4O8+fPN6f36tWLL7/8EjAG0VNTjS2jBw8ezOrVqwkNDTVbJxpNeZN0IYmDZw/yVLunqF65OgsPLeRi7kXm7Z3HqZRTxKXHkZufy5oTa1gRvgKAE0knUEqRm59Lk8+bMGXdFACiUqKo516PngE9+fOhP8nKy6Lj7I5sitpEeKLhAWjs2RiAbvW6XeLKKmu04qjAvPDCC/z3v/+lc+fO5od1WVK5cmW++OIL+vXrR5cuXahRowbu7u6XlHvyySeZO3cuHTp0IDw83Gwd9OvXj3vuuYeQkBBatWrFhx9+CMD333/PjBkzCAwMpFOnTsTFxeHn58d9991HYGAgI0eOpHXr0s3ot956i/bt29OnTx+aNGliTv/kk0/YsGEDLVu2pE2bNhw8aKwJdXJyomfPntx33316RpamwrA1eisKRQ//Htzd6G5+D/+dT7d/yqglo/jvuv8CIAgrwleYFUdqVirnL5wnIimC8xfO8/Wur0nLSiMqOQr/av4AdPTryL7x+6jnXo9Hlz3K7tjdADT2anzd+nZL7DkeEhKiim/kdPjwYZo2bVpOElUc0tPTcXV1RSnFhAkTaNiwIc8880x5i3VV5OfnExwczC+//ELDhg3/VVv6d6Gxhti0WHbE7LjsNNcJv09g9u7ZJL6QyJoTaxiycAiuTq6kZ6cD4GjnyD2N72F5+HKy87LpWrcrf536i+1jt3Mm7QyDfzbGCWf0m8Hbf73NwMYDmXl34RjkhsgN3D7vdtwruZOWnUbmlMwiYyhlgYjsUkpdMvdfWxy3OLNmzaJVq1Y0b96clJQUHn/88fIW6ao4dOgQDRo0oFevXv9aaWg0l8PyJfuT7Z8w6OdBnMs8V2LZzJxMYxV3s6FUcarCHbfdgbODM+nZ6dR2M9zPQTWDeKbDM3So04GXu77Mx30/BuDE+RMcSjgEQGCNQD7e9jFnM86aLY4Cegb05Mu7viQrL4tGno3KXGlcDj04fovzzDPP3HAWhiXNmjUjIiKivMXQ3OSsOraKEYtGsOOxHTTybMThc4cB2HVmF30bXDqu9svBX0jJSmFc8DgAs/L44/gfzBk0hz7f96Gdbzs61+3MptGbAMwrvCOSIjiSeAS/qn78t8t/GbHImCZfXHEAjA8ZT9/b+pKTX/KMS1uhLQ6NRqO5Al/t+oqUrBTe2PQGgHn2U+iZUADe2vQWHWd35ELOBQC+2/MdjTwb0a1eN3Mb0/tOZ/WDq+kV0Iv3er/HhHYTilzDxdGFWq61OJFkWBxNvZsytOlQfN18gZIVB0CARwCNPBuVaX+vhFYcGo1GcxkSMxNZeWwlHs4e/LT/J/bE7eHE+RMA7Dyzk3yVz1e7vmJb9DZeXPsiCRkJ/HXqL4Y3H15kSmyARwA9/HsgIrzQ+QWaeTe75Fr1Pepz/PxxDiccpplXMxztHZnUbhIOdg40qN7guvX5SmjFodFoNJfhl0O/kJufy8JhC3G0d+Tl9S+Tp/JwcXRh55mdbI82BrNb+LTg0x2f8sLaF8hX+dcUH+q26rexPWY7F3IvmBXLfzr/h8MTDuNTpcRdsssFrTg0Go3mMvxy6BeaeDWhV0Avevj3YOUxY7eHwU0GE5MWw4wdM3C0c+TPh/6knns95uyZg19Vv2tauT2h7QTz4HnBWgw7satQ1gZoxXFDURC08MyZM9x7770llunRowfFpx4XZ/r06eZFewB33nknycnJZSeoRnMDE5Maw+/hvwOQcjGFzSc3M7DxQESEAQ0LA3WOCjI2Il1wYAG96/empmtNpvWdBmAuf7W0q92OYxOPcWziMZvFmSoLtOK4AfH19eXXX3+95vrFFcfKlSupVq1aWYh2XVBKFQlfotH8GxIzE/ki9AvzdNtXN7zKgJ8GsCduD2tOrCE3P5e7GxmhQgY0MhSHr5svvev3ZuUDK/mwz4fmqbSDmgxi3qB5TOk65Zrlsbezr3AWRnG04ignXnzxRb744gvz+dSpU/noo49IT0+nV69eBAcH07JlS5YuvXRL9aioKFq0aAHAhQsXGD58OIGBgdx///1cuHDBXO6JJ54gJCSE5s2b8/rrrwMwY8YMzpw5Q8+ePenZsydghDU/d86Yj/7xxx/TokULWrRowfTp083Xa9q0KY899hjNmzfnjjvuKHKdApYvX0779u1p3bo1vXv3Jj4+HjAWGY4ZM4aWLVsSGBhojvC7evVqgoODCQoKolevXub7ULACHaBFixZERUWZZXjyyScJDg7m9OnTJfYPIDQ0lE6dOhEUFES7du1IS0uja9eu5v1PADp37sy+ffus/ntpbl5+2PcDE1ZOYG/8XvLy81gevhyA1za8xrLwZVSvXJ0OdToAxgB3UI0ggmoEISL0b9if5zo9RxMvI8KBiPBQ0EMlRri9qVBK3fSfNm3aqOIcOnTIfPz000p17162n6efvuSSRQgLC1PdunUznzdt2lSdPHlS5eTkqJSUFKWUUgkJCeq2225T+fn5SimlqlSpopRSKjIyUjVv3lwppdRHH32kxowZo5RSau/evcre3l6FhoYqpZRKTExUSimVm5urunfvrvbu3auUUqpevXoqISHBfO2C8507d6oWLVqo9PR0lZaWppo1a6bCwsJUZGSksre3V7t371ZKKTVs2DD1/fffX9Kn8+fPm2WdNWuWevbZZ5VSSr3wwgvqaYsbcv78eXX27FlVp04dFRERUUTW119/XX3wwQfmss2bN1eRkZEqMjJSiYjaunWrOa+k/mVlZamAgAC1Y8cOpZRSKSkpKicnR82ZM8csw9GjR1VJvwmliv4uNDce6Vnp6r2/31PZudlW15m0cpJiKurbsG/V5qjNiqmodrPaKaaimIp66LeHipSPTolWcWlxZS16hQTYqUp4ptrU4hCRfiJyVESOi8hLJeQ3EZGtIpIlIs9bpDcWkT0Wn1QRmWzKmyoiMRZ5d9qyD7aidevWnD17ljNnzrB37148PDyoW7cuSimmTJlCYGAgvXv3JiYmxvzmXhKbN2/mwQcfBCAwMJDAwEBz3sKFCwkODqZ169YcPHiQQ4cOXVamv//+m8GDB1OlShVcXV0ZMmQIf/31FwABAQG0atUKgDZt2pgDI1oSHR1N3759admyJR988IE5ltTatWuZMKFwzrqHhwfbtm2jW7du5pDu1atXv+I9q1evHh06dLhs/44ePUqtWrVo27YtAFWrVsXBwYFhw4axYsUKcnJy+Pbbbxk9evQVr6e58Zi3dx4vrn2RTSc3WV0nMjkSgLDYMJYcWWKOQvtat9eY1nca7/V+r0j52lVrU8O1RpnKfaNhs5XjImIPfA70AaKBUBFZppSyfHqdByYBgyzrKqWOAq0s2okBFlsUmaaU+pAyYno5RVW/9957+fXXX4mLi2P48OEAzJ8/n4SEBHbt2oWjoyP+/v6XhCAvTkmDcJGRkXz44YeEhobi4eHB6NGjr9iOukzcsuJh2UtyVU2cOJFnn32We+65h40bNzJ16lRzuyWFXy9J7suFX7cMvV5a/0pr18XFhT59+rB06VIWLlx4xQkEmhuTVcdXAYX7V1hDgeLYFbuLmLQYegX0ooZrDd7o+YYtRLwpsKXF0Q44rpSKUEplAwuAIhOblVJnlVKhwOXWy/cCTiilTtpO1PJh+PDhLFiwgF9//dU8SyolJQUfHx8cHR3ZsGEDJ09evtvdunUzhx4/cOCA2W+fmppKlSpVcHd3Jz4+nlWrVpnruLm5kZaWVmJbS5YsITMzk4yMDBYvXkzXrl2t7o9lGPi5c+ea0++44w4+++wz83lSUhIdO3Zk06ZNREYa/7QFuwf6+/sTFhYGQFhYmDm/OKX1r0mTJpw5c4bQUGNFb1pamnl/krFjxzJp0iTatm1rlYWjubHIys1ifeR6ACKTSv7d5OXnkZZV+NtXSpnLbo3eyqmUUzwU+JDthb3BsaXiqA1Y7hcabUq7WoYDPxVLe0pE9onItyLiUVIlERknIjtFZGdCQsI1XNb2NG/enLS0NGrXrk2tWsZg2siRI9m5cychISHMnz+/SFjxknjiiSdIT08nMDCQ999/n3bt2gEQFBRE69atad68OY888gidO3c21xk3bhz9+/c3D44XEBwczOjRo2nXrh3t27dn7Nixlw1/XpypU6cybNgwunbtipeXlzn9lVdeISkpiRYtWhAUFMSGDRvw9vZm5syZDBkyhKCgIPMOgEOHDuX8+fO0atWKL7/8kkaNSg6lUFr/nJyc+Pnnn5k4cSJBQUH06dPHbLW0adOGqlWrMmbMGKv7pLlx+OvUX2TkZACGFXE44TA7YopuI/zy+pdp9FkjsvOyAUjITCAjJ8O85sK9kjuDmgxCcwVKGvgoiw8wDPjG4vwh4NNSyk4Fni8h3Qk4B9SwSKsB2GMovXeAb68ky5UGxzW3BjExMaphw4YqLy+v1DL6d3Hj8sKaF5TTW06qwzcdVIdvOqhu33VTTm85qY2RG5VSSmVmZyqP/3kopqLWHF+jlFJq2+ltiqmotza9pZiKenz54+XZhQoH5TA4Hg34WZzXAc5cZRv9gTCllHl0WCkVr5TKU0rlA7MwXGIazWWZN28e7du355133sHOTs9CvxnZE7+Hlj4tae7dnOPnjxMaE0p2XjaDfh5EalYqiw4vIuliEoKw5IixQ2XB+MbAxgN5u+fbvNz15fLswg2DLf+DQoGGIhIgIk4YLqdlV9nGCIq5qUTEcoL0YODAv5JSc0vw8MMPc/r0aYYNG1beomiukYzsDD7d/im5+bkl5h84e4DmPs0JqBbAucxzXMi9wLjgcSRfTGbzyc18E/YNDao34J7G97D06FKUUkQkGSH5AzwCeLnby/i5+5XYtqYoNlMcSqlc4CngD+AwsFApdVBExovIeAARqSki0cCzwCsiEi0iVU15Lhgzsn4r1vT7IrJfRPYBPYFr3kxC3QK7H2qsR/8eKjbz9s5j0upJ/Hniz0vyki4kGYEGvVsUCT/+TMdnqGRfiR/3/8jmk5t5KPAhhjQdQkxaDFtObyEiKQKfKj64Orlex57c+Nh0Iyel1EpgZbG0ryyO4zBcWCXVzQQ8S0gvkykPzs7OJCYm4unpeU0xZTQ3F0opEhMTcXZ2Lm9RNKWwIWoDAJtObqJ/w/6AoTB6f9+bkS1HAtDcpznVnI3wOT5VfGjs2ZjOdTvz0wHDcTG06VDqVavHc2ue48W1L3Lg7AFuD7i9HHpzY3PL7gBYp04doqOjqagzrjTXH2dnZ+rUKfE9RlOOPLXyKQJrBBZRHAX8fepvwmLDzBsrtfBpgaOdIwDta7dHROjp35P1ketp7NmYZt7NjP0wOr3AC2tfwNHO8ZIFfporc8sqDkdHR/OqZY1GUzG5kHOBr3Z+hYiQm59LPfd67Dyzk4zsDKo4VWFX7C7A2HbVzckNv6p+KBQtfFqYp9XeHnA7r254lXub3Wv2LkxoN4Ef9v/AAy0euO67590M3LKKQ6PRVHz2n91PnsoD0/DTy11fZtyKcczYPoMRLUewK3YXbk5upGWn0dynOSKCIOx/Yr+5jQ51OvDxHR/zYOCD5jQXRxf2PL5Hu6mvET0vUaPRlDvnMs/x1qa3yMzJLJIeFmtEEXig5QN0qduFES1HUMWxClPWT6H3vN7sOrOLgU0G0rt+b/o36F9i23ZixzMdn8G7ineRdK00rh1tcWg0mnJn7p65vLbxNY4mHuX7wd+bH+q7Y3fj4ezBD4N/MKeFTwznt8O/MXHVRADa1GrD5A6Tyxu/Jg0AACAASURBVE32WxFtcWg0mnJn08lN2Is98/fPZ+7ewjhnYXFhtK7Vuoh14Ovmy/iQ8eZpt21qtbne4t7yaMWh0WjKlbz8PP469RejgkbR1rctb29+m7l75tL+m/bsi99HcM1Lt1B1sHPg5a4v4+XiRetaV7+3t+bfoRWHRqMpV/af3U/yxWR6+PdgStcpnEg6weilo9kXv4/svGza1S45qtDY4LHEPx+vF++VA3qMQ6PR2BSlFAmZCfhU8TGnJV9MZtauWYxoOYINkcb6jO7+3alTtQ5BNYJIzUpl29hthCeG08mvU6lt24l+9y0PtOLQaDQ25Yd9P/DIskc4+tRR6nvU52TySfrN78eRc0d4+6+3yczJpIVPC+q61wVg0+hN2NvZ4+rkWkTZaCoOWl1rNJoyYfyK8Xh/4E33Od2LxP36atdX5ObnsiJ8BQBPrXqKmNQYfhj8Ax3rdOTR1o+y9qG15vLuzu7a/VTB0RaHRqMpE5YdXUbKxRQ2n9xMdGo0fu5+hCeG88/pfwBYeWwl7Wu3Z0X4Ct65/R1GBo5kZODIcpZacy1oi0Oj0VjF4YTDfLDlA06nnL4kLzsvm7j0OLr7dwdgb/xeAGbtmoW92HN/8/vZGLWRSasn4eXixcR2E6+r7JqyRSsOjUZjFdO2TeOFtS9w24zb2Hxyc5G8mNQYFIq7Gt4FwN64veyI2cH07dMZ0XIEj7R+hKy8LHae2ckXd36BWyW38uiCpozQriqNRmMVkcmRNPVqSlZeFo8ue5S94/dS2aEyp1JOcSrlFGBEpw2oFkBYXBjz9s3D182XGf1m4OLowvAWwxnWbBhDmg4p555o/i1acWg0GquITIokxDeEx9s8zu3zbufDfz7Es7Ink/+YzNs93wbAr6ofQTWDWHpkKXkqj4X3LsSjsgcAPw396XLNa24gtKtKo9Fckbz8PE6lnCKgWgA9A3rSr0E/Zu6ayde7viY3P5dFhxcB4OfuR1CNIPJUHnWq1mFw08HlLLnGFmjFodForsiZtDPk5OeY40ONCx5HTFoM+88a4ctDz4TiWdkTF0cXgmoEATC+zXgc7LRT42ZEKw6NRnNFIpMjAQjwMDY/G9BoADVda+Jk70RANSOtYAFf3wZ9ebXbqzzV7qnyEVZjc2yqOESkn4gcFZHjIvJSCflNRGSriGSJyPPF8qJEZL+I7BGRnRbp1UXkTxE5Zvr2sGUfNBoNRCVHAZiVhKO9I5/2/5RpfaeZp+D6ufsBxiZJb/Z8E3dn93KRVWN7bKY4RMQe+BzoDzQDRohIs2LFzgOTgA9LaaanUqqVUirEIu0lYJ1SqiGwznSu0WhsSGRSJIKYrQqAe5vdy5NtnzSHNa9btW5p1TU3Gba0ONoBx5VSEUqpbGABMNCygFLqrFIqFMi5inYHAgUB++cCg8pCWI1GUzqRyZH4uvlSyaHSJXlmxeGuFcetgi0VR23AcolptCnNWhSwRkR2icg4i/QaSqlYANN3iVHQRGSciOwUkZ0JCQlXKbpGoylgy6kthJ4JNY9vFKeNbxseafUIdze++zpLpikvbKk4StrQV5WQVhqdlVLBGK6uCSLS7WourpSaqZQKUUqFeHt7X7mCRqO5hO92f0eX77pwKOEQneqUHN7cyd6J2QNn08SryXWWTlNe2HKuXDTgZ3FeBzhjbWWl1BnT91kRWYzh+toMxItILaVUrIjUAs6WocwajcbE/vj9PPH7E/QK6MX8IfN1iHONGVtaHKFAQxEJEBEnYDiwzJqKIlJFRNwKjoE7gAOm7GXAKNPxKGBpmUqt0dxkLDmyhFfWv3LV9RYfWUx2XjY/Df2JGq41iuz7rbm1sZnFoZTKFZGngD8Ae+BbpdRBERlvyv9KRGoCO4GqQL6ITMaYgeUFLDb9UB2AH5VSq01N/w9YKCKPAqeAYbbqg0ZzMzBz10xWH1/NxHYTqeFa45L8c5nnmLVrFqlZqbzZ800c7R0BCE8Mp657XbyraFevpig2XdaplFoJrCyW9pXFcRyGC6s4qUBQKW0mAr3KUEyN5qbi+Pnj/B7+O5PaT0JEOJhwEIVi5bGVjGk9pkjZCzkXaDurrXmdRvj5cL6860t8qvgQnhhOI89G5dADTUVHrxzXaG4yPtjyAZP/mMyZtDOkZqWaI9euOLbikrLTt00nKjmKVSNXMb3vdH47/Bt+0/xYfnS5VhyaUtGKQ6O5yVgbaWzDuiduD4cSDgHGGovVx1fTe15v1kas5fj544xYNIJ3/nqHuxvdTb8G/Xi6w9McnnCYGlVq8M5f75CSlUJjz8bl2RVNBUUrDo3mJiIiKYKIpAjAUBwHzhpzSt7o8QbZedlsjd7Kc2ue4/EVj7P86HJ61e/FjP4zzPWbeDXhzoZ3sj1mO4C2ODQlohWHRnOTcDH3ImsjDGujimMV9sTv4eDZg7g4uvBw0MNkvZLFl3d9yb74fayPXM9bPd9i6fCl5oi3BfSu39t8rBWHpiR0zGON5gZDKcX6yPV08utEZcfKgDEzqsGMBqRlp+Hr5kvHOh3ZE7eH5IvJNPNuhp0Y74gjWozgtQ2vkZ2XzfiQ8SW239O/J4LgaO+ow4hoSkQrDo3mBmNF+AruWXAPTb2asvj+xTT2aszcPXNJyUphSNMh3FH/Ds5lnmPR4UXEpsUyvMVwc11He0dWP7iavPw8s9IpjqeLJ8G1grmYexF7O/vr1S3NDYRWHBrNDcb3+76neuXqnEk7w+sbX+enoT8xM2wmnf06s+g+Yye+38N/B8Dd2Z3Xur9WpL41oUFm3zObi7kXy154zU2BVhwazQ1EysUUlh1dxrg24ziXeY6NURvZfHIz4YnhvNz1ZXO5bvW68UDLB3ip80vX5G4KqlniMiqNBtCD4xrNDcWiw4vIysviwcAH6V6vO7Hpsby28TVcnVy5t9m95nJuldyYP2Q+LWu0LEdpNTcrWnFoNOXMtuhtZOVmlZh3KuUUz695ntSsVAB+O/wbAdUCaOvb1rzz3uaTmxnadCguji7XTWbNrY1WHBpNOTJt6zQ6zu7InD1zzGl5+Xnm44/++YiPtn7EqCWjSM1KZW3EWgY1GYSI0NizMTWqGLGnRrYceb1F19zCaMWh0ZQTm6I28eyaZwEIPRMKwNbTW3F7140tp7aQl5/HwkML8XbxZsmRJdz1411k5WUxsLGxkaaIcMdtd+BX1Y/bA24vt35obj304LhGU05sPrkZgM5+nQmLDQPgzc1vciH3Au9teY9nOz5LXHocC4Yu4M+IP5m9ezaelT3pXLezuY3P7/ycjJwMPW1Wc13RikOjsRFJF5Lo+0NfpvebTie/TuSrfDZFbaKHfw9EhKjkKGq51qJL3S58vPVjtkVvY/Xx1dRzr8fy8OWcSTuDi6MLAxoNYGizodiLPQ09G+JgV/hv61bJDbdKbuXYS82tiHZVaTQ2Ys2JNYSeCWXqxqnm89vn3c7So8beY1EpUfhX86d1zdbk5Ofw6LJHqVqpKn8+9CfODs6EJ4Yzo98MqjhVwcHOga/v/prnOz1fjj3SaAy0xaHR2IiCuFF/RvzJ/vj97IvfB8AP+35gUJNBRCZF0qFOB4JrBQNwKOEQU7pMoaFnQ8LGheHl4qU3UdJUSLTFodHYiHWR6+herzsuji58Hvq5OcT58vDlJGYmcjr1NP7V/Lmt+m24OblR2aEykztMBqCpd1OtNDQVFm1xaDRlwJZTWxi3YhxrH1pLLbdaRCRFEJkcyXMdn6NqpapsiNqAeyV3arrWJC49jhnbZ5Cbn4t/NX/sxI4JbSfgU8VHKwvNDYFWHBrNvyQzJ5PRS0dz/PxxdsXuYoDbAGbumglAr/q9SM9OZ3n4cirZV+Kx4MdYdXwVn4d+DmAOaf5u73fLS3yN5qqxqatKRPqJyFEROS4iL5WQ30REtopIlog8b5HuJyIbROSwiBwUkact8qaKSIyI7DF97rRlHzSa4uTm5xKTGmM+n7Z1GsfPHwcgKjmKeXvn8d6W9xjdajRNvJqYp89m5WXR3Kc5AxsPJPFCIgAB1QKufwc0mn+JzRSHiNgDnwP9gWbACBFpVqzYeWAS8GGx9FzgOaVUU6ADMKFY3WlKqVamz0rb9ECjKZmvd35N488ak5GdAcDGkxtpXbM1zg7ORCVH8Xno57Sq2YqZAwyrI8Q3BCd7JwCaejVlUJNB5rb0fheaGxFbWhztgONKqQilVDawABhoWUApdVYpFQrkFEuPVUqFmY7TgMNAbRvKqtFYzY4zO8jIySAqOQqlFHvj9tK6Zmv8q/kTmRzJ4YTDdPHrgqO9IwDODs6E+IYA0My7GZ38OuHl4oWvmy+VHCqVZ1c0mmvClmMctYHTFufRQPurbURE/IHWwHaL5KdE5GFgJ4ZlklRCvXHAOIC6dfVbnabsOJxwGICTKSepXrk6CZkJBNUM4kz6Gf45/Q9p2Wk08y5qXA9sPJDki8nmwe/nOz5PQmbCdZddoykLrmhxiMgAEbkWy0RKSFNX1YCIK7AImKyUSjUlfwncBrQCYoGPSqqrlJqplApRSoV4e+uZKpqyQSnF4XMmxZF8kr3xewEIqhGEv7s/celxgDGd1pL/dPoPB588aD5/scuLfHhHcQ+tRnNjYI1CGA4cE5H3RaTpFUsXEg34WZzXAc5YW1lEHDGUxnyl1G8F6UqpeKVUnlIqH5iF4RLTaK4L0anRpGenA4bFsTfOUByBNQLNM6SASywOkZLeozSaG5MrKg6l1IMYrqITwHemWVDjRORKAXJCgYYiEiAiThgKaJk1QonxXzYbOKyU+rhYXi2L08HAAWva1GjKgoJFfGBSHPF78avqh0dlD7Pi8KzsibeLtnI1Ny9WjXEopVJFZBFQGZiM8cD+j4jMUEp9WkqdXBF5CvgDsAe+VUodFJHxpvyvRKQmxjhFVSBfRCZjzMAKBB4C9ovIHlOTU0wzqN4XkVYYbq8o4PFr6bhGcy0UKI6WPi05mXyS5IvJ5m1WCxRHU++m2sLQ3NRcUXGIyN3AIxjjCt8D7ZRSZ0XEBWO2U4mKA8D0oF9ZLO0ri+M4DBdWcf6m5DESlFIPXUlmjaasyVf5/Lj/R5YeXYqXixchviEsPLiQjJwMRrcaDRQqjmZexWedazQ3F9ZYHMMw1k1stkxUSmWKyCO2EUujuf5MXj2ZxAuJzLp7Fs4Ozub0zJxMRv42kiVHlgDQ97a+1HOvR0aOsY7j7kZ3A+BTxYcHWj7Afc3vu/7CazTXEWsUx+sYs5cAEJHKQA2lVJRSap3NJNNoriOpWal8ufNLsvOyOZtxll+H/YpbJTdy83O5/9f7+T38d6b1ncaARgPwqeLDb4eN+Rq3edxGE68mgDEAPn/I/PLshkZzXbBmVtUvQL7FeZ4pTaO5aVh9fDXZedmMbzOedRHr6PRtJ2aHzebO+XeyInwFX9z1BZM7TKZB9QZUrVSVeu71ABjQaIAez9DcclijOBxMK78BMB072U4kjeb6cODsAfOeGUuOLMHLxYvP7vyMVSNXkZiZyNjlY9kRs4Mv7/qS8SHji9RtVbMV7Wq3Y0yrMeUhukZTrljjqkoQkXuUUssARGQgcM62Ymk0tufl9S+z+eRm4p6LY+WxlQxpOgR7O3v63NaH6GejOXj2IHWq1sGjsscldT0qe7B97PYSWtVobn6sURzjgfki8hnGTKfTwMM2lUqjuQ4cSjhE8sVk5uyZQ0pWCnc1vMucZyd2tKzRshyl02gqLldUHEqpE0AHU/gPMQUd1GhuWHLycshTeUQkRQDwf3//H4Jwe8Dt5SyZRnNjYNUCQBG5C2gOOBcMBCql3rShXBqNTdgUtYm+P/Tl8zs/J18Zcz5OpZyirW/bEl1SGo3mUqwJcvgVcD8wEcNVNQyoZ2O5NJoyJycvhydXPklWXhbv/m3suFewkVLv+r3LUzSN5obCmllVnZRSDwNJSqk3gI4UDV6o0dwQfLfnOw4lHMLLxYsTSScQxDwrSisOjcZ6rFEcF03fmSLii7Hpkt7vUnPDsS16GzVda/Jsh2cBqFetHhPaTeCDPh/QvV73cpZOo7lxsEZxLBeRasAHQBhGYMGfbCmURmMLjp0/RsPqDenboC9gbONavXJ1nu/0PPZ29uUsnUZz43DZwXHTBk7rlFLJwCIRWQE4K6VSrot0Gk0Zcvz8ce5scCetaraiQfUGdPbrXN4iaTQ3JJe1OEybJX1kcZ6llYamopKdl82qY6vIy88zp2VkZ/DAogf4+9TfxKXH0aB6A+zEjsMTDjOl65RylFajuXGxZjruGhEZCvymlLqqrV81mutFvspn1JJRLDiwgBn9ZpCenc7hc4fxr+bPTwd+4nTqaQAaejYEwMHOqpnoGo2mBKz573kWqALkishFjCm5SilV1aaSaTRWsvX0Vl5a9xKbT27Gy8WL1za+RsrFFJTFFvd/n/obgIbVG5aXmBrNTYM1W8e6KaXslFJOSqmqpnOtNDQVhgcXP8jRc0eZ0W8Gi+5bRPLFZOq61+X17q/j5eLFuOBx5rK3Vb+tHCXVaG4OrNkBsFtJ6cU3dtJobMXSI0v548QffHHXF+Y0pRT5Kp/07HQikiL4v9v/j4ntJwLw5V1f0rFOR4JqBvFqt1fZf3Y/M8NmUsu1Fq5OruXVDY3mpsEaV9V/LI6dgXbALkAH9tFcF77e9TWrjq9iUvtJeLt44+7szvKjyxmzdAxzB80FILBGoLm8ZQh0ezt7AmsE4uXiZR7f0GhK49w5cHQEd/fylqRiY42r6m6LTx+gBRBvTeMi0k9EjorIcRF5qYT8JiKyVUSyROR5a+qKSHUR+VNEjpm+dYChmxilFNuitwHw6fZPCfgkgPe3vM/aiLWkZKUwbds0oKjiKI6d2DH7ntm82UOHV9NcniFD4Mkny1uKio81CwCLE42hPC6LiNgDnwP9gWbACBFpVqzYeWAS8OFV1H0JY21JQ2Cd6VxzkxKeGE7SxSQE4YudX5CWncaGqA3sid8DwKaTm3Cv5E6dqnUu2849je+hu79eHa65PBERcOKE7drfuRMGDIDk5MK0Cxfg3nshPPzq2irPOa7WBDn8VERmmD6fAX8Be61oux1wXCkVYdo1cAEw0LKAUuqsUioUI4yJtXUHAnNNx3OBQVbIorlBKbA2RrcaDYCzgzM7YnawN67wJxhYI1Bv36r51ygFiYlw9qxt2j9xAu68E37/HcLCCtMPHYJFi+DHHy9ff+1ao8zp03DwILi4wP79Rcv8+CP4+UGjRrByZdn3oQBrxjh2WhznAj8ppbZYUa82xqZPBUQD7a2U63J1ayilYgGUUrEi4lNSAyIyDhgHULduXSsvq6lobIveRtVKVXm/z/u4V3LHv5o/k/+YDEBwrWDCYsMu66bSaKwlMxMuXoSEBNu0P2kSpJiWT8fGFqbHmxz/W7ca36mp8N578MILhWMtERHQp49xfNdd0LevIesff0BL035joaEwciS0bQsZGXDPPXD8OPj7l31frHFV/Qr8oJSaq5SaD2wTERcr6pX0CmitcfVv6hqFlZqplApRSoV4e3tfTVVNOZCv8rnvl/tYH7m+SPq2mG20r90eLxcvpvWbZo4zBfBi5xcRhLa+ba+3uJqbkHOmDbHT0w0lcjXMng3jx5eef/iwYQFMNCb+FVEcBRbO9u2Qn29YFv/3f/Daa4ZyyMiA3buNMq1bw5YthssLCpUNwLRpULWqUX/1aiPt00+vrh/WYo3iWAdUtjivDKy1ol40RcOv1wHOWCnX5erGi0gtANO3jQxLzfUkMTORXw79wurjq81pGdkZ7IvfR4c6HcxpjTwbUc25Gg52DgxsPJADTx7gwcAHy0NkzU1GgeKAq7c6li2D334rPX/6dKhUCV580XAxlWRxpKTAkSMQE2Ocf/aZ4Xbq1w/27QM7Oxg71hgfWbrUKLN1q+FiO3YMFi408qtWNerddx98841hwZQ11igOZ6VUesGJ6dgaiyMUaCgiASLiBAwHllkp1+XqLgNGmY5HAUutbFNTgYlLjwMgPqNwwl7omVDyVX4RxWEndnSr143gWsFUcqhEM+9mOrKtpkxITCw8vlrFERMDaZfZVHvZMmPGlrc31KoFZyxeoeMt5qhu3WrkOTiAry+IGBbGpk3QsCH07GmUS0mBGjUMBfTqqxAUBM7OhjusgGefNWRat+7q+mIN1iiODBEJLjgRkTbAhStVUkrlAk8BfwCHgYVKqYMiMl5Expvaqiki0RhhTV4RkWgRqVpaXVPT/wP6iMgxoI/pXHODE5tuvIKdzSg0IAsGxtvXLjo09t3A71g+Yvn1E05zS2BpcYSGGmMDpc10ysoqOvsqJsZwK+UUn+YD5OUZ7qjbTEELatW61FXl7w8eHrBtm9GWry+cPGlYMUoZiiMwEBo3hmrVjHrjTAER3nkHunWDAwegnsXerCEhEBkJgwdf7Z24MtYMjk8GfhGRAh1ZC2Mr2SuilFoJrCyW9pXFcRyGG8qquqb0RKCXNdfX3DjEphn/SfHp8WRkZ7Anbg/borfRyLMRni6eRcpWr1y9PETU3ORYKo5Fi4wHd1iYMUOpOF98YbzRDxkC331XaDWkpUH1Yj/PhARj7KJmTePc1xf27CnMj4838urWNcZCKlWC2rUN11S7doZrKzPTGAS3s4MOHYwxjNGjDXdWy5awZIlhcRSnno02+b6i4lBKhYpIE6AxxqD1EaVUCXpVcyMSmxZLZcfKVHOuVq5yWLqqZoXN4pk/nsHBzoGRLUeWq1yaWwdLxVEw6BwXV3LZiAjj+7ffjId7wZqK1NRLFUdBGwWKo1YtWLWqMD8+HgICwMfHGLuoXh1amFbKOTlB587w55+Fs6eGDzcsnoAA2LvXqFep0rX1+VqxZh3HBKCKUuqAUmo/4Coiem3lTUK/+f0Ys3TMdbnWvL3z+H7v9yXmWbqqjp47CkBufi6d/DpdF9k0mnPnjId25cqFs6pKUxwJCcbbvL29MYupgJLGOUpSHGlpxuwtMFxVNWoYlk1CguFeql27sH4vk38lKMj4HjUK1q83xj/8/K6/0gDrxjgeM+0ACIBSKgl4zHYiaa4X2XnZHDx7kFXHVpGenX7lCv+Sj7Z+xIdbC4MExKTGkJlj/IcWKI7c/Fx2x+2mVc1WrBq5ijGtro9S02gSE8HLyxjALqA0xXHunPFwb9AA/vqrMN1axQHGOEdenqEsChQHQHZ2UcUxcaKxXiMg4Nr6ZQusURx2YrEs1xQOxMl2ImmuFyfOnyBP5ZGVl8Xq46uJSY2x6fWiU6M5cf4ESimSLyYT+FUgvef1Ji8/z+yqAtgdt5v6HvXp16AfjvaONpVJoyng3DlDcfhYLCm+nMXh7Q3NmhluowIsp77m5UFSUuH4R40axrevr/EdG2soq/z8oooDiioOFxe4445r75ctsEZx/AEsFJFeInI78BOw6gp1NDcAR84dAUAQnvj9CepMq0NYbNgVal0bmTmZnL9wnoycDOIz4vl468ecv3CerdFb+Tz0c2LTYvFy8QIMSyigWgV6vdLcEhQojgKLw87u8orDywuaNi2abmlxfPutMVvq2DFwdTU+UNTiKFj85+MD9esb14RC5VJRsUZxvIixCPAJYAKwj6ILAjU3KAWK495m93Iu0xgZtJXVcTqlMILMrjO7mL5tOkObDqVfg368tuE1YtJiaFWzlbmMVhyaskQpeP11+PXX0ssUtzhaty5ZcShllPX2LlQcDqZpRpYWx969xvkffxS6qaBQccTEFLVGKlUqDA9iaXFURKwJq54PbAMigBCMqbCHbSyXpgzJys1idths8vLzAPj10K/U/LAmm09tprZbbb4e8DXfDzYGrVOyUmwiQ3RqtPl4Vtgs0rLTeLr90zzd/mlSslLIzMkkqEaQuYx/NX+byKGpeLz7rhF76XJ88smVy4DxUD906NL0V1+FN9+EOXMK07ZvN2YsjRxZGODQ09N4yItA9+6GZZGXV7St1FRjvUaBqwqMxXlQ1OI4dcr4jo4uqjg8PIw1HYsWXerGKminoiuOUqfjikgjjBXbI4BE4GcApVTP6yOapqxYfGQxY5ePxcvFi4FNBvL1rq+Jz4hn9fHV3B5wOx6VPehT34iglpplg/gEwOnUQovj92O/4+zgTPs67REEz8qeJF5IpIVPC+zEjnyVT4CHtjhuBnbvNtwxl3vor19vzEyKjCx9AHj7dlizxngwu7mV3tbGjXD77cZq606mCXmxscYiOShcHZ6dbYwbpKYa183IMMYqvLzggQcMhXL6tDH+sHKloTwGmeJwF6wq9/IyFuSB8X34cFGLo0BxQFHFIQJPP22s8r5woXCVOECbNobiq1Kl9D5WBC5ncRzBsC7uVkp1UUp9CuRdprymgrLrzC4A1kWu42zGWdZHrsdOjD99E88mALg7G2E4Uy7a1uKo6VqT3Pxc2tduj5O9E472jgxpOgSA2m618XYxHMza4rg5ePfdwhXOliQlGVFeT582HtxghBsvjYL9K/btMyyEqVONh31xjhjeV/74ozCt4K3eyalQcezZYzzkGzc2FFvBSm5vb6hTB+6+u/BhP2qUsXaioJ0CxeHtbTzgBw+G/v2NabwpKYbi2bLFWEBYQIFFUcCYMUbk2927YcYMI74UGJbRrl2l34eKwuUUx1AgDtggIrNEpBclR63VVHB2xxmhNddGrGXRoUXkq3ze6PEGAE28DMXh7OCMk72TzVxVp1NO4+3iTXPv5gB0rdvVnDeuzTj8q/nTskZLfKr44FPFBxdHa8KhaSo6aWmGL7+4u2fbNuNN/vffC9/MV6wwvk+cKFxgV0BBOPIffjD2nHjjDWPVdnEKHtYbNxamFVgB9esXKo6CBX6DBxuy7dtnnFu6iAoUR1KSYY18+aVxXrBQsGAQ/bffDOXo5gZHj8JPPxllk5MLFYKlxQHGQPk338DMmfDEE4XpOIxixgAAIABJREFUzs5FpwNXVEpVHEqpxUqp+4EmwEbgGaCGiHwpIhVscpimNJRShMWGUcm+EofPHebdv9+luXdzpnSdwtcDvi4SWda9krvNLI7TqaepU7UOt3kYAXu61itUHCG+IUQ+HUlN15o0qN6Alj4tbSKD5vqTkWE8mOOLbTZdYGWsW2eMF3h6woYNxkO6d294rNhKsQKLY9484/uxxwzXleVbPRQqoW3bDDcQFCqd+vWN9vP+v70zD6+quvr/d4VMNwMZmEnCPA8BAUGkVaxYQX1Bi7NSK61Wi1XUH621g77Wt1qtY7UqKlVfqTiiOLwMouIIMhpAQGaSEMhIBkhChv37Y92Vs+/JuVO4N+P+PA/PzT33DPvchP09a9hr1bFwZGSwawiwnvJ14dCthEGDuMzIiROeriqdxEQrviIieOGF/GoXDoC7/tnvs60QSHD8uFJqsVLqInBdqS0w7VrbDIdKD6GkqqShg15eRR6eu+g5RFAEbhx/I1JcVsv2pNiksAbHM5IycHra6UiOTcbk9MmO+y2atQhvXPZGWMZgaH7EnZSd7bn9wAF+XbWKX2+/neMOM2bwZ3aLQ4TjxAkOIP/hD/ze3jXv0CHOTjp5Evj6a94mwtG/PwfBjx1j4Zg82ZrQpSOfngYrwtGzJ/fbKCgAHnrI01Wl07mzdV9yzTlzWAjPbmddi4PqOa6UKlZKPaeU+km4BmQILbIu4xdjf4ELBl+A5//reUzpM8Vx36SY8AlHdlk20hPTMfe0uci+PRuJMc4RzuTYZFPEsB0hwpGT47ldLA6ZYC+7DLj2Wg6CA+zeqq+39i/V/izPOYdF4Mwz2d3z+ONWNtOhQ9yeFfDsqAewxQFwu9VDhzyFY+NGjlEkayXbEhJYHGbN4uqzV1zBnfnWr+d97QHsxMTGfcAzM1kcJVuqvRCUcBjaHiv3rkQERSCzRyY+vPrDBsvDiaTY0LqqjlUdQ3ZpNkqrSnGs6hj6JPVBBEUgITohZNcwtG78WRxCnz78NN+zJxcNrKmxFsfV1PB5ZJKXnhQ33cSWye23c1yhpoYFZ9QonvSLi3k/3VUFcBYXwC1W5ZxSQsTeuv6rr4CHH+af//EPXqD39tuN3VSAFc8QIiOdXVTtASMc7RDlfux58MsH8ezGZ3H92OsDCjZ3jukcUovj9hW3Y8qiKdhwmPtc6gv8DO2b7dv56duXxaGX4IiNtfpU/PGPnsfIxH/ddZyxJBbFnDkcx0hM5OD24cNspfTpw8IhRQRLSzmjStxQ0nZ14EDeL879X8Np7cTgwVb6b3o68Kc/8c9OAWzZb/BgPm96OhdBbI8Y4WhnvP3928h4LANvbn8Tf/zkj7hi5BV47qLnAjo2KSYpJOs4jp/k2eKLg18guywb/5vFiwtPTzO9wdsS+fnsCgqWDRv4qX/tWmfhKC/n7KYZM/i9rJYW0t0desRKEeEYMQJYvNjzyT42lsuNi/sJaCwcZWV8TJcu1vhiYz1jGEBgZT7uuINTeMV60RHh6NMH+NGPrNLo7REjHO2AelWP33z4G6zLWYfPDnyG3PJcXP7W5eji6oJnL3o24NaqociqWpuzFil/T8Fb37+FvSXcIu0/W/+DQamDTOyijfHGG5z1Y8+IAjgzye7PF6Rr3sGDHKQGPF1V4qaaNo3dOfZFfyIcIjYSGE/20jJm9Gi2OCTDqm9fnsR1iyMpyRIOKYkubikRjkBWa8fEcBxm0aLGn4mgpacDr7/eOHDfnjDC0Q7YcmQLntnwDF757hXsLNqJbnHdEB8Vj0fPfzSoBk1JsWxx1Kt6/zt74d7P7kVNfQ3+38r/17Ctpr4GE9MmNvmchpZBrAWnUuFDhnB6qhPST1tvj6pbHCIcgwcDjz0G/MbW3adbN3YtBSocmZm8j2RRZWSwxSHjLi3lSb1zZ6uIoC5WwQgHwCLktHpdtmVk8LV8rXBv6xjhaAes3LsSAPDd0e+wq3AXpg+ajuLfF3us0QiEpJgkKKgm9+ZYl7MOK/auQOeYzjhYehAEwgWD2SE9sXfHFo5Nm6wFZK2NhQu5p7Wdqip+tQtHdTUHpffscT5frrtOpghI166eiwBFOPr1A265xSoNIhDxU7vdVZWU5Hw96Yz32mvsJoqLa+yqSkpi0ZDufLp7LBhXlS/0WEh7J6zCQUTTiWgXEe0hokZrP4h50v15FhGNc28fSkRbtH9lRDTf/dm9RJSrfXZBOO+hLbBiL9dX2HxkM7LLsjGs6zBEdwq+ZUpTyo7Uq3rcvvx2bDmyBX/9/K/o4uqCf13Aj6LDug7DrKGzAACT0icFPZ72xL//Dcyf792944uqKvaZf/ll6MdVUMBP/M8+63xdwJqABZnIZYGdHbtwDB3KoiGVZo8e5Unc1wrpjIzgXFWy37338s/24LiIjrirTsXi8IbuqmrvhE043A2fngYwA8AIAFcR0QjbbjMADHb/uxHAMwCglNqllBqrlBoLYDyAEwCWasc9Jp8rpT4K1z20FlbsWeF1Mq84WYGvDn2FHvE9GrrpSRmRYEmKcQtHEJlVPxT9gMfXPY7pr07Hh7s/xB2T78DPhv8MnWM648yMM3HdmOvw1mVvYVJaxxaOqir298tkHAx79nBaqKxLCCVvvsmTupM7SoRBJuDsbC5GKMIh7VXtiGDIqwSJZe1GRQWvgbCnvuroFoc/4UhO5pXdkyZx5hXAT/92VxVgCYducUgfjFPtsCfl0tvbmg0nwmlxTASwRym1Tyl1EsASALNs+8wC8Ipi1gJIJqJetn3OBbBXKWUrLtAxyD+ej+mLp+Phrx92/HzNgTWoqa/BrZNubdg2tMvQJl2rKRbH9vztAICjx48iJTYFt0y8Ba4oF7755Td4cNqDiImMwewRs0G+ZokOgHSJKykJ/ljJFmrKsf5YvJhfyxyS6eyuqgcf5AqxgVocEuPIzOTXvZwrgePHraZG3khPtxYBlpayyPiKGaxaxbWvJIbh5KoCnC2OK67g4PqpuqqmT+fsLr2TX3slnMKRBkBf9pPj3hbsPleCuw7q3OJ2bS0iohQ4QEQ3EtEGItpQIDUC2iA7Crj1yWcHPgMAlFSWYOZrM7G3eG/D9uhO0fj1+F8jgiIQQREYlDqoSddqisXxfcH3IBBeveRVLLl0CTrH8KPdiG4jGjr6GaxJ+FSEQ568Q0VurhVQdrI47K6q3bt50heXk5NwKNXY4hgxgid0XTj8lQ3v25cX9B0+bBULjPAxW/XrZ8UvAEs4lHIWDt3iiIwERo70PZ5AiIho3ym4OuEUDqdHTLuH1+c+RBQNYCaAN7XPnwEwEMBYAHkAHnG6uFJqoVJqglJqQre2UG7SC9Kl79vcb3Gi5gTe/+F9vP/D+/jPVs71W3NwDSamTUSXuC4YnDoYA1IGICYypknXkkk/mLUc2wu2o39Kf1yTeQ1+OtDUvvTGqQiHpJmGWjhkIu/ePTDhkGC4uJychKOoyErBlXOmpHDQWq5XUeHf4hg40BrjsWPe3VTeSExkF1xREb+Kq2rQILYsnFZ+GwInnMKRAyBDe58O4HCQ+8wAsEkp1ZBJrpQ6qpSqc3cmfB7sEmu3iHDU1Ndgbc7ahgyqTw98ivLqcmzK24Sz+3IFtTsn34n5k+Y3+VpNclUVbMeIbvbQVXioqWmWy4SFULiqQi0cevDayVUlwlBezt+9jEMKEDrFOMRNpRMfz0IQjMWhC0dpafDCIcIk4xGLY8ECdid1cM/pKRNO4VgPYDAR9XdbDlcCWGbbZxmAn7uzq84AUKqU0rK/cRVsbipbDOQSANtCP/TWw66iXRiQMgARFIHPDnyGVfu4nOjX2V/jk/2foE7VYWq/qQCAG8bfgHkT5zX5WoG6qjYc3oCC4wWora/FrsJdDT02wsl33/Fk4y0FtLUjT+/eJv/t2xuXCBfCFeOQGMTQof4tjoMHrXRaEY7KSt5HT+WViTpDexy0C4cEx33Rpw+X6xCLw1sqrjfswiEWR3S0p0vL0DTCJhxKqVoAtwBYAe5R/oZSajsR3UREN7l3+wjcy3wP2HpoWApERHEAzgPwju3UDxHRViLKAnAOuE9Iu2Vn4U5MTJuI03ufjifWPYH84/m4bMRlqK6rxr1r7kVkRKTXEuXBEhcVh07UyafFUVdfh3NePgd3rLwDe4r3oKa+plksjt27+alXOrw1N0pxNztZFR0svlxVSnFg9Y47nI8Nl8WRl8crofv04fHZLTpdOGTSBzxdVUuWAFOnNk7BHT7c2l+Eo7CQLZtAguNRURznOBVXFdDY4jCEhrCu41BKfaSUGqKUGqiU+h/3tmeVUs+6f1ZKqXnuz0crpTZox55QSnVRSpXazjnHvW+mUmqmzUJpV1TWVOLAsQMY1mUYXpz5IlJdqYigCNx3zn2IoAhsObIF8yfNR3x0aBoUExESohNwvMahJ6eb/cf2o+JkBZbtWoZvsjk/tDmEQ56IQ5HnkNeEv5jycuDuuzl9tSn4clVt2cJrFuwWx/HjXC9KJr+mCEdxsfcU4Lw8TiGVp3G71aFnVTkJx4kTVkc9+U5195cgwgHweQJxVQGWlVJU1HRXlYzHCEdoMSvHWzF7ivdAQWFY12EY2X0kNt64EWt/uRbDug7D/efcj4UXLcRD5z0U0mvGRcU1FCl0QtJvy6rLMH/FfAxIGYAxPcaEdAxOyKQmpbabyrZtHBz99tvgjhN/vrcUVH/4sjikW5xd0G69FRg2jF1EKSlNE44pU6xFcXYOH2bhkKdzu3Do6zj27uXsI3kvn8sx0k61uJiFSILPMTHsctKFIxBXFcDHiKiecYb//XW8uaoMocEIRytmYx73s5QFfamu1IYKs3/48R9ww/gbQr4+Ij46HidqvazsAqffAkBCdALKqsvwl7P+gqhOUSEdgxOhFA6gcT8If8gkGk7hOHrUszf3zp3W/mPG8Dl06+Huu61jnaiu5nPYe2EIdovDHiC3u6qGDGEhECorLRERS7C8nIVInvBFIPr25ddDhwJzVQEsHLW1LFiXXeZ/fx0RQ1l9biyO0GKEoxXz0paXMDBlIEb3aL4e3HFRcQ0r0J3YXrAdGZ0zcO3oazGmxxhck3lNs4wrVK6qpsYLwmVxFBVxR7nevVk05MkdsNwsADDW3cpExq0U8MgjwG23eYqNjkyax70YkCIc3iwOXTj27eOJXA8s6xaH/F7Kyvh8IkYiEElJnMlUVMTHBWpxABz/CTZ9Vq4rMak2nJHfKjHC0UrZVbgLaw6uwQ3jbkAEhe/X9MEHnm6b+Kh4n66q7wu+x8juI/GvC/+FDTduQGREZNjGphMqi6OlhENiHPbrbt3KIjBzJr8XsZCFdDffzMX7Jk70PL6sjNdL7NsHLLPnKrqRe3USjspKPlfv3v5dVeXlLEJ9+ngKh1JWjEMEr7ycRcNucUREsLtNxCwQiyMzk4+bO9f/vnbk/Hv3cg0qlyv4cxi8Y4SjFbBw48KGBX36tsiISJ+tXkPBggXAX/9qvfdmcZRWleKrQ19hR+EOjOg6AkTUbKIB+BeO+nprcvZFUxfTObmqvNVqcsKbxbGDCwPg3HP5VeIchYUsDMOHA1deyZOuPm7d8vrnP62x6UUUfQmHrP4OxFVVUMDj7t27cSqr/D78uaoAvgdxmwVqcRw+DFxyif997ejlScRyMYQOIxwtTE1dDRasWoA7V96Junr2OZRVl+GFzS9g9vDZ6JHQI6zXr6z0DMrGRcU5ZlUtWLUAP/r3j1BVW4WR3cO/bsOO3Zdu54knOJPHX/VZmUxLg+xXZbc4du7kSfTTT/0fq5R34fj+e57kxo/n9/K7kKCu1E+SrCIRDpmw09N5LJWVvK/eYEhE0kk4xLIJxFUlY0pLs0p2SEtU+X3YXVVOwpGaalkcgQgHYHXpC5bYWKtEiRGO0GOEo4X58tCXKKsuw5GKI/ji0BcAgEWbF6Gsugx3TPaS2B9Cqqs9fenx0fGNLI7jJ49jybYlGN9rPKZkTMG0AdPCPi47usXhJA579vBEKU/S3giVq+rll/m727rV/7H6+ggni2P4cEsg7HWepNS3CIccL8IxeDBP1kVFfE+vactldYvjyBHg2muByy8HNm+2xEAXDt3iqK3lfzppaZbFIRO6CIbdVSVWjDeLIxBX1alAZF3DCEfoMcLRwny4+0NEd4pGXFQcXt/2OpRSeHLdk/hRnx81S9e86mrPbJ64yMbpuO/seAflJ8vx6PmP4su5X6JPUp+wj8uOCMfJk87lMcQi8bVAr6zMEoxTcVXV11ttQZ1KbNiRJ/eUFBYgqeUEWMIRE8OTst3iEOHw5qoaOJCFobiY369ZY30/IhwVFcBnn3El3LffBv72NyurzJvFIWPWJ37dVSUlxCXGEajF4XTecGGEI3wY4WhhPvjhA0ztNxUzh87EWzvewtfZX2P/sf341Wm/apbrV1fzRCj/8e0WR219LZ5a/xQGpAzAj/v8uFnG5IQ+qTm5qwIRDplIgaa7qk6c4N4Ycq5ghEMmW7EaSkvZspBV1r168eK6557joDeR1WRIJmK7q0omRXEB1dYCK7mcmYerSu531izg/feB55/nFN9u3XiVdmyss3Do2Ui6xSHjEgoK2BL0FhwHLPGzbw8XIohGOEKPEY4WJK88D7uKdmH6wOmYO3YuCk8U4vr3rkdkRCRmDp3ZLGOQgLI86dqD479b9Tt8m/st7pt6X4v21CgvtyZepwB5MMLRq9epuaqkFPmoUZ5uPm/Idyzjl2tLYFwXjuXLgZtu4n7ePXrwpA7wxB4b62lxdO7MlW0Bz7Ua8+cD11zj6aoS4bj5Zh7PDz9wiRP5lXbu7GnJiXBIGmx8PO/jTThKSvg6tbU8YcfE8NjtFocQbleVfg0jHKHHCEcLsqOQZ47MHpmYNmAaRnUfhd3Fu/GT/j9BisuxzUhIqauzXFQyAcZFxaG6rhp19XXIOpqFx9Y+hnmnz2u29RreKC+3JgBfwrF7t/dzyESamXlqrqqyMg4ODx/OFsdDD3FrV2/IJCyTbUkJT/Syolt6QeiNhMrKGjcWSk72jHF062bFEkQ4br6ZV5u//jpft3dvtgTy81kkzj2Xv8eePTlbS9A75un3KxZH7958vATHe/XyPBaw3F+JibzvPfd4XqO5LY6EBP7OTFHD0GOEo5k4fvI45i+f71FAUEqmD+s6DESEO87gYPjs4bObZUx6+qpYHPFR/D/6RM0JLNy4EDGdYvDfU/+7WcbjDXGBDBjA75vqqsrJ4Ql/2LBTy6qSlNO0NBaO5ct5LYy3jC4RDgkoHzvGadBr1gD/+IcliMOGsYvnJncJUHsPbL3sSH4+WxviEhJX1d13c3vXhQv5/elcaAB5eVYzpLfeYndVtNaW3i4cdleVjGXQID7HCK08mfxepJ6ViNkf/+gpqM0tHP37W9lqhtBihKOZWHNwDZ5Y9wQ+2m21SN9ZuBMJ0QnonciPlnPGzMGrl7yK68Zc1yxjchKOuKg4AEDBiQK8mvUqZo+YjS5xXZplPN6oqmLLSCYocfHo6M2G6uo4TnD33Z77FBXx02dqKu9fW8slSH76U9+WCtBYOBISeDI9fpxFo6bGOWgPWN+zCIfENs44A7jzTmu/BQs4xiHb7MKRmmplLxUUsHDYLQ55P3cuJz3IwkIRDoBXoU+Y4Hluf64qGcvYsXxtfUKWNqxSbt1bi9fmdlU98wzw3nvhv05HxAhHM5FTxo+EWUezGrbtLNzZYG0AQGREJK7JvKbJHfyCRRcOcVVJpd03t7+J0upS3DDuhmYZiy/kSbhrV65Z9PjjwNKlnvtUVHAMoKaGg8LvveeZmgqwmyclxXpKLy3lIPGqVVzWwlc5E91VVVFhWRyAtU7C2/F2i6O01LlUeGQkj2/QIODJJ4Ebb/T8vGdPFgOgsavq0CHPFFSAhUWe7HXhcMKfxaG7zVJTgbg4670Ih1TN9SYczW1xxMY2z3U6IkY4moncMk6/ycpvLBwthS+L4/tCLmY4vlfL2/oyoSUmAi+9xG6S//kfz30qKqxYwf79PDFLiqpQXMyTnr6Y7v33+Xz79gGvvup9DGJx1NTwcYmJjWMQwQhHaanvwnu//S1w2mme23r25PUY9fVseegWR06Oc19uvby4P+HQLQ4RSrvFIeglPMTVJm5Cb9cRiyM21lpAaGibGOFoJuwWR8XJCmSXZWNYl9YpHIdKDyEqIgoJ0c3gU9BwmvB14YiLY3eJvpCuro4n9j7u5SUlJTwxl5V5LmITi0OEY+1aFpnf/pazgHwtHtTLixQUWK4qnfx84KyzGrtHRDhSU3nC9GZx+KNnT/5ujh7l+9KFo6rKWYjkibuszLdQJSWxm69nT47byJhHjgRmz2aLTEcXjv79+b0shvRncRgroO1jhKOZyCln4cgpy0FxZTF+KOLHs9ZgccTHNw6OHyo9hK5xXZs9Bffyy4GLL/bcpgsH0NgfL5O6tCstKXFe6Fdc7OmqWryYXy+8kF0yvgoo6jWq8vM9XVWSMrttG/DFF1ztVke+Z5eLx15czONvinDIdQAec0KCZ0qtHX2S9mVx3Horryw/epRLmIhwJCVxMF1vzASw1aCft18/y93pz+IwwtH2McIRZpbvWY51OeuQU5aDzjH8P2rr0a3YcmQLgNYhHOnpVtBVLI6cshx0jQuylrUDhw4BV11lBa+F+vrG+xYXA598AnzzjedE7U845NxOwqFbJiUlnq6qlSt5EVxGBj+9+xIOu8WRmMhCkJICTJrE2zdy+5SGSVeyrOR9bCxPxBLIDrZHhAiHXKdXLxYNmah9WRyAb+EYMQK46y7+uajIc8xORERYnyUksHAI3iwOl4szuZojMG4IL0Y4wki9qsecpXNwx8o7kFOWg/MGnAcA2Jq/FW9sfwN9k/pieLfhfs4SeqqrgawsSziSk63KqhIcP1l3MiTC8fHH3JdaFs0BXCupd+/GLp0VK9jtVFtrTY6As3CcPGmNX4SjRw8OMBcUWBO9uL3q61lMdFdVXR1w0UX8c/fuvoPjunDU1lqT31/+wtlbsbHWmCsrOV4SEdF4Ek5KslZ0N9Xi+Pxzfh0yxPo+gFMTDsBaoyE9M2TM3hB3VUKCFSCX904QsXAbi6PtE1bhIKLpRLSLiPYQ0V0OnxMRPen+PIuIxmmfHSCirUS0hYg2aNtTiWgVEe12v4Z/pVwTyTqahcIThVifux5l1WU4vffp6JfcD099+xRW7VuFq0df7bXXxvr1Te9v7Y///IfTKSVDRyaw6mrL4gAQkjRcmYzF/11fD8ybx9e+5RbPyq0ffGBNbt98Y223C4e9tpIIR2IiC4Pe3U8v76GUp8UBsJsKCM5VpY9h/nxgxgw+XhYYVlVZtaw+/tgSuJgYvrbsF6xwSHD9q6841iPBefnO/Lmq/Fk44krSxc5XHwvJrEpMtCyOhITGAXqdlBQjHO2BsAkHEXUC8DSAGQBGALiKiEbYdpsBYLD7340AnrF9fo5SaqxSSs86vwvAaqXUYACr3e9bJR/v+xgAUFPP5VEzkjLw5PQnsatoF+pVPa7NvNbrsY8+yhNrOJDgqgiHTChVVZ7C0dUVvMVRVMQB4j17+L1MxlnuZLJ33mFRuPFGzgR6+GHeXlvLC+kuvpjXa6xda53TyeKQ+zjvPJ5IAZ60UlKstFDAsjjkNSXFOk/XrlaDpEBcVfpEb3+q1ms6VVayCwzge7VbHLL4MFhXlZQXKStja8Me2zhViyM6mr+bQFxVgKfFIcLhzU0l/OxnwAUX+N7H0PoJp8UxEcAepdQ+pdRJAEsAzLLtMwvAK4pZCyCZiHrZT+RwzMvun18GcLGPfVuUj/d9jJ4JVlGftMQ0/NfQ/8LcsXNxbv9zMaKbXUctSkp4ItMrqYYKeUKXp3GZECsrreA4gCa5qjZs4ACxrLOwWxwbN7I76ZlnWCT++U+elNeu5cn9oouAyZN5wpUYgQiHTNYyAW7ezE/0775rfZ6c7Ckcco/yKplN3bvztSQttHt3vn9vbVZPnLBcOUDjCVJvbVpVZY19zZrGwiEEa3FIBV2Ay6kLck4n4YiN9R08t9Oli6erKsbHkiKXi8/tclmuKn/Ccf/9vNDR0LYJp3CkAdBKryHHvS3QfRSAlUS0kYj0pVA9lFJ5AOB+7e50cSK6kYg2ENGGglNtVN0Eqmur8fnBz3HZiMsaypCnd04HALw460V8/POPfR4vE53eZClUiHDIU7hucbiiLN9EU1xVUvpCXE3yFP/992xVHDnCvvqICF4hXVwMvPIKu6kiI3kV96RJfN9Seba8nCfASHfDQZkARSBk/YBYHHo6r5PFAQCrV3PPbkEsBm9WR2Wlb+GwWxwy8X73nfU7jIo6NeEArDiHxDcA3xYHkWV1BCMcVVUsGr7cTi4XnzsiwrI4ArmGoe0TTuFwyuO0V/Pxtc8UpdQ4sDtrHhGdFczFlVILlVITlFITurVAp/pvcr5BZW0lpg2YhjMzzgQApHW266Z3JCvIV/XVp58GLr00+LH5sjgiKAKuSBaPplgckjEkFoMU16uu5rIeIhwAMGUKl774+9+5T8RZZ/HkJ24esVKkNpQgk5PEMvTmQCm2iJfd4pDPR43yLIEhbiBvwmG3OHy5qqqqLOFQilemy5N/OIXD26QtwhGIa0wXDl9uKoBjHPJ76dKFvxN/FoehfRBO4cgBkKG9Twdgnwa97qOUktd8AEvBri8AOCruLPerD89087M2Zy0+2f8JVu9bjU7UCWf3PRu/nfhb/PmsPyM20s//RA0RDr3fw5EjngHz1asDa11qx5twiEtF4hxNEQ6xOI4c4SBwQQEv2AM4zqELBxGXDzl8mGMikuE0ejS/ehMOezVWwS4cnTo1tji8VUoV4XAyTpViIdCP9WVxiHCI++qHH6xJWJ+8m/J0HqzFATTd4vAnHC6XJaBELMbp6f6vYWj7hFM41gOFyuQmAAAYCElEQVQYTET9iSgawJUAltn2WQbg5+7sqjMAlCql8ogonogSAYCI4gH8FMA27RipAngdgFZTxuzdne/irH+fhZmvzcTSnUsxMW0ikmKTcGbGmbjvnPsCPo9SzsLx/PO8QE5SQ/PyPNNEA8Wbq0qekkU4uriCd1VlZ1sT1TffWKupibg4oS4cAFsdixdzifLZ7qLAKSk8AUlA3ZvFoccygMbCkZHh3eKw48tVJYIaaIxDXFU9erDYKGXFCuS7TkiwXG/B0FzCUVnpXzjOPJN/t8KyZRyzMrR/wiYcSqlaALcAWAFgB4A3lFLbiegmInIXjsZHAPYB2APgeQC/cW/vAeBLIvoOwLcAPlRKLXd/9iCA84hoN4Dz3O9blKraKlz99tW45PVLMLTrUByvOY7tBdsD7s195ZXcR0GorLSC4rpwyKQmweK8PJ7UnBbT2amv54Dqv//t21UFWGs57BaHUp5Ba50DB9jayMkBfvITdmOsWMH3kZHBQvDDD3wP9iZAl17KMZA+WkfazEz/riq9o1+nTjw5izAQ8fl0i8Pl8j4ZehOOP//Zqhnly1UlqbF9+1oWh8tl+f7luvJdN8VNBQBXX81rR3TrRwTDn6sqUOE4doyTBHyl4gLAn/4EvPCC9b5bt+AzxQxtkyY88wSOUuojsDjo257VflYA5jkctw/AGC/nLAJwbmhHemq8u/NdvLbtNSw4cwHuOfseXPPONXhv13s4t39gw9y82TN7RS+Tocc4ZHV3eTm7ViToWlXlWa3Uifx8dgdlZfkOjgPeXVXffstPmStWcBBb59JLeTLNzgamTePJdrlb6rt350J469axgNmFw4nRozk2UFNj3a8QH8/CIE2oAKv0hghHUhJbAbt28XupU+WN+Hj+Z3dVLV9uncOXq2r6dM4kW7qU+3uLcHTrBmza1NhV1dQJdvz4xj0mArU4Ao1xKMV/W/4sDkPHJazC0VFYm7MWrkgX/nbu3xAZEYmHznsI/ZL7NQTF/VFSYq3cJvIUDt3iKCri1/JynvTFKjlxwr9wyNP5sWONLQ6ZeBosjqj4hgKHSvGai6FDrafqjRs9haOqCtjCFVRQV8fWhVLW+goRjs8+4/eBCEdmJovGrl2e3f8Aq8yG3oxJLAB5kk9KsjKsSkqsXhy+sC8CrKmx3GUAn4+I780uHJGRnF68fLllcXTubKWp2l1VTbU4nDjzTODssz1TdHVEVANZeCdWVVaW766Gho6NKTkSAtblrsOE3hMQGcE6PKTLEDw+/XFEdYrye6xSPLlVVFgWgAhHUpKncIjFUVHhmaZrX9XshGQe6cJx/Dgv+hLR0S0OKXC4bBm7I5YutcaSlcUZUlJGZOtWzza0GRnAuIYaADwh6xN/IMIxahS/bt/e2FUFWO/1RWiAZVVIy9D8fK7p9N57vi0OgN1MH3zA/b5ra/na+jqauDjP+kxOuFz8+zhxwtlVFQ7hGDaMRdnbmKRfeCD1KkVcKyqAqVNDNUJDe8MIRxOpV/W46u2rcM+n92BT3iZMSpvUpPNUVFgTrgR7xRIYOZJdVRJT0F1VunAEEiB3Eg6An4Rl8hUByuicgUGpg1BZySU1AK6vJG6zrVs5JnPuubxdrysFsMWhu1PE4hACEQ7Zp7DQWTjEShKBkadpXThSUvi7jYvjeIe9v4WdZ5/lDLB589jieecd3i6TflyctejNm4UXG+sZ4xCLI1SuqqYwapSV4uwPPY5jhMPgDSMcTeSV717Bkm1LcN/n9+Fk3UmckX6G131ffJFXQzsFlfXFapJeKhbHyJFsFUglWN3i0GMfgQiHuKpKShoLh0xqYnE8MeMJvH/V+3j4YR7T2Wfz9WR8O3daK6LvvJN9+Kmp7DIB2OIYPtw6r93ikJpLvhABKCqyOu7p2IXDbnFIjAMAHniABe6JJ3xfc9gwrs777rsstPffz9c9/3z+3OXyXPTmhMvFLq6KCk+LI5yuKn/84Q/8+woEEY7ERNOv2+AdIxxBUq/q8WrWq1iwagHG9RqHxGie0Sale7c4XniBS2rIGgcdXTjE4hDhGOGuSHL4MIuDWAR2iyMYV9XRo55BZSeLIy4qDqX5SXjgAU7/nTOHRe/bb/lzqWB70UW8cO+119g1NWMGTzi9erHPf8wYnuBjYizhSEgIrKx2VBRP0PKdeROOnj3ZonFyVc2ezSnMv/qV/+sJRMCsWZy5pBRbKdKfWywOX4vcRCxLSnjfvn09t8fF8eQs21sbIhw//nHT0oUNHQMjHEHyv9/9L+YsnYNUVypeufgVPHTeQ7hg8AUN5USEqiqeuD74gLOJACu9VEfvF2G3OKR5Tn6+FRgHTs1VJYUNBd3i0AXo3Xf5Hh54wJrkDh+2YhcpKbwYccYMfroePx743e84LhAdzftcdpn1tC4xh0DcVEJqqlWC3JtwdOnCFW6nTLH2i4jgJ/vUVBaNprQpve02njwvuYQFcsgQdjvpq6Wd0K03WSDXrZtlcRBxjOjWW4MfU3PQuTNbx9d6r79pMJisqmDZfGQz4qPisWPeDkRQBEZ2H4mbJtzUaL+NG9lH/uGHlosqK6txZVCxOGJigL17eSV4YSFPOrIKNz/fMwffHhwPxlVld5dJPaLoaMtVBbD1Ex/Pk6XefnXqVF7IN2MGT5JvvMENgObM4XNkaHUA7rzT81pDh/oummcnJcW7cOilLhYtsrZHRAB/+xuvJTkVoqOtvheAlZLrcvl+EtfXPsjPf/2rZ6Mje6/y1gSRZ+8Ug8EJIxxBsq9kHwakDPDaR0OQgHF1teW68WVxZGby+ogVK3gyTE72LIOh+8TLy/npX0qB+3NVnTzJK7b1kt6CTOSxsZ7n2b+fJzsiTzHo25c75+mup6ee8n194cUXA8vsEVJTLWvNl8Vh5/e/D/wawdK/v+8Fl/raBxGOX/86fOMxGFoCIxwBopQCEWFfyT4MTB3o8VlWFnD99cDrr3MDn7w8q+TEzJmcX79mjeeaAEEsjnHjrF7VRUUc35BJMT/fcw2CWBwDB/Jn/iyO3Fy2NEaPBr780vMzEQ6Xy9PiOHDAyghyuSyRSktren7/8CCbHaakWGIWjHCEk5df9v25bnH4W1tjMLRVjHAEwMm6kxjwxAD86aw/Yf+x/Q0tYAGekG++mTOL7rqLYxonT7KVMX48sHAh71dSYpXgkBiAbI+KYp/6wIHsqvq//2MLIzKSJ8aCAitDKD6eLY6jR62+Ff6EQ+IbmZmWcKSmsmjpwqFXdN2/n338Qp8+LBzN6WbxtVK7pYRD/9054WRxGAztDRMcD4D1ueuRW56LFza9gBM1JzAgZUDDZ9JPu39/zjCqruaJ9/Bhz3TGzEyOFezc6Xnu4mKeIIcP5wY357qrlIhrSp70Cwut+ktHjnCarvjN/bmqRDik6qycF/B0VYnFcewYpwDrfaSljlRa4JXhTxl9wZ5dOEaNYhFrbdVYjXAYOgJGOAJgzUFOgt+Yx4ELXThWr+asmffcNXpnzLDSN/XV0+KmkaZDgr2G0jnn8KtskzIYhYUsJsnJHEQHLOEQi6OoyLksuATGdeGQtRROFodkd+kB3f79OTupl7/+jCHEX22o3NzW17/aKThuMLQ3jKsqAEQ4BF04cnP5aXz0aI5xTJjA9Yq2bLH6WQPWJGzvISEWhzBmDE/O8oTfvTunuBYVsbsqMdFaT9G7N7u5RDjmzmWBkRpRQnY2X0O3FnxZHLKeRLc45s/nEtpR/quohAxfFkdrxVgcho6AEQ4/1NTV4KtDX+H8gedjxd4VAIB+yf0aPs/NtSbYyy/n15tu4rRbPR4gRff0HhK1tWxx6Pt16sSiIxNl9+4c9ygoYH9+YqK1gK9HDw7A6pbCtm3satKzsLKzOTNKn4jtwuHP4khPb363kC6orc2y8IaxOAwdAeOq8sOmvE04XnMcvzztl+gW1w29E3t79OXOzW0cMNZ7MOv062dNyqtW8cS4Z0/jqq3du1uTTrdubG1kZXF2lr7qWoRDLI7CQk4V/eILz/MdOsTCkZhopcNK/wmndNz9+zn43JxlMZwQoUtI8N37ujVhLA5DR6CN/HdsOXYV8cqvMT3H4IqRV3g0Z6qqYldToAHjfv0si2PzZs6OKi/3XbVVX8sxebKny6Z7d0s4lLJWl9vbyWZns+tLVlTrq5+d0nF37+YMr2DWXIQDEdS24qYCjHAYOgbGVeWHnDIulpTeOR3/vOCfUIon8W7drEKDgQpH//4c/1DKs1y6rz4RegOjM86wMqSSkzk1VFxMx49zRhfgKRwVFewOk0V8KSm8r6wxsLuqlOLUYun/3ZKIoLYl4TCuKkNHwFgcfsgpy0GqK7WhK97jj/Pq6aIia/IPxuKorOQsqdxca0L0tTZCXErx8RyAF1eVZEWJxSGVcwcOBL77jld3A5bQiHAkJ/M57MIhwfHcXBbG1lAZtS0Kh7E4DB2BsAoHEU0nol1EtIeI7nL4nIjoSffnWUQ0zr09g4g+JaIdRLSdiG7TjrmXiHKJaIv73wX284aSnLKchgKGNTXAI4/w5L9xoyUcgS6KkyD6gQN87MSJPMnPmeP9GLE4Tj+dFwTKJKoLR2WlJRz33ssCM3s2rxkR4ZAsLREOCTbbLQ4plaKnErcUSUnsLjPCYTC0LsLmqiKiTgCeBnAegBwA64lomVLqe223GQAGu/9NAvCM+7UWwJ1KqU1ElAhgIxGt0o59TCn1j3CNXSenLAdpCX0wbpyni2njRmvSDcbiADjOkZvLazYyM30fIwIxeTK/6tlWAE9OBQVWfGPAAOCjj7ig4AMPWKu/xeKYO5ezrrxZHJs2cSwk0MY/4SQigoWuLQkHEX+n1dWm5Iih/RLOGMdEAHuUUvsAgIiWAJgFQBeOWQBeUUopAGuJKJmIeiml8gDkAYBSqpyIdgBIsx3bLOSU5WBYp+n4v838ftQojhFs2sRP8S5X4NlHIhz79nGtqUAsldRUXh8i1V79uaq6dmUhmzuXO9rV1fFkJuIm5bKlsY89OL5xIy9WbC2T3oABlrXUVoiNZeEwFoehvRJOV1UagGztfY57W1D7EFE/AKcBWKdtvsXt2lpERH46STedqtoqFJwoQHQpt5l7912ecCdMsFxVaWmBZx8lJLBYfPYZr+EI1FK5/HKrVpU/V5XUbrrtNr7G4sXcwc++cM/uqhIXy9dft474hrBqFfDQQy09iuBwufj7bkofEIOhLRBO4XCaTu3NU33uQ0QJAN4GMF8p5W6gimcADAQwFmyVPOJ4caIbiWgDEW0ocKrDEQC5ZeyXqi3gleKTJrEFMG4cu5u2bQu+dtOkSVbWU1PqPtmFw+WyLA5x7QAcJH/8cW6XumJF4/M4ZVUBnIF1+unBjytcpKS0HusnUGJjjbVhaN+EUzhyAGidHJAO4HCg+xBRFFg0Fiul3pEdlFJHlVJ1Sql6AM+DXWKNUEotVEpNUEpN6CapScHegDsV93hebyQkWJO1PJFv3x58LOCMM6zGSE2pNNunD6fhSq9tcVUVFbGo6U+5t97K/5wquvbsycfqpdMFiacYmob0JjcY2ivhjHGsBzCYiPoDyAVwJYCrbfssA7udloCD4qVKqTwiIgAvAtihlHpUP0CLgQDAJQC2hesGRDiKclIxZIjlkpo8mVuinnMOu4SCQZ+Um2JxpKdzMya9h7W4qsSdFQhSVl1ERc8G8hewN/jGWByG9k7YhEMpVUtEtwBYAaATgEVKqe1EdJP782cBfATgAgB7AJwAcL378CkA5gDYSkRb3NvuVkp9BOAhIhoLdmkdABC2/moiHDn74zBpkrU9IYEX8jWFCRM4rbauLrj+2zr2lM/aWg62B9ubQm/jKhNdly7NW8iwPWKEw9DeCevKcfdE/5Ft27PazwrAPIfjvoRz/ANKKR+rHkJLTlkOkiK74+DBCJ9rLYLB5QLGjgVycnz3rg4U8f9nZ/N5m4pYU6dyDgPjclmr+A2G9ogpOeKDOWPmoE/N+fhdPTBkSOjOu2ABcPBgaM6lC8e0ab739YVMdNJIytB0rr+eU7YNhvaKEQ4fnN57Il5yZyRJMDoUSPn1UCAukfr64GIcdq68ks9xzTWhGVdHRtbKGAztFSMcPvj734FnnmELoTWspHZCLA4izx7hwRIZCfz856EZk8FgaN+YIoc+GDAA+MUvgAcfbOmReGfaNO7Ot2kTcOGFLT0ag8HQESCOT7dvJkyYoDZs2NDSwzAYDIY2BRFtVEpNsG83FofBYDAYgsIIh8FgMBiCwgiHwWAwGILCCIfBYDAYgsIIh8FgMBiCwgiHwWAwGILCCIfBYDAYgsIIh8FgMBiCokMsACSiAgBNLSvYFUBhCIfTFuno30FHv3/AfAcd9f77KqUadcLrEMJxKhDRBqeVkx2Jjv4ddPT7B8x30NHv345xVRkMBoMhKIxwGAwGgyEojHD4Z2FLD6AV0NG/g45+/4D5Djr6/XtgYhwGg8FgCApjcRgMBoMhKIxwGAwGgyEojHD4gIimE9EuItpDRHe19HiaAyI6QERbiWgLEW1wb0slolVEtNv9mtLS4wwlRLSIiPKJaJu2zes9E9Ef3H8Tu4jo/JYZdejwcv/3ElGu++9gCxFdoH3W3u4/g4g+JaIdRLSdiG5zb+8wfwPBYoTDC0TUCcDTAGYAGAHgKiIa0bKjajbOUUqN1fLW7wKwWik1GMBq9/v2xEsAptu2Od6z+2/gSgAj3cf8y/230pZ5CY3vHwAec/8djFVKfQS02/uvBXCnUmo4gDMAzHPfZ0f6GwgKIxzemQhgj1Jqn1LqJIAlAGa18JhailkAXnb//DKAi1twLCFHKfU5gGLbZm/3PAvAEqVUtVJqP4A94L+VNouX+/dGe7z/PKXUJvfP5QB2AEhDB/obCBYjHN5JA5Ctvc9xb2vvKAAriWgjEd3o3tZDKZUH8H8yAN1bbHTNh7d77kh/F7cQUZbblSVumnZ9/0TUD8BpANbB/A14xQiHd8hhW0fIXZ6ilBoHdtHNI6KzWnpArYyO8nfxDICBAMYCyAPwiHt7u71/IkoA8DaA+UqpMl+7OmxrF99BoBjh8E4OgAztfTqAwy00lmZDKXXY/ZoPYCnYBD9KRL0AwP2a33IjbDa83XOH+LtQSh1VStUppeoBPA/LFdMu75+IosCisVgp9Y57c4f+G/CFEQ7vrAcwmIj6E1E0OBi2rIXHFFaIKJ6IEuVnAD8FsA1839e5d7sOwHstM8Jmxds9LwNwJRHFEFF/AIMBfNsC4wsrMmG6uQT8dwC0w/snIgLwIoAdSqlHtY869N+ALyJbegCtFaVULRHdAmAFgE4AFimltrfwsMJNDwBL+f8RIgH8Rym1nIjWA3iDiH4J4BCAy1pwjCGHiF4DMBVAVyLKAXAPgAfhcM9Kqe1E9AaA78HZOPOUUnUtMvAQ4eX+pxLRWLAL5gCAXwPt8/4BTAEwB8BWItri3nY3OtDfQLCYkiMGg8FgCArjqjIYDAZDUBjhMBgMBkNQGOEwGAwGQ1AY4TAYDAZDUBjhMBgMBkNQGOEwGE4BIqrTKshuCWUVZSLqp1esNRhaC2Ydh8FwalQqpca29CAMhubEWBwGQxhw9zX5OxF96/43yL29LxGtdhcPXE1EfdzbexDRUiL6zv3vTPepOhHR8+4+ESuJyOXe/1Yi+t59niUtdJuGDooRDoPh1HDZXFVXaJ+VKaUmAngKwOPubU8BeEUplQlgMYAn3dufBLBGKTUGwDgAUqVgMICnlVIjARwDMNu9/S4Ap7nPc1O4bs5gcMKsHDcYTgEiqlBKJThsPwDgJ0qpfe4CekeUUl2IqBBAL6VUjXt7nlKqKxEVAEhXSlVr5+gHYJW7kRCI6PcAopRS9xPRcgAVAN4F8K5SqiLMt2owNGAsDoMhfCgvP3vbx4lq7ec6WHHJC8EdKscD2EhEJl5paDaMcBgM4eMK7fUb989fgystA8A1AL50/7wawM0Aty0mos7eTkpEEQAylFKfAvgdgGQAjawegyFcmKcUg+HUcGkVVQFguVJKUnJjiGgd+AHtKve2WwEsIqIFAAoAXO/efhuAhe5KrHVgEcnzcs1OAF4loiRwU6HHlFLHQnZHBoMfTIzDYAgD7hjHBKVUYUuPxWAINcZVZTAYDIagMBaHwWAwGILCWBwGg8FgCAojHAaDwWAICiMcBoPBYAgKIxwGg8FgCAojHAaDwWAIiv8PldKlRYDghBQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = history.history['categorical_accuracy']\n",
    "loss_val = history.history['val_categorical_accuracy']\n",
    "epochs = range(1,41)\n",
    "plt.plot(loss_train, 'g', label='Training accuracy')\n",
    "plt.plot(loss_val, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:06:31.950083Z",
     "iopub.status.busy": "2020-10-03T14:06:31.949384Z",
     "iopub.status.idle": "2020-10-03T14:06:36.777522Z",
     "shell.execute_reply": "2020-10-03T14:06:36.776939Z"
    },
    "id": "t4naHqcUlZwD",
    "outputId": "0436d35b-8809-4574-d9bf-26a36e258087",
    "papermill": {
     "duration": 13.941055,
     "end_time": "2020-10-03T14:06:36.777646",
     "exception": false,
     "start_time": "2020-10-03T14:06:22.836591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 4s 185ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "res_test=model.predict_generator(test_generator,\n",
    "#steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:06:54.920405Z",
     "iopub.status.busy": "2020-10-03T14:06:54.919058Z",
     "iopub.status.idle": "2020-10-03T14:06:54.923320Z",
     "shell.execute_reply": "2020-10-03T14:06:54.923940Z"
    },
    "id": "npEpSWh1Xdbi",
    "outputId": "db051e0d-f7e9-4050-a4b3-34b3957420ef",
    "papermill": {
     "duration": 9.253064,
     "end_time": "2020-10-03T14:06:54.924092",
     "exception": false,
     "start_time": "2020-10-03T14:06:45.671028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1380, 80)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:07:13.248536Z",
     "iopub.status.busy": "2020-10-03T14:07:13.247808Z",
     "iopub.status.idle": "2020-10-03T14:07:16.405770Z",
     "shell.execute_reply": "2020-10-03T14:07:16.405198Z"
    },
    "id": "NZSx35J0mP4P",
    "outputId": "d467bca4-e070-4a62-b80e-ac7753eeeb86",
    "papermill": {
     "duration": 11.948517,
     "end_time": "2020-10-03T14:07:16.405924",
     "exception": false,
     "start_time": "2020-10-03T14:07:04.457407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 3s 109ms/step\n"
     ]
    }
   ],
   "source": [
    "valid_generator.reset()\n",
    "res_cv=model.predict_generator(valid_generator,\n",
    "#steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:07:34.176880Z",
     "iopub.status.busy": "2020-10-03T14:07:34.176085Z",
     "iopub.status.idle": "2020-10-03T14:07:55.730555Z",
     "shell.execute_reply": "2020-10-03T14:07:55.731077Z"
    },
    "id": "WoTDEbQ8mWjp",
    "outputId": "a898e571-f235-4905-f5e8-323cfabf2646",
    "papermill": {
     "duration": 30.640527,
     "end_time": "2020-10-03T14:07:55.731229",
     "exception": false,
     "start_time": "2020-10-03T14:07:25.090702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 21s 215ms/step\n"
     ]
    }
   ],
   "source": [
    "train_generator.reset()\n",
    "res_train=model.predict_generator(train_generator,\n",
    "#steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:08:14.393614Z",
     "iopub.status.busy": "2020-10-03T14:08:14.392793Z",
     "iopub.status.idle": "2020-10-03T14:08:14.395952Z",
     "shell.execute_reply": "2020-10-03T14:08:14.396618Z"
    },
    "id": "GF3dag-hmaxo",
    "outputId": "6c3200b8-2a0d-4b8b-9ccb-88a2f93d14be",
    "papermill": {
     "duration": 9.081224,
     "end_time": "2020-10-03T14:08:14.396759",
     "exception": false,
     "start_time": "2020-10-03T14:08:05.315535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6251, 80)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:08:32.204224Z",
     "iopub.status.busy": "2020-10-03T14:08:32.203162Z",
     "iopub.status.idle": "2020-10-03T14:08:32.208891Z",
     "shell.execute_reply": "2020-10-03T14:08:32.209638Z"
    },
    "id": "utPbTWaEunpC",
    "outputId": "a68ccbb0-d116-497e-eb01-c5d19f0b6251",
    "papermill": {
     "duration": 8.937449,
     "end_time": "2020-10-03T14:08:32.209825",
     "exception": false,
     "start_time": "2020-10-03T14:08:23.272376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6251, 80)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:08:50.151997Z",
     "iopub.status.busy": "2020-10-03T14:08:50.151138Z",
     "iopub.status.idle": "2020-10-03T14:08:50.351020Z",
     "shell.execute_reply": "2020-10-03T14:08:50.349851Z"
    },
    "id": "426dRAxkr4pK",
    "outputId": "6b57c86c-4a95-4cbf-d0d4-930568c60d77",
    "papermill": {
     "duration": 9.158607,
     "end_time": "2020-10-03T14:08:50.351187",
     "exception": false,
     "start_time": "2020-10-03T14:08:41.192580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converting taget and identity columns to booleans\n",
    "\n",
    "target_columns=list(trainmultidf.columns)[:-1]\n",
    "\n",
    "def convert_to_bool(df, col_name):\n",
    "    df[col_name] = np.where(df[col_name] >= 0.5, True, False)\n",
    "    \n",
    "def convert_dataframe_to_bool(df):\n",
    "    bool_df = df.copy()\n",
    "    for col in target_columns:\n",
    "        convert_to_bool(bool_df, col)\n",
    "    return bool_df\n",
    "\n",
    "test_bool = convert_dataframe_to_bool(testmultidf) \n",
    "test_lable_bool=test_bool[list(test_bool.columns)[:-1]].to_numpy()\n",
    "\n",
    "train_bool = convert_dataframe_to_bool(trainmultidf) \n",
    "train_lable_bool=train_bool[list(train_bool.columns)[:-1]].to_numpy()\n",
    "\n",
    "cv_bool = convert_dataframe_to_bool(cvmultidf) \n",
    "cv_lable_bool=cv_bool[list(cv_bool.columns)[:-1]].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGR3yHWL1RNt",
    "papermill": {
     "duration": 9.316516,
     "end_time": "2020-10-03T14:09:09.871695",
     "exception": false,
     "start_time": "2020-10-03T14:09:00.555179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:09:27.975482Z",
     "iopub.status.busy": "2020-10-03T14:09:27.974704Z",
     "iopub.status.idle": "2020-10-03T14:09:27.978370Z",
     "shell.execute_reply": "2020-10-03T14:09:27.977743Z"
    },
    "id": "60yDzAaN1NWR",
    "papermill": {
     "duration": 9.092201,
     "end_time": "2020-10-03T14:09:27.978497",
     "exception": false,
     "start_time": "2020-10-03T14:09:18.886296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "\n",
    "def _one_sample_positive_class_precisions(scores, truth):\n",
    "  \"\"\"Calculate precisions for each true class for a single sample.\n",
    "  \n",
    "  Args:\n",
    "    scores: np.array of (num_classes,) giving the individual classifier scores.\n",
    "    truth: np.array of (num_classes,) bools indicating which classes are true.\n",
    "\n",
    "  Returns:\n",
    "    pos_class_indices: np.array of indices of the true classes for this sample.\n",
    "    pos_class_precisions: np.array of precisions corresponding to each of those\n",
    "      classes.\n",
    "  \"\"\"\n",
    "  num_classes = scores.shape[0]\n",
    "  pos_class_indices = np.flatnonzero(truth > 0)\n",
    "  # Only calculate precisions if there are some true classes.\n",
    "  if not len(pos_class_indices):\n",
    "    return pos_class_indices, np.zeros(0)\n",
    "  # Retrieval list of classes for this sample. \n",
    "  retrieved_classes = np.argsort(scores)[::-1]\n",
    "  # class_rankings[top_scoring_class_index] == 0 etc.\n",
    "  class_rankings = np.zeros(num_classes, dtype=np.int)\n",
    "  class_rankings[retrieved_classes] = range(num_classes)\n",
    "  # Which of these is a true label?\n",
    "  retrieved_class_true = np.zeros(num_classes, dtype=np.bool)\n",
    "  retrieved_class_true[class_rankings[pos_class_indices]] = True\n",
    "  # Num hits for every truncated retrieval list.\n",
    "  retrieved_cumulative_hits = np.cumsum(retrieved_class_true)\n",
    "  # Precision of retrieval list truncated at each hit, in order of pos_labels.\n",
    "  precision_at_hits = (\n",
    "      retrieved_cumulative_hits[class_rankings[pos_class_indices]] / \n",
    "      (1 + class_rankings[pos_class_indices].astype(np.float)))\n",
    "  return pos_class_indices, precision_at_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:09:46.217151Z",
     "iopub.status.busy": "2020-10-03T14:09:46.216125Z",
     "iopub.status.idle": "2020-10-03T14:09:46.221411Z",
     "shell.execute_reply": "2020-10-03T14:09:46.220862Z"
    },
    "id": "p0pSGCCP1a4R",
    "papermill": {
     "duration": 9.335406,
     "end_time": "2020-10-03T14:09:46.221521",
     "exception": false,
     "start_time": "2020-10-03T14:09:36.886115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_per_class_lwlrap(truth, scores):\n",
    "  \"\"\"Calculate label-weighted label-ranking average precision.\n",
    "  \n",
    "  Arguments:\n",
    "    truth: np.array of (num_samples, num_classes) giving boolean ground-truth\n",
    "      of presence of that class in that sample.\n",
    "    scores: np.array of (num_samples, num_classes) giving the classifier-under-\n",
    "      test's real-valued score for each class for each sample.\n",
    "  \n",
    "  Returns:\n",
    "    per_class_lwlrap: np.array of (num_classes,) giving the lwlrap for each \n",
    "      class.\n",
    "    weight_per_class: np.array of (num_classes,) giving the prior of each \n",
    "      class within the truth labels.  Then the overall unbalanced lwlrap is \n",
    "      simply np.sum(per_class_lwlrap * weight_per_class)\n",
    "  \"\"\"\n",
    "  assert truth.shape == scores.shape\n",
    "  num_samples, num_classes = scores.shape\n",
    "  # Space to store a distinct precision value for each class on each sample.\n",
    "  # Only the classes that are true for each sample will be filled in.\n",
    "  precisions_for_samples_by_classes = np.zeros((num_samples, num_classes))\n",
    "  for sample_num in range(num_samples):\n",
    "    pos_class_indices, precision_at_hits = (\n",
    "      _one_sample_positive_class_precisions(scores[sample_num, :], \n",
    "                                            truth[sample_num, :]))\n",
    "    precisions_for_samples_by_classes[sample_num, pos_class_indices] = (\n",
    "        precision_at_hits)\n",
    "  labels_per_class = np.sum(truth > 0, axis=0)\n",
    "  weight_per_class = labels_per_class / float(np.sum(labels_per_class))\n",
    "  # Form average of each column, i.e. all the precisions assigned to labels in\n",
    "  # a particular class.\n",
    "  per_class_lwlrap = (np.sum(precisions_for_samples_by_classes, axis=0) / \n",
    "                      np.maximum(1, labels_per_class))\n",
    "  # overall_lwlrap = simple average of all the actual per-class, per-sample precisions\n",
    "  #                = np.sum(precisions_for_samples_by_classes) / np.sum(precisions_for_samples_by_classes > 0)\n",
    "  #           also = weighted mean of per-class lwlraps, weighted by class label prior across samples\n",
    "  #                = np.sum(per_class_lwlrap * weight_per_class)\n",
    "  return per_class_lwlrap, weight_per_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:10:05.240815Z",
     "iopub.status.busy": "2020-10-03T14:10:05.238965Z",
     "iopub.status.idle": "2020-10-03T14:10:05.241601Z",
     "shell.execute_reply": "2020-10-03T14:10:05.242108Z"
    },
    "id": "J4ZZS-k71ffc",
    "papermill": {
     "duration": 9.48151,
     "end_time": "2020-10-03T14:10:05.242276",
     "exception": false,
     "start_time": "2020-10-03T14:09:55.760766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculate_overall_lwlrap_sklearn(truth, scores):\n",
    "  \"\"\"Calculate the overall lwlrap using sklearn.metrics.lrap.\"\"\"\n",
    "  # sklearn doesn't correctly apply weighting to samples with no labels, so just skip them.\n",
    "  sample_weight = np.sum(truth > 0, axis=1)\n",
    "  nonzero_weight_sample_indices = np.flatnonzero(sample_weight > 0)\n",
    "  overall_lwlrap = sklearn.metrics.label_ranking_average_precision_score(\n",
    "      truth[nonzero_weight_sample_indices, :] > 0, \n",
    "      scores[nonzero_weight_sample_indices, :], \n",
    "      sample_weight=sample_weight[nonzero_weight_sample_indices])\n",
    "  return overall_lwlrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:10:23.672089Z",
     "iopub.status.busy": "2020-10-03T14:10:23.671178Z",
     "iopub.status.idle": "2020-10-03T14:10:23.675572Z",
     "shell.execute_reply": "2020-10-03T14:10:23.674992Z"
    },
    "id": "MV5Yu3aL1hPM",
    "papermill": {
     "duration": 9.178814,
     "end_time": "2020-10-03T14:10:23.675684",
     "exception": false,
     "start_time": "2020-10-03T14:10:14.496870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class lwlrap_accumulator(object):\n",
    "  \"\"\"Accumulate batches of test samples into per-class and overall lwlrap.\"\"\"  \n",
    "\n",
    "  def __init__(self):\n",
    "    self.num_classes = 0\n",
    "    self.total_num_samples = 0\n",
    "  \n",
    "  def accumulate_samples(self, batch_truth, batch_scores):\n",
    "    \"\"\"Cumulate a new batch of samples into the metric.\n",
    "    \n",
    "    Args:\n",
    "      truth: np.array of (num_samples, num_classes) giving boolean\n",
    "        ground-truth of presence of that class in that sample for this batch.\n",
    "      scores: np.array of (num_samples, num_classes) giving the \n",
    "        classifier-under-test's real-valued score for each class for each\n",
    "        sample.\n",
    "    \"\"\"\n",
    "    assert batch_scores.shape == batch_truth.shape\n",
    "    num_samples, num_classes = batch_truth.shape\n",
    "    if not self.num_classes:\n",
    "      self.num_classes = num_classes\n",
    "      self._per_class_cumulative_precision = np.zeros(self.num_classes)\n",
    "      self._per_class_cumulative_count = np.zeros(self.num_classes, \n",
    "                                                  dtype=np.int)\n",
    "    assert num_classes == self.num_classes\n",
    "    for truth, scores in zip(batch_truth, batch_scores):\n",
    "      pos_class_indices, precision_at_hits = (\n",
    "        _one_sample_positive_class_precisions(scores, truth))\n",
    "      self._per_class_cumulative_precision[pos_class_indices] += (\n",
    "        precision_at_hits)\n",
    "      self._per_class_cumulative_count[pos_class_indices] += 1\n",
    "    self.total_num_samples += num_samples\n",
    "\n",
    "  def per_class_lwlrap(self):\n",
    "    \"\"\"Return a vector of the per-class lwlraps for the accumulated samples.\"\"\"\n",
    "    return (self._per_class_cumulative_precision / \n",
    "            np.maximum(1, self._per_class_cumulative_count))\n",
    "\n",
    "  def per_class_weight(self):\n",
    "    \"\"\"Return a normalized weight vector for the contributions of each class.\"\"\"\n",
    "    return (self._per_class_cumulative_count / \n",
    "            float(np.sum(self._per_class_cumulative_count)))\n",
    "\n",
    "  def overall_lwlrap(self):\n",
    "    \"\"\"Return the scalar overall lwlrap for cumulated samples.\"\"\"\n",
    "    return np.sum(self.per_class_lwlrap() * self.per_class_weight())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:10:41.626776Z",
     "iopub.status.busy": "2020-10-03T14:10:41.625699Z",
     "iopub.status.idle": "2020-10-03T14:10:41.845483Z",
     "shell.execute_reply": "2020-10-03T14:10:41.846108Z"
    },
    "id": "cmO-oJ5w1mLg",
    "outputId": "79e6cab4-d43b-4a24-a6d0-0c432a2a00cc",
    "papermill": {
     "duration": 9.397227,
     "end_time": "2020-10-03T14:10:41.846308",
     "exception": false,
     "start_time": "2020-10-03T14:10:32.449081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lwlrap from sklearn.metrics = 0.2220629950003967\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/voglinio/keras-2d-model-5-fold-log-specgram-curated-only\n",
    "truth = test_lable_bool\n",
    "scores = res_test\n",
    "print(\"lwlrap from sklearn.metrics =\", calculate_overall_lwlrap_sklearn(truth, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:11:00.751179Z",
     "iopub.status.busy": "2020-10-03T14:11:00.750162Z",
     "iopub.status.idle": "2020-10-03T14:11:01.674974Z",
     "shell.execute_reply": "2020-10-03T14:11:01.675751Z"
    },
    "id": "MfM47X5u1nxs",
    "outputId": "5993f374-81f6-43c4-b90e-c5ddb695c142",
    "papermill": {
     "duration": 10.644135,
     "end_time": "2020-10-03T14:11:01.675900",
     "exception": false,
     "start_time": "2020-10-03T14:10:51.031765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lwlrap from sklearn.metrics = 0.34433522350224083\n"
     ]
    }
   ],
   "source": [
    "truth = train_lable_bool\n",
    "scores = res_train\n",
    "print(\"lwlrap from sklearn.metrics =\", calculate_overall_lwlrap_sklearn(truth, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:11:20.005035Z",
     "iopub.status.busy": "2020-10-03T14:11:20.004103Z",
     "iopub.status.idle": "2020-10-03T14:11:20.231930Z",
     "shell.execute_reply": "2020-10-03T14:11:20.232506Z"
    },
    "id": "nA-xIaLZ1rCM",
    "outputId": "20d2bf94-e109-44d2-f0b4-82d6b408db75",
    "papermill": {
     "duration": 9.470215,
     "end_time": "2020-10-03T14:11:20.232655",
     "exception": false,
     "start_time": "2020-10-03T14:11:10.762440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lwlrap from sklearn.metrics = 0.22868170238282937\n"
     ]
    }
   ],
   "source": [
    "truth = cv_lable_bool\n",
    "scores = res_cv\n",
    "print(\"lwlrap from sklearn.metrics =\", calculate_overall_lwlrap_sklearn(truth, scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgOoKyzbgtF6",
    "papermill": {
     "duration": 8.711338,
     "end_time": "2020-10-03T14:11:37.880125",
     "exception": false,
     "start_time": "2020-10-03T14:11:29.168787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:11:56.648947Z",
     "iopub.status.busy": "2020-10-03T14:11:56.648161Z",
     "iopub.status.idle": "2020-10-03T14:11:56.716184Z",
     "shell.execute_reply": "2020-10-03T14:11:56.714682Z"
    },
    "papermill": {
     "duration": 9.557524,
     "end_time": "2020-10-03T14:11:56.716321",
     "exception": false,
     "start_time": "2020-10-03T14:11:47.158797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_dataframe = pd.DataFrame({'fname':os.listdir('../input/sc2-total-aug-noisy-data/sub2/sub2')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:12:15.415060Z",
     "iopub.status.busy": "2020-10-03T14:12:15.414426Z",
     "iopub.status.idle": "2020-10-03T14:12:16.234151Z",
     "shell.execute_reply": "2020-10-03T14:12:16.233606Z"
    },
    "id": "rxozU-gjkfKI",
    "outputId": "8d0701f6-0c55-46a1-f82e-ab7ae0f8efec",
    "papermill": {
     "duration": 9.829893,
     "end_time": "2020-10-03T14:12:16.234292",
     "exception": false,
     "start_time": "2020-10-03T14:12:06.404399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3361 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "sub_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "sub_generator=sub_datagen.flow_from_dataframe(\n",
    "    dataframe=sub_dataframe,\n",
    "    directory=\"../input/sc2-total-aug-noisy-data/sub2/sub2\",\n",
    "    x_col=\"fname\",\n",
    "    y_col=None,\n",
    "    batch_size=64,\n",
    "    seed=42,\n",
    "    shuffle=False,#shuffle=False,\n",
    "    class_mode=None,\n",
    "    color_mode=\"grayscale\",\n",
    "    target_size=(128,128))\n",
    "STEP_SIZE_SUB=sub_generator.n//sub_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:12:34.367203Z",
     "iopub.status.busy": "2020-10-03T14:12:34.366211Z",
     "iopub.status.idle": "2020-10-03T14:12:45.708531Z",
     "shell.execute_reply": "2020-10-03T14:12:45.707928Z"
    },
    "id": "OQVBkHHUlzTH",
    "outputId": "5be2f5af-4aa6-4cde-8228-aaeb359e412a",
    "papermill": {
     "duration": 20.305614,
     "end_time": "2020-10-03T14:12:45.708658",
     "exception": false,
     "start_time": "2020-10-03T14:12:25.403044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 11s 207ms/step\n"
     ]
    }
   ],
   "source": [
    "sub_generator.reset()\n",
    "res_sub=model.predict_generator(sub_generator,\n",
    "#steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:13:04.537812Z",
     "iopub.status.busy": "2020-10-03T14:13:04.536821Z",
     "iopub.status.idle": "2020-10-03T14:13:04.541062Z",
     "shell.execute_reply": "2020-10-03T14:13:04.540487Z"
    },
    "id": "h4YRO7V9l2JQ",
    "papermill": {
     "duration": 9.310992,
     "end_time": "2020-10-03T14:13:04.541173",
     "exception": false,
     "start_time": "2020-10-03T14:12:55.230181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit_data=pd.DataFrame(res_sub.astype(\"float64\"), columns=list(mlb_train.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:13:22.949201Z",
     "iopub.status.busy": "2020-10-03T14:13:22.948507Z",
     "iopub.status.idle": "2020-10-03T14:13:22.986169Z",
     "shell.execute_reply": "2020-10-03T14:13:22.986998Z"
    },
    "id": "cTwMBIDcl-U_",
    "outputId": "7563a816-3020-4bc1-a006-b3edea85e215",
    "papermill": {
     "duration": 9.434673,
     "end_time": "2020-10-03T14:13:22.987159",
     "exception": false,
     "start_time": "2020-10-03T14:13:13.552486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>Accelerating_and_revving_and_vroom</th>\n",
       "      <th>Accordion</th>\n",
       "      <th>Acoustic_guitar</th>\n",
       "      <th>Applause</th>\n",
       "      <th>Bark</th>\n",
       "      <th>Bass_drum</th>\n",
       "      <th>Bass_guitar</th>\n",
       "      <th>Bathtub_(filling_or_washing)</th>\n",
       "      <th>Bicycle_bell</th>\n",
       "      <th>...</th>\n",
       "      <th>Toilet_flush</th>\n",
       "      <th>Traffic_noise_and_roadway_noise</th>\n",
       "      <th>Trickle_and_dribble</th>\n",
       "      <th>Walk_and_footsteps</th>\n",
       "      <th>Water_tap_and_faucet</th>\n",
       "      <th>Waves_and_surf</th>\n",
       "      <th>Whispering</th>\n",
       "      <th>Writing</th>\n",
       "      <th>Yell</th>\n",
       "      <th>Zipper_(clothing)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53cefef0.wav</td>\n",
       "      <td>0.346481</td>\n",
       "      <td>0.351873</td>\n",
       "      <td>0.346637</td>\n",
       "      <td>0.352271</td>\n",
       "      <td>0.349168</td>\n",
       "      <td>0.366126</td>\n",
       "      <td>0.347189</td>\n",
       "      <td>0.351332</td>\n",
       "      <td>0.405199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351133</td>\n",
       "      <td>0.351358</td>\n",
       "      <td>0.350390</td>\n",
       "      <td>0.351016</td>\n",
       "      <td>0.352038</td>\n",
       "      <td>0.346159</td>\n",
       "      <td>0.351702</td>\n",
       "      <td>0.349679</td>\n",
       "      <td>0.349258</td>\n",
       "      <td>0.352273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63b41f09.wav</td>\n",
       "      <td>0.349181</td>\n",
       "      <td>0.354293</td>\n",
       "      <td>0.396450</td>\n",
       "      <td>0.350703</td>\n",
       "      <td>0.352679</td>\n",
       "      <td>0.348850</td>\n",
       "      <td>0.351810</td>\n",
       "      <td>0.364183</td>\n",
       "      <td>0.354378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352159</td>\n",
       "      <td>0.357297</td>\n",
       "      <td>0.354791</td>\n",
       "      <td>0.349025</td>\n",
       "      <td>0.368260</td>\n",
       "      <td>0.353365</td>\n",
       "      <td>0.342081</td>\n",
       "      <td>0.340141</td>\n",
       "      <td>0.346909</td>\n",
       "      <td>0.350295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9da3bbc9.wav</td>\n",
       "      <td>0.351659</td>\n",
       "      <td>0.349719</td>\n",
       "      <td>0.346252</td>\n",
       "      <td>0.352661</td>\n",
       "      <td>0.349353</td>\n",
       "      <td>0.348353</td>\n",
       "      <td>0.354356</td>\n",
       "      <td>0.353510</td>\n",
       "      <td>0.348553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355527</td>\n",
       "      <td>0.351215</td>\n",
       "      <td>0.357203</td>\n",
       "      <td>0.354910</td>\n",
       "      <td>0.348584</td>\n",
       "      <td>0.350091</td>\n",
       "      <td>0.349533</td>\n",
       "      <td>0.357303</td>\n",
       "      <td>0.354594</td>\n",
       "      <td>0.346603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b6e192f8.wav</td>\n",
       "      <td>0.360171</td>\n",
       "      <td>0.349143</td>\n",
       "      <td>0.351196</td>\n",
       "      <td>0.351163</td>\n",
       "      <td>0.357307</td>\n",
       "      <td>0.352828</td>\n",
       "      <td>0.350358</td>\n",
       "      <td>0.369143</td>\n",
       "      <td>0.357907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348489</td>\n",
       "      <td>0.351874</td>\n",
       "      <td>0.357501</td>\n",
       "      <td>0.351153</td>\n",
       "      <td>0.366923</td>\n",
       "      <td>0.346773</td>\n",
       "      <td>0.341868</td>\n",
       "      <td>0.336726</td>\n",
       "      <td>0.350900</td>\n",
       "      <td>0.355026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f2ebd17a.wav</td>\n",
       "      <td>0.351671</td>\n",
       "      <td>0.351150</td>\n",
       "      <td>0.347524</td>\n",
       "      <td>0.351846</td>\n",
       "      <td>0.360044</td>\n",
       "      <td>0.358940</td>\n",
       "      <td>0.350322</td>\n",
       "      <td>0.350472</td>\n",
       "      <td>0.356367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.348898</td>\n",
       "      <td>0.350655</td>\n",
       "      <td>0.349155</td>\n",
       "      <td>0.354011</td>\n",
       "      <td>0.353215</td>\n",
       "      <td>0.350979</td>\n",
       "      <td>0.356401</td>\n",
       "      <td>0.352485</td>\n",
       "      <td>0.349758</td>\n",
       "      <td>0.348032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          fname  Accelerating_and_revving_and_vroom  Accordion  \\\n",
       "0  53cefef0.wav                            0.346481   0.351873   \n",
       "1  63b41f09.wav                            0.349181   0.354293   \n",
       "2  9da3bbc9.wav                            0.351659   0.349719   \n",
       "3  b6e192f8.wav                            0.360171   0.349143   \n",
       "4  f2ebd17a.wav                            0.351671   0.351150   \n",
       "\n",
       "   Acoustic_guitar  Applause      Bark  Bass_drum  Bass_guitar  \\\n",
       "0         0.346637  0.352271  0.349168   0.366126     0.347189   \n",
       "1         0.396450  0.350703  0.352679   0.348850     0.351810   \n",
       "2         0.346252  0.352661  0.349353   0.348353     0.354356   \n",
       "3         0.351196  0.351163  0.357307   0.352828     0.350358   \n",
       "4         0.347524  0.351846  0.360044   0.358940     0.350322   \n",
       "\n",
       "   Bathtub_(filling_or_washing)  Bicycle_bell  ...  Toilet_flush  \\\n",
       "0                      0.351332      0.405199  ...      0.351133   \n",
       "1                      0.364183      0.354378  ...      0.352159   \n",
       "2                      0.353510      0.348553  ...      0.355527   \n",
       "3                      0.369143      0.357907  ...      0.348489   \n",
       "4                      0.350472      0.356367  ...      0.348898   \n",
       "\n",
       "   Traffic_noise_and_roadway_noise  Trickle_and_dribble  Walk_and_footsteps  \\\n",
       "0                         0.351358             0.350390            0.351016   \n",
       "1                         0.357297             0.354791            0.349025   \n",
       "2                         0.351215             0.357203            0.354910   \n",
       "3                         0.351874             0.357501            0.351153   \n",
       "4                         0.350655             0.349155            0.354011   \n",
       "\n",
       "   Water_tap_and_faucet  Waves_and_surf  Whispering   Writing      Yell  \\\n",
       "0              0.352038        0.346159    0.351702  0.349679  0.349258   \n",
       "1              0.368260        0.353365    0.342081  0.340141  0.346909   \n",
       "2              0.348584        0.350091    0.349533  0.357303  0.354594   \n",
       "3              0.366923        0.346773    0.341868  0.336726  0.350900   \n",
       "4              0.353215        0.350979    0.356401  0.352485  0.349758   \n",
       "\n",
       "   Zipper_(clothing)  \n",
       "0           0.352273  \n",
       "1           0.350295  \n",
       "2           0.346603  \n",
       "3           0.355026  \n",
       "4           0.348032  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_data.insert(0, 'fname', os.listdir('../input/sc2-total-aug-noisy-data/sub2/sub2'))\n",
    "submit_data[\"fname\"]=submit_data[\"fname\"].apply(lambda x: x.split(\".\")[0]+\".wav\")\n",
    "submit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-03T14:13:40.932618Z",
     "iopub.status.busy": "2020-10-03T14:13:40.931904Z",
     "iopub.status.idle": "2020-10-03T14:13:41.795917Z",
     "shell.execute_reply": "2020-10-03T14:13:41.795277Z"
    },
    "id": "v73id52ZmEWg",
    "papermill": {
     "duration": 9.793335,
     "end_time": "2020-10-03T14:13:41.796063",
     "exception": false,
     "start_time": "2020-10-03T14:13:32.002728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit_data.to_csv(\"submission_AugNoisyData_selfNoisy1.csv\",index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 9.787653,
     "end_time": "2020-10-03T14:14:00.553587",
     "exception": false,
     "start_time": "2020-10-03T14:13:50.765934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "papermill": {
   "duration": 6948.07774,
   "end_time": "2020-10-03T14:14:11.108857",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-03T12:18:23.031117",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
